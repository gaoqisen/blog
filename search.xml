<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[《代码整洁之道》]]></title>
    <url>%2Fbook%2FTheCleanCoder.html</url>
    <content type="text"><![CDATA[第一章 专业主义1.1清楚你要什么清楚自己负责的是，并为自己收拾残局 1.2 担当责任自己写的代码要对它负责，如果有bug需要自己去负责，不要推卸责任。并且需要想清楚为什么会有这个bug，现在如何更好的解决这个bug，以及以后如何防止相同的事情发生 1.3 职业道德 需要了解自己的领域：必须精通设计模式、设计原则、方法（结构化分析、瀑布模型等）、实践（测试驱动开发、面向对象设计、持续集成）、工件（UML图、结构图）。 坚持学习：与时俱进，学习不同的语言 练习：歌手练习声音、医生联系手术缝合、音乐家练习音阶 合作：一起编程、一起计划、一起练习、一起设计、一起合作。也需要学会独处 辅导：辅导新人的同时自己也会受益 了解业务领域：如果不了解业务是写不出好的程序的，需要花时间去了解业务 与顾客保持一致：雇主的问题就是你的问题。必须弄清楚问题，并找到最佳解决方案。 谦虚：专业人士都知道自己也会摔跟头，不要因别人犯错了就对之横加贬损，因为自己很可能就是下一个犯错的人。如果遇到挫折最好的办法就是一笑而过，并在上面长个心眼 第二章 说“不”能就是能，不能就是不能。不要说“试试看”。– 尤达 2.1 对抗角色竭尽所能的捍卫自身的目标，如果无法完成任务就要勇于说“不”，也要勇于对抗，不能为达目的不择手段。“为什么”远不如“事实”重要。为什么是一个细节问题。不能因为各种原因而去省略重要的步骤 2.2 高风险是时刻最要说“不”的时候就是那些高风险的时刻。越是关键时刻，“不”字就越具有价值 2.3 要有团队精神有团队精神的人，不会永远说是。那些事情做得到，那些事情做不到一定要分清楚，做不到的事情一定要讲出来，不能自信过头。 试试看： 没有“试试看”这回事，尝试的意思就是“付出额外的精力” 消极对抗：一辆火车冲向大家，只有你一个人有所察觉，你可以选择自己轻轻抽身到马路边，眼睁睁看着其他人被车碾过，也可以选择大喊：“车来了，快离开” 2.4 说“是”的成本大多数情况下，我们都希望说是。一个故事：部门招标1个月时间做一个系统，然后a公司中标了。b成员负责项目的开发，时间特别赶b成员同意做此项目。他没日没夜的加班，没有全部用硬编码方式完成了这个项目，自己还沾沾自喜的认为干了一件特别了不起的事情。结果之后部门来了个新领导砍掉了这个项目，而去在项目开发期间还加了一些其他的功能。 2.5 如何写出好代码有可能写出好的代码吗？有可能坚守专业主义的精神吗？在项目特别赶的情况下就可以硬编码，不管设计原则吗？其实想要写出好的代码就需要学会如何说“不”。 第三章 说“是”3.1 承诺用语做出承诺的步骤 口头上说 心里认真对待做出的承诺 真正付诸行动 3.1.1 识别“缺乏承诺”的征兆 需要/应当：我需要减肥。有人应当负责某某事情 希望/但愿：希望明天能完成任务。但愿明天有时间 让我们：让我们把事情做完 3.1.2 真正的承诺是怎样的我将在…之前…完成任务。 之所以没有成功，是因为我寄需求于某某去做这件事：比如这件事依赖于其他团队，这种情况应该提前就采取行动，提前预估风险 之所以没有成功，是因为我不太确信是否正的能够完成：即使目标无法完成，你任然要不留余力的前进，离目标要更近一些 之所以没有成功，是因为有些时候我真的无能为力：遇到这种情况的时候要及时向承诺对象发出预警越夸越好！ 3.2 学习如何说“是” “试试”的另一面：试试意味着“仍然有余力可施” 坚守原则：彻底不要出现“如果…或许…”，也不要冒险放弃原则，比如不写测试用例等。专业人士对自己的能力极限了如指掌，清楚的知道如果保持效率的加班能持续多久，也明白要付出的代价 专人人士不需要对所有请求都回答“是”。不过，他们应该努力寻找创新的方法，尽可能做到有求必应。如果给出了肯定的回答，就要使用正式的承诺。 第四章 编码4.1 做好准备 代码必须能够正常工作 代码必须能够帮助你解决客户提出的问题 代码必须和现有的系统结合的天衣无缝 其他程序必须能看懂你写的代码 凌晨3点写出的代码：疲劳的时候千万不要写代码，要确保自己已经将睡眠、健康和生活方式调整到最好的状况 焦虑时写下的代码：焦虑的时候建议可以花点时间让自己安静下来，不要硬逼自己写代码，不然很容易写出以后不得不抛弃的代码 4.2 流态区高效率状态会出现“绝无错误”的误区，这种状态会为了追求所谓的速度理性思考的能力会下降。建议可以结对编程 音乐：听音乐并没有帮助“我”专注编码，反而会消耗一部分脑力资源 中断：中断无法避免，发生这种情况的时候要想一下，自己也可能回去打扰别人，乐于助人的态度就是专注的态度。 4.3 阻塞无法写出代码的时候建议结对编程会有意想不到的收获 创造性输入：广泛阅读各种资料来激励自己去创造 4.4 调试真正调试的时候往往是大于编码的时间的，建议使用“测试驱动开发”可以有效的减少调试时间。医生不喜欢重新打开病人的胸腔去修复此前犯下的错误、律师不喜欢复杂之前搞砸过的案子、同样写代码如果写的更多的是bug也是不专业的 4.5 保持节奏知道何止应该离开一会： 当遇到问题感到疲倦的时候可以离开一会，调整一下精力后才会更好。 4.6 进度延迟管理延迟的诀窍： 早期检测和保持透明 期望：如果计划的是12天开发周期，那么不要期望自己能10天完成，否则期望会导致大麻烦。不要让其他任何人对此抱有期望 盲目冲刺：快速冲刺是做不到的，要明确的告诉老板，让他们不要有这种期望 加班加点：如果没有加班失败的后备方案，建议不要同意接受加班方案 交付失误：明知道没有完成任务却说完成了任务 定义完成：要说清楚完成的情况，是代码编写完成了还是自测完成，还是对接完成了 4.7 帮助 帮助他人： 互相帮助是每个程序员的指责所在，要以能帮助他人为荣 接受让人的帮助：如果有人向你伸出援手，要诚挚接受，心怀感激的接受帮助并诚意合作。不要应该自己压力大而推开伸来的援手。 辅导：向深资导师寻求辅导也是程序员的专业指责 第五章 测试驱动开发5.1 此事已有定论TDD不仅仅是一种用于缩短编码周期的简单技巧。结论很清楚，每个开发人员都需要掌握TDD 5.2 TDD的三项法则 在写好失败的单元测试之前，不要写任何产品代码 只要有一个单元测试失败了就不要写测试代码了，无法通过编译的也是失败的情况 产品代码恰好能够让当前失败的单元测试代码通过即可，无需多写 5.3 TDD的优势 确定性： 代码有任何修改，都需要运行全部测试 缺陷注入率：有不少研究称TDD能显著较低缺陷 勇气：看到有坏味道的代码就可以马上修改，应该TDD给你了勇气 文档：单元测试就是文档，每个单元测试都是一个调用示例 设计：遵循三项法则能够产生一种驱动力，促使你做出松耦合的设计 5.4 局限在某些情况下的三项法则是不切实际的，这种情况很少，如果弊大于利就不要使用它 第六章 练习6.1 引子没门编程语言都它的hello world。这也是第一个练习，练习能够带来协调的开发节奏。无论是搏斗还是编程，速度都来源于练习 6.2 编程柔道场 卡塔：类似于编程小游戏，训练自己 自由练习：不限制形式的搏击 6.3 自身经验拓展 开源：可以在开源网址上去贡献代码 练习的职业道德：不要在上班的时候进行练习，老板的职责不包括避免你的技术落伍 无论何时，专业人士都需要练习。 第七章 验收测试7.1 需求的沟通 过早精细化：经常愿意花大代价追求这种不现实的精确性 不确定原则：需求完成的越精细，就越容易被忽视。业务想看到和开发看到的不一致 预估焦虑：需求是一定会变化的，追求精确性是徒劳的 迟来的模糊性：需求的不确定性会让开发和测试都搞错需求 7.2 验收测试 完成的定义：不同的团队的完成对定义是不相同的 沟通：验收测试的目的是沟通、澄清、精确化。开发方、业务方、测试方都要达成共识 自动化：验收测试都应该自动进行，手动执行的都要考虑成本 额外工作：大量的测试用例不是额外的工作，只有确定了细节指标才可以避免开发误入岐途 验收测试什么时候写，由谁写：通常会交给业务分析人员、QA或者开发人员。如果是开发人员尽量不让写代码的人和开发的人是同一个人 开发人员的角色：开发人员有责任吧验收测试与系统联系起来，让测试通过 测试的协商与被动推进：测试也是普通人，也会犯错误。如果发现测试用例有问题要及时沟通改进 验收测试和单元测试：验收测试是业务方写给业务方的。单元测试是程序员写给程序员的。 图形界面及其他复杂因素：尽可能减少GUI测试，GUI测试越多后期维护的难度就越大 持续集成：持续集成不应该失败，如果失败了团队所有人应该都要停止干活，先让测试先通过 第八章 测试策略8.1 QA应该找不到任何错误开发小组应该把【QA找不到任何错误】当成努力的目标 QA也是团队的一部分：他是团队中需求定义者和特性描述者 需求规约定义者：编写针对极端情况、边界状态、异常路径的测试 8.2 自动化测试金字塔人工探索式测试 &gt; 系统测试 &gt; 集成测试 &gt; 组件测试 &gt; 单元测试 单元测试：程序员自己编写的测试，应该要接近100%的覆盖率，通常要达到90%以上 组件测试： 针对系统的各个组件编写的，封装了业务规则（QA 和业务人员编写） 集成测试：对组件很多的大型系统才有意义 系统测试： 对整个集成完毕的系统进行的自动化测试包含吞吐率和性能测试等 人工探索式测试： 确保在人工操作下表现良好，同时有创造性的尽可能多的找到“古怪之处” 第九章 时间管理9.1 会议会议是必须的、会议浪费了大量的时间 拒绝： 理智的使用时间，谨慎的选择需要参加的会议，礼貌的拒绝一些不必要的会议 离席：如果你明白继续待在会议室会浪费时间可以找合适的机会商量如何离席 确认议程与目标：务必弄清楚议题是什么，花多长时间，取得什么成果 立会：每个人回答不超过1分钟（昨天干了什么，今天打算干什么，遇到了什么问题） 迭代计划会议：会议的节奏要快，每个任务应该限制在5-10分钟之内，如果不够应该另选时间专人专门讨论 迭代回顾和demo展示： 看最新的工作成果的demo可以在最后一周的最后一天下班前45分钟召开，前20分钟回顾，后25分钟展示 争论/反对：如果观点无法在5-30分钟之内达成一致，就永远无法达成一致，出路是用数据说话 9.2 注意力点数注意力是稀缺的资源如果注意力用光了需要1个小时或更多的时间去补充，可以在注意力不够的时候做其他事情。 睡眠：充足的睡眠可以保证好的注意力 咖啡因：适当的咖啡可以保持注意力 恢复： 注意力耗尽可以自己沉思一会，或者小睡一会 肌肉注意力：转移注意力到肌肉注意力上面可以提升心智注意力 9.3 时间拆分和番茄工作法给自己设定25分钟，25分钟之内无论什么干扰都需要在25分钟之后在处理，没4个番茄时间段之后休息30分钟 9.4 要避免的行为专业开发人员会评估每个任务的优先级，排除个人的喜好和需要，按照正式的紧急程度来执行任务 9.5 死胡同比如选择了走不通的技术道路越是坚持浪费的时间就越多，专业的开发人员会保持开放的头脑来听取其他意见 ，即使走到尽头，他们仍然有其他选择 9.6 泥潭专业人员时刻留意显露出来的泥潭，然后各种努力，尽快脱身。在泥潭中继续前进时不易察觉的，要及时修正设计。 第十章 预估10.1 什么是预估开发认为预估是猜测，业务认为预估是承诺 承诺：如果你承诺某事，就必须按时完成，不兑现承诺就是一种欺骗 预估：它不包含任何承诺 暗示性承诺：试试看就是暗示性承诺，尽量不要使用 10.2 PERT一种避免乐观的项目估计的合理方法 10.3 预估任务一组人集合起来重复进行讨论-预估的过程，知道意见统一 亮手指： 用大家的手指精细预估 规划扑克：用成员的扑克点数进行预估 关联预估：任务写在卡片上按照规则进行预估 三元预估： 用三种预估得出概率分布的一种方法 10.4 大数定律把大任务分成多个小任务，分开预估在加总，结果会比单独评估大任务要准确很多 第十一章 压力11.1 避免压力 承诺：如果没有兑现承诺导致业务失败的压力 保持整洁：代码设计的整洁可以避免压力，混乱会降低速度，导致工期延误、承诺失信 危机中的纪律：当困境降临时，不要改好的行为。如：赶工期的时候要保证代码质量 11.2 应对压力 不要惊慌失措：放松下来，多想一下问题，努力寻找就会带来好的结果 沟通：请求团队其他成员或者主管，避免产生惊恐 依靠你的纪律原则：战胜压力的方式就是依靠你已经知道的切实有效的东西-纪律 需求帮助：结对编程可以制止你的精神错乱 第十二章 协作12.1 程序员与人 程序员与雇主：要端正态度，准守规章制度 程序员与程序员 代码个体所有：自己的代码自己维护和其他同事不沟通，拥有大量重复的代码 协作性的代码共有权：打破隔断，相互合作 结对：结对编程是复查代码最好的方式 一定要学会交流–和大家交流 第十三章 团队与项目13.1 只是简单混合吗 有凝聚力的团队 发酵期：一起计划、一起解决问题、一起面对问题、一起搞定一切 团队和项目，何者为先：专业的开发组织把项目分配给有凝聚力的团队 如何管理有凝聚力的团队：可以给团队设置目标值 第十四章 辅导、学徒期与技艺软件学徒期 大师：一半拥有10年以上的从业经验，他们懂得如何领导和协调多个团队，他们是熟练的设计师和架构师 熟练工：能胜任工作，并且精力充沛，他们会学习如何在团队中卓越的工作和成为团队的领导者 学徒/实习生：刚开始进入自己的职业生涯，他们需要熟练工的督导。他们应该至少持续一年的实习期 技艺中包含着价值观、原则、技术、态度、正见。工匠知道何时该说不，他们懂得如何做出承诺，成熟的工匠才能算是专业人士。 ​]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>code</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[五一成都]]></title>
    <url>%2Flife%2Fchengdu.html</url>
    <content type="text"><![CDATA[准备在五一假期来临的前一天决定了去成都。这次的成员有我、妈妈、堂弟。 出行方式两种方式：跟团、自游。考虑了一下时间，也想到不用急急忙忙的安排时间去玩。于是确定了座火车去成都。 出现路线初略计划路线: 春熙路 &gt; 锦里 &gt; 宽窄巷子 &gt; 青城山 &gt; 都江堰。之后沙大大贡献了一张手写攻略。将路线改为春熙路 &gt; 锦里 &gt; 宽窄巷子 &gt; 熊猫基地 &gt; 青城山 &gt; 都江堰。 车票问题路线确定好后就是购买车票，这个时间订票就比较困难了，看了一圈12306都没有合适的票。之后看到有个火车票在17:40出发，11:47到达成都东站(买票时是成都东站，订票成功之后就是成都站)，于是和妈妈沟通之后果断购买了该车次的火车票。 住宿问题火车票定好之后，就是住宿的问题，由于5月1日晚上11:47才到站。所以必须先定好住宿的地方，下火车之后就可以直接休息了。订票的几个关键点就是东站附近，价格适中，我们三个人住宿开始计划的是订两个房间，我和我堂弟一间，我妈妈一间。然后就开始下载app（携程旅行、美团），在里面搜索符合自己条件的酒店/民宿。花了两个小时也还是没有找到合适的。 开始准备前由于票是定在下午5点40的，因此上午还是有大把的时间可以准备的。于是上午我整理了一下房间，把该洗的衣服都洗好了。快10点多的时候我堂弟就拉着行李箱抵达到了我住的地方，12点左右的时候我妈妈带了一包炒黄豆（吃多了放屁的那种），还有一包炸熟了的腊肉和一箱牛奶出现在了楼下。（前一天晚上就跟我妈妈说不要带东西，去玩的时候带东西背着很累，作为老一辈勤俭持家的典范，她还是义无反顾的带上了），我也是像往常一样数落了一番。 看房子一看时间还早我们也没有吃午饭，于是商量之后决定先去买房子的地方（三亚湾）去看下，到了三亚湾去吃了个沙县小吃，然后围着还没修好的小区外面走了一圈。还没修好的小区看着总觉得破破烂烂的，工地旁边的车子停放的乱七八糟，凹凸不平的马路也没有休整，只有快交房的3期才看着像房子的样子。绕着整个小区走一圈还是有点费劲的，何况正午的太阳正是最热的时候，我的衬衫后背都全部汗湿了。买了瓶水之后我们就回到我住的地方了，休息了半个多小时（玩手机）我们就是出发去北站坐火车了。 火车出发了在车站玩了1小时的手机之后，17:40分的时候我们从重庆北站正式出发了。之后就是长达5小时的火车之旅，一路上有人下车，有人上车。有人侃侃而谈，有人沉默不语。一会有美丽的风景从眼前呼啸而过，一会有深不可测的隧道让人短暂沉默。在车上除了玩手机，就是把头撇向窗口。天黑了之后就只剩下玩手机和焦急看看还有多久才能到达终点。大概8点的时候我们拿出了在楼下买好的酸菜面，泡上了我妈妈炸好的腊肉也加了一些炒好的黄豆。于是我正儿八经的坐在椅子上津津有味的吃了起来，我估计坐在我对面的一个大兄弟一定也想来一碗。在吃的时候我问我堂弟和妈妈要吃吗？他们都说不饿，于是我就自己先泡了吃。吃了一半的时候我堂弟也去泡了面。我问我妈妈要吃吗，她还是说不饿。在堂弟泡好快吃的时候我说“妈妈我给你泡吧!”, 这次她没有说不饿，于是我去加好了水（准备把腊肉放在里面一起泡的，她说干吃好吃一些），泡好之后她也静静有味的吃了起来。现在想起来她是不是早就饿了，还是其他什么原因呢？我想不明白。我们打扫完小桌子之后，又安静的等待火车抵达的那一刻了。9点左右对面的大兄弟在咨询了盒饭25元一份之后果断的选择了7元一碗的泡面，他在津津有味的吃泡面的时候，却不知道吃饱了的我也是一点也吃不下了。我看向了黑漆漆的窗外，好像没有方向一样，不知道终点在哪里。 东站？晚上11点47我们抵达了终点成都站，下车后我妈妈开始拍照片。我就给我们定好的名宿老板打电话。“你好，我到成都东站了。”，“好的，你们直接在a酒店来”，“是b酒店吗？”，“不是”，“是c d e酒店吗？”，“不是，你们是在成都东站吗”，“稍等我看下地图”。好家伙，我们总算发现火车抵达的是成都站，住宿的地方是在成都东站。问了下老板怎么去东站，老板说假期的地铁往后延迟了，可以去做地铁，还不算晚。本来我们应该飞一般的奔向地铁的，奈何我们当中没有一个人着急，慢慢悠悠的走到的地铁里面，支付宝切换为成都扫码后就上了地铁。我堂弟没满18岁用不了支付宝去买票花了10分钟（其实没有这么久，可能只有5分钟吧！可是我分明觉得买了很久，哈哈～～～）。坐上车的那一刻，突然感觉终点好远，之后就是长达1小时的地铁之旅。 住宿在12点的时候我们实实在在到达了终点，名宿老板带我们过了一个红绿灯和一条马路之后就到小区门口了，进小区大门的时候还需要登记刷脸才能入住，刷脸还总是不过，我骂了句垃圾系统，大概也是10分钟左右才进到小区里面吧！洗漱之后就是快速的躺下入睡 了。我堂弟还睡的比较香，我还是日常失眠，睡不着，隔壁有人神经病一样的敲墙壁，迷迷糊糊的不知道从几点开始还是睡着了几个小时（五一假期的第一天过去了）。 熊猫基地第二天醒来的洗漱完成之后，处理碗肥肠粉就就去做公交车了。有直达熊猫基地的车10元每人，做这个车子的人还是挺多的，一路上都没有座位，这是一趟直达的公交车，路途中间一共停留了两次。在快要到熊猫基地的时候堵了一会车，那个时候已经9点多了。在快要下公交车的时候就已经看到人山人海了，之后我们就找入口进去。在进去的时候整个广场上都排满了，人挤人。这是我第一次经历这么多人排队的时候。之前最多的时候也就是排队买票，但是这次真的是特别的挤。人太多了工作人员就会进行限流，拦住人群让前面的人先走一会。每次放人进去的时候每个人都想快一步进去，就会听到有人说“在挤就要发生踩踏事件了，不要挤了”。在这样经历了3次之后，我们总算进到了正式排队的地方（很多栏杆隔开像迷宫迷宫一样的广场，用来限流）。之后等待了20多分钟，总算是进到了熊猫基地里面。在里面看了一下官方推荐的地图就先去了天鹅湖围着天鹅湖走了一圈，看到了一只天鹅，我妈妈去拍了一张照片。这个时候的天气已经热起来了，我的衬衫已经汗湿了紧紧的贴着我的皮肤。而我们也满怀期待的在这个陌生的环境行走，想要去看大熊猫，小熊猫。 结束]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[审核流学习]]></title>
    <url>%2Fjava%2Fview_flow.html</url>
    <content type="text"><![CDATA[一、案例分析 有两个审核组（审核组1、审核组2）、每组有两个审核成员（审核组1- a，b。审核组2- c，d） 当有数据需要审核初始化审核组的时候，如数据a需要审核组1和审核组2进行审核。则初始化两条审核信息 初始数据只有审核组1的成员可以查看并且审核，审核组1审核通过之后审核组2才能查看和审核数据到审核数据。审核组2审核的时候，审核组1只能查看并不能操作审核数据。 当前用户去查询列表的时候，需要先去查找自己的数据权限。如果有权限则进行展示。（代办事项） sql初始化成功之后，进行代码开发。 二、接口设计2.1 创建审核流程接口（初始化审核流） 逻辑：根据审核类型关联flow_review_rule、flow_rule_group、flow_review_group获取审核类型所需要的审核组并创建审核流程 入参: 审核唯一编码、审核类型、用户ID… 2.2 流程列表查询接口（代办事项） 入参: 产品编码、用户ID、开始时间和结束时间 逻辑： 通过用户ID去查询用户所在的审核组，如果没有审核组则直接返还空数据 通过审核组和业务类型分页获取当前用户可以审核的流程审核表里面的数据 用业务类型获取业务系统的dubbo接口 通过dubbo接口和分页获取的审核唯一编码泛化调用业务系统，获取业务系统的列表数据 组装审核信息后返还给前端 通用的业务审核列表。只是展示需要审核的数据 2.3 流程审核查询（查看审核情况） 入参: 审核唯一编码、业务类型 逻辑: 通过审核唯一编码查询审核流程表和审核流程记录表并组装数据后返回给前端 2.4 流程审核接口（判断是否有审核权限） 入参: 审核唯一编码、审核人员ID、审核结果、驳回资料等、当前审核流程ID、审核类型 逻辑： 判断审核情况是通过还是拒绝，如果是拒绝则通过审核类型调用业务系统（用户中心or订单中心）审核接口进行拒绝操作。 如果是通过则判断当前审核流程是否是最后一个审核流程，如果是最后一个流程则通过审核类型调用业务系统（用户中心or订单中心）审核接口进行审核。 修改流程表里面当前流程流状态 在审核流程记录表里面添加记录 审核通过、审核拒绝时调用 2.5 流程数据修改接口（判断是否有权限修改）三、数据库表设计1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586- 用户和组的关联表create table flow_group_user( id bigint(20) auto_increment key comment &apos;自增ID&apos;, group_id bigint(20) not null comment &apos;组ID&apos;, user_id bigint(20) not null comment &apos;用户ID&apos;, create_user_id bigint(20) comment &apos;创建用户ID&apos;, create_date timestamp null default current_timestamp comment &apos;创建时间&apos;, modify_user_id bigint(20) comment &apos;修改用户ID&apos;, modify_date timestamp null default current_timestamp on update current_timestamp comment &apos;修改时间&apos;) comment &apos;用户和组的关联表&apos;;-- 审核组create table flow_review_group( id bigint(20) auto_increment key comment &apos;自增ID&apos;, name varchar(100) not null comment &apos;审核组名称&apos;, `desc` varchar(300) default null comment &apos;审核组名称&apos;, create_user_id bigint(20) comment &apos;创建用户ID&apos;, create_date timestamp null default current_timestamp comment &apos;创建时间&apos;, modify_user_id bigint(20) comment &apos;修改用户ID&apos;, modify_date timestamp null default current_timestamp on update current_timestamp comment &apos;修改时间&apos;) comment &apos;审核组&apos;;-- 审核表（一条审核记录对应多条审核操作操作记录）为了展示所有的审核详情create table flow_review( id bigint(20) auto_increment key comment &apos;自增ID&apos;, review_no bigint(20) not null comment &apos;审核码&apos;, rule_id bigint(20) not null comment &apos;规则ID&apos;, review_status varchar(2) not null comment &apos;审核状态 0-待审核,1-审核中,2-审核成功,3-审核失败&apos;, create_user_id bigint(20) comment &apos;创建用户ID&apos;, create_date timestamp null default current_timestamp comment &apos;创建时间&apos;, modify_user_id bigint(20) comment &apos;修改用户ID&apos;, modify_date timestamp null default current_timestamp on update current_timestamp comment &apos;修改时间&apos;) comment &apos;审核表&apos;;-- 审核操作记录表create table flow_review_operate( id bigint(20) auto_increment key comment &apos;自增ID&apos;, review_no bigint(20) not null comment &apos;审核码&apos;, review_parent_id bigint(20) not null comment &apos;审核父ID&apos;, review_status varchar(2) not null comment &apos;审核状态 0-待审核,1-审核成功,2-审核失败&apos;, `desc` varchar(300) default null comment &apos;审核描述&apos;, review_group_id bigint(20) not null comment &apos;审核组ID&apos;, review_user_id bigint(20) not null comment &apos;审核用户ID&apos;, create_user_id bigint(20) comment &apos;创建用户ID&apos;, create_date timestamp null default current_timestamp comment &apos;创建时间&apos;, modify_user_id bigint(20) comment &apos;修改用户ID&apos;, modify_date timestamp null default current_timestamp on update current_timestamp comment &apos;修改时间&apos;) comment &apos;审核操作记录表&apos;;-- 审核规则create table flow_review_rule( id bigint(20) auto_increment key comment &apos;自增ID&apos;, name bigint(50) not null comment &apos;名称&apos;, `type` varchar(2) not null comment &apos;类型: 0-用户,1-订单,2-实名制&apos;, `desc` varchar(300) default null comment &apos;描述&apos;, request_type varchar(2) not null comment &apos;请求类型1-dubbo,2-http&apos;, class_name varchar(300) default null comment &apos;类名&apos;, class_method varchar(300) default null comment &apos;类方法&apos;, class_method_args varchar(300) default null comment &apos;类方法参数&apos;, create_user_id bigint(20) comment &apos;创建用户ID&apos;, create_date timestamp null default current_timestamp comment &apos;创建时间&apos;, modify_user_id bigint(20) comment &apos;修改用户ID&apos;, modify_date timestamp null default current_timestamp on update current_timestamp comment &apos;修改时间&apos;) comment &apos;审核规则&apos;;-- 规则和组关联表create table flow_rule_group( id bigint(20) auto_increment key comment &apos;自增ID&apos;, group_id bigint(20) not null comment &apos;组ID&apos;, rule_id bigint(20) not null comment &apos;规则ID&apos;, is_modify varchar(2) not null comment &apos;是否修改0-不修改, 1-修改&apos;, is_review varchar(2) not null comment &apos;请求审核0-不审核, 1-审核&apos;, create_user_id bigint(20) comment &apos;创建用户ID&apos;, create_date timestamp null default current_timestamp comment &apos;创建时间&apos;, modify_user_id bigint(20) comment &apos;修改用户ID&apos;, modify_date timestamp null default current_timestamp on update current_timestamp comment &apos;修改时间&apos;) comment &apos;规则和组关联表&apos;;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java flow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单的权限管理小工具详细设计]]></title>
    <url>%2Fjava%2FwebCenter2.0.html</url>
    <content type="text"><![CDATA[一、项目结构123456789101112// 通用的核心类webcenter-core// 提供的接口webcenter-api// 只要的业务逻辑，项目通过集成core、api、admin即可实现简单的单系统权限框架webcenter-admin// 审核流，项目集成core、api、admin、review接口实现审核流功能webcenter-review// 控制台，项目通过集成core、api、admin、console即可实现web中心的单点登录功能webcenter-console// 提供ui页面webcenter-webpage 二、项目流程 一个用户多个角色 一个部门，多个角色(包含当前部门和当前部门子部门的所有权限) 一个用户一个部门，一个角色(用户拥有所有角色的并集权限) 一个角色多个菜单和权限 三、功能点webcenter-admin 权限管理 用户管理 角色管理 菜单管理 流程审核 webcenter-console系统管理用于给系统初始化client_id等参数，其它自系统必须通过初始化的参数进行系统的配置。 权限管理主要是进行接口的管理，给进行权限的控制，防止没有权限的用户进行接口的攻击 用户管理用户体系都用同一套。用户通过单点登录获取用户和权限信息等。 角色管理给角色可以添加不同系统的不同菜单，和不同的权限 菜单管理菜单管理实现增加系统ID参数，通过系统ID区分不同的系统有不同的菜单。 四、实现方式 通过导入依赖和增加数据库即可实现，简单的登陆注册、权限管理等 以一种插件的方式去集成 五、接口详细设计5.1 webcenter-admin用户的增删改查 角色的增删改查 菜单的增删改查 权限的查询（增加通过系统启动的时候初始化到数据库） 登录接口 退出接口 密码修改接口 菜单查询接口 验证码获取接口 5.2 webcenter-console单点登录接口(登录后返回用户的权限、菜单等信息) 退出接口 系统的增删改查接口 菜单通过系统区分 用户角色的权限分配区分系统 5.3 webcenter-review]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java springBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发中一些常见的需要避免的问题]]></title>
    <url>%2Fjava%2FcodeIssue.html</url>
    <content type="text"><![CDATA[一、接口重放问题1.1 影响同一个接口调用多次（请求原封不动的多次发送）导致出现重复数据。 1.2 解决办法利用时间戳(判断时间必须当前时间的60s以内)＋随机串（通过redis进行缓存校验查询，判断随机串是否出现过） 二、平行越权问题2.1 影响攻击者可以执行同级别的其它用户可以执行的权限，比如攻击者可以自己登陆之后修改其它用户的信息等 2.2 解决办法每个阶段都通过cookie和sessin等进行用户身份的校验 三、短信轰炸问题3.1 影响 公司短信发送多余，产生经济损失。2. 造成用户收到垃圾短信 3.2 解决办法短信频率限制（1分钟获取一次等），添加图形验证码（防止爬虫通过接口发送验证码） 四、铭感信息隐藏隐藏手机号码、邮箱等敏感信息 五、分布式锁5.1 数据库锁5.1.1 乐观锁乐观锁一般都乐观的认为数据不会被锁， 在读取数据的时候把数据的版本号一起读出，更新数据的时候使用数据版本号进行数据的更新，如果更新失败了则重新读取数据后再次更新如: 1update tablesname set data = #&#123;data&#125;, version = #&#123;version&#125; +1 where id = #&#123;id&#125; and version = #&#123;version&#125; 也是增加一个字段用来保存时间戳，查询数据的时候把时间戳也查询出来。更新的是判断时间戳是否是一致的 5.1.2 悲观锁悲观锁是悲观的认为所有的数据都会出现被锁的情况，故有表锁、行锁、读锁、写锁等，直接数据库层面的锁属于重量级的锁 5.2 redis锁利用redis的setnx去增加锁(setnx只有当key在redis中不存在的时候才能设置成功)，通过expire去释放锁来实现。在代码中判断setnx是否成功，如果成功了则表示锁是空闲状态，否则锁处于占用状态 l 5.3 redission5.4 zookeeper六、分布式事务]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java一些常用的类]]></title>
    <url>%2Fjava%2Fcommom.html</url>
    <content type="text"><![CDATA[BeanCopier拷贝两个对象,网上资料显示: BeanCopier的性能是PropertyUtils (apache-common)的504倍。PropertyUtils的性能是BeanUtils(apache-common)的1.71倍,因此对象的拷贝尽量使用BeanCopier。注意属性没有提供set方法，只是提供了get方法是会报错的，无法复制属性 1234// 拷贝对象， 在create对象的时候会出现性能瓶颈，可以将创建的过程放在缓存中，方便直接获取BeanCopier copier = BeanCopier.create(FromEntity.class, ToEntity.class, false); ToEntity to = new ToEntity(); copier.copy(from, to, null); 内存分页1234567891011// 总条数int totalRow = 101;// 每页记录数int pageSize = 20;// 总页数int totalPage = (totalRow - 1) / pageSize + 1;for(int i = 0; i&lt; totalPage; i++) &#123; int start = i * pageSize; int end = Math.min((i + 1) * pageSize, totalRow);&#125; AOP注解1234567891011121314151617// @Before 切入点开始处切入内容// @After 切入点结尾处切入内容// @AfterReturning 切入点return内容之后切入内容// @Around在切入点前后切入内容，并自己控制何时执行切入点自身的内容// @AfterThrowing用来处理当切入内容部分抛出异常之后的处理逻辑try&#123; try&#123; doBefore();//对应@Before注解的方法切面逻辑 method.invoke(); &#125;finally&#123; doAfter();//对应@After注解的方法切面逻辑 &#125; doAfterReturning();//对应@AfterReturning注解的方法切面逻辑 &#125;catch(Exception e)&#123; doAfterThrowing();//对应@AfterThrowing注解的方法切面逻辑 &#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java base</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些面试题]]></title>
    <url>%2Fstudy%2Finterview.html</url>
    <content type="text"><![CDATA[一、索引问题1.1 从数据结构角度 B+Tree索引: 适用于查找范围内的数据 hash索引: 适用于随机访问的场合，查找每条数据的时间都是一样的。 Fulltext索引: 查找文本中的关键字。 R-Tree索引: 查询比较接近的数据 1.2 物理存储角度 聚集索引: 表数据按照索引的顺序来存储 InnoDB的主键使用的就是聚簇索引，MyISAM不管是主键还是二级索引都是使用的非聚簇索引。 非聚集索引: 表数据存储顺序与索引的顺序无关 1.3 逻辑角度 主键索引: 普通索引和单列索引: 唯一的任务就是加快数据的访问速度 多列索引: 符合最左原则: key index(a,b,c)相当于创建了三个索引a,ab,abc。不支持bc索引。 唯一索引: 允许有空值，索引列的值必须唯一 空间索引 1.2 聚簇索引二、Mysql的引擎对比2.1 InnoDB支持事务、支持外键、支持崩溃修复能力和并发控制、支持行级锁和表级锁 2.2 MyISAM插入速度快、空间和内存使用比较低、只支持表级锁。不支持事务，安全性不高 三、类加载器单独学习: https://gaoqisen.github.io/java/classloader.html 四、HashMap原理 通过key的hashCode经过扰动函数处理过后得到hash值 12345678// 扰动函数: 使用扰动函数可以减少碰撞，防止不同的hashcode的高位不同但低位相同导致的hash冲突static final int hash(Object key) &#123; // key.hashCode(): 返回的就是散列值就是hashcode // ^: 的意思就是按位异或 // &gt;&gt;&gt;: 无符号右移，忽略符号位，空位用0补齐 int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 通过(n-1)&amp;hash判断当前元素存在的位置，如果当前位置已经存在值则对比key是否一样，如果一样就替换值，如果不一样就通过拉链法解决冲突。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // 判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，这里的相同指的是hashCode以及equals if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 链表长度大于8转换为红黑树进行处理 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // key已经存在直接覆盖value if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // // 插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; 拉链法: 将链表和数组结合，如果遇到hash冲突就将值放到链表中 JDK1.8: 当链表的长度大于阀值(默认8)之后，将链表转为了红黑树减少搜索时间。 五、排序算法原理Arrays.sort(list.toArray());源码 12345678public static void sort(Object[] a) &#123; if (LegacyMergeSort.userRequested) // 归并排序 legacyMergeSort(a); else // Tim优化后的归并排序 ComparableTimSort.sort(a, 0, a.length, null, 0, 0);&#125; 5.1 legacyMergeSort(a)源码12345/** To be removed in a future release. 在以后的版本中会删除*/ private static void legacyMergeSort(Object[] a) &#123; Object[] aux = a.clone(); mergeSort(aux, a, 0, a.length, 0); &#125; mergeSort(aux, a, 0, a.length, 0);归并算法源码 123456789101112131415161718192021222324252627282930313233343536373839404142@SuppressWarnings(&#123;"unchecked", "rawtypes"&#125;) private static void mergeSort(Object[] src, Object[] dest, int low, int high, int off) &#123; int length = high - low; // 如果数组长度小于INSERTIONSORT_THRESHOLD(7),直接用插入排序 // Insertion sort on smallest arrays if (length &lt; INSERTIONSORT_THRESHOLD) &#123; for (int i=low; i&lt;high; i++) for (int j=i; j&gt;low &amp;&amp; ((Comparable) dest[j-1]).compareTo(dest[j])&gt;0; j--) swap(dest, j, j-1); return; &#125; // 归并排序 // Recursively sort halves of dest into src int destLow = low; int destHigh = high; low += off; high += off; int mid = (low + high) &gt;&gt;&gt; 1; mergeSort(dest, src, low, mid, -off); mergeSort(dest, src, mid, high, -off); // If list is already sorted, just copy from src to dest. This is an // optimization that results in faster sorts for nearly ordered lists. if (((Comparable)src[mid-1]).compareTo(src[mid]) &lt;= 0) &#123; System.arraycopy(src, low, dest, destLow, length); return; &#125; // Merge sorted halves (now in src) into dest for(int i = destLow, p = low, q = mid; i &lt; destHigh; i++) &#123; if (q &gt;= high || p &lt; mid &amp;&amp; ((Comparable)src[p]).compareTo(src[q])&lt;=0) dest[i] = src[p++]; else dest[i] = src[q++]; &#125; &#125; 5.2 ComparableTimSort.sort源码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// 本质是插入排序和归并排序的结合体 // 1.是稳定的排序算法，最坏时间复杂度为O(N*log(N))// 2.对小块进行插入排序，然后进行归并排序// TimSort算法是由Tim Peters在2002提出并首先实现在了phtyon中，是结合了合并排序（merge sort）和插入 排序（insertion sort）的一种高效稳定的算法。算法原理看这里 https://blog.csdn.net/yangzhongblog/article/details/8184707static void sort(Object[] a, int lo, int hi, Object[] work, int workBase, int workLen) &#123; // 保证数组的合法性 assert a != null &amp;&amp; lo &gt;= 0 &amp;&amp; lo &lt;= hi &amp;&amp; hi &lt;= a.length; int nRemaining = hi - lo; // 对于只有0|1个元素的数组，不需要进行排序 if (nRemaining &lt; 2) return; // Arrays of size 0 and 1 are always sorted // If array is small, do a "mini-TimSort" with no merges // 如果数组长度小于32个则调用binarySort，二分插入排序 if (nRemaining &lt; MIN_MERGE) &#123; // 计算数组头部递增或递减的的序列长度，如果是递减，则翻转，保持升序 int initRunLen = countRunAndMakeAscending(a, lo, hi); // 使用二叉插入排序对在initRunLen后的元素进行排序 binarySort(a, lo, hi, lo + initRunLen); return; &#125; /** * March over the array once, left to right, finding natural runs, * extending short natural runs to minRun elements, and merging runs * to maintain stack invariant. */ ComparableTimSort ts = new ComparableTimSort(a, work, workBase, workLen); // 计算最小run的长度 int minRun = minRunLength(nRemaining); do &#123; // Identify next run // 计算当前排序的run的长度，如果为递减数组则翻转 int runLen = countRunAndMakeAscending(a, lo, hi); // If run is short, extend to min(minRun, nRemaining) // 如果当前run的长度小于minRun，则进行扩展，在扩展过程中使用二叉排序来排序扩展的的元素 if (runLen &lt; minRun) &#123; int force = nRemaining &lt;= minRun ? nRemaining : minRun; binarySort(a, lo, lo + force, lo + runLen); runLen = force; &#125; // Push run onto pending-run stack, and maybe merge // 将此run放入栈中 ts.pushRun(lo, runLen); // 执行合并逻辑，合并的时候也做了一些优化 ts.mergeCollapse(); // Advance to find next run lo += runLen; nRemaining -= runLen; &#125; while (nRemaining != 0); // Merge all remaining runs to complete sort assert lo == hi; // 保证最后的run都被合并 ts.mergeForceCollapse(); assert ts.stackSize == 1; &#125; binarySort原码(二叉插入排序) 12345678910111213141516171819202122232425262728293031323334353637383940414243private static void binarySort(Object[] a, int lo, int hi, int start) &#123; assert lo &lt;= start &amp;&amp; start &lt;= hi; if (start == lo) start++; for ( ; start &lt; hi; start++) &#123; Comparable pivot = (Comparable) a[start]; // Set left (and right) to the index where a[start] (pivot) belongs int left = lo; int right = start; assert left &lt;= right; /* * Invariants: * pivot &gt;= all in [lo, left). * pivot &lt; all in [right, start). */ while (left &lt; right) &#123; int mid = (left + right) &gt;&gt;&gt; 1; if (pivot.compareTo(a[mid]) &lt; 0) right = mid; else left = mid + 1; &#125; assert left == right; /* * The invariants still hold: pivot &gt;= all in [lo, left) and * pivot &lt; all in [left, start), so pivot belongs at left. Note * that if there are elements equal to pivot, left points to the * first slot after them -- that's why this sort is stable. * Slide elements over to make room for pivot. */ int n = start - left; // The number of elements to move // Switch is just an optimization for arraycopy in default case switch (n) &#123; case 2: a[left + 2] = a[left + 1]; case 1: a[left + 1] = a[left]; break; default: System.arraycopy(a, left, a, left + 1, n); &#125; a[left] = pivot; &#125; &#125; 六、ConcurrentHashMap原理1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public V put(K key, V value) &#123; return putVal(key, value, false); &#125; /** Implementation for put and putIfAbsent */ final V putVal(K key, V value, boolean onlyIfAbsent) &#123; // 不允许插入空值，否则报错空指针 if (key == null || value == null) throw new NullPointerException(); // 计算key的hash值 int hash = spread(key.hashCode()); int binCount = 0; // 更新元素是使用的CAS机制，需要不断尝试，直到成功为止 for (Node&lt;K,V&gt;[] tab = table;;) &#123; // f：链表或红黑二叉树头结点，向链表中添加元素时，需要synchronized获取f的锁。 Node&lt;K,V&gt; f; int n, i, fh; // 判断Node[]数组是否初始化，没有则进行初始化操作 if (tab == null || (n = tab.length) == 0) tab = initTable(); // 通过hash定位Node[]数组的索引坐标，是否有Node节点，如果没有则使用CAS进行添加（链表的头结点），添加失败则进入下次循环。 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; // 检查到内部正在移动元素（Node[] 数组扩容） else if ((fh = f.hash) == MOVED) // //帮助它扩容 tab = helpTransfer(tab, f); else &#123; V oldVal = null; // 锁住链表或红黑二叉树的头结点 synchronized (f) &#123; // 判断f是否是链表的头结点 if (tabAt(tab, i) == f) &#123; // 如果fh&gt;=0 是链表节点 if (fh &gt;= 0) &#123; binCount = 1; // 遍历链表所有节点 for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; // 如果节点存在，则更新value if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; // 不存在则在链表尾部添加新节点。 Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; // TreeBin是红黑二叉树节点 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; // 添加树节点 if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; // 如果链表长度已经达到临界值8 就需要把链表转换为树结构 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; // 将当前ConcurrentHashMap的size数量+1 addCount(1L, binCount); return null; &#125; 判断Node[]数组是否初始化，没有则进行初始化操作 通过hash定位Node[]数组的索引坐标，是否有Node节点，如果没有则使用CAS进行添加（链表的头结点），添加失败则进入下次循环。 检查到内部正在扩容，如果正在扩容，就帮助它一块扩容。 如果f!=null，则使用synchronized锁住f元素（链表/红黑二叉树的头元素） 4.1 如果是Node(链表结构)则执行链表的添加操作。 4.2 如果是TreeNode(树型结果)则执行树添加操作。 判断链表长度已经达到临界值8 就需要把链表转换为树结构。 七、秒杀库存问题 前端限制(防止普通用户): 用户只能请求一次，一次之后按钮变灰。限制用户只能在10分钟之内只能提交一次等，大概拦住了80%的请求。 防止接口重复调用(防止程序员写for循环): 同一个uid限制访问频度，60秒内请求的接口返回相同的页面(页面缓存) 后端限流: 异步处理、消息队列、并发限制.对于超过系统负载的请求，可以选择直接拒绝，以此来对系统进行保护，保证在极限压力的情况下，系统有合理范围内的处理能力 下单减库存: 用户下单的时候就减库存，这种情况会出现用户下单了但是不支付的情况 付款减库存: 用户支付之后减库存，这种情况会出现多个人下单了，但是付款的时候没有库存了。 预扣库存: 用户下单之后预先减去库存，之后提示用户2分钟之内进行付款，如果不支付就回滚数据不进行库存减少。 防止多并发时数据错误问题: 修改库存的时候，判断当前取回的库存在修改的时候是否一致。“Compare And Set”（CAS） 八、数据库锁悲观锁: 认为别的线程会修改值 乐观锁: 认为别的线程不会修改值（cas） 如何防止锁表，数据库死锁问题 九、如何自己实现削峰填谷、限流等令牌桶算法 十、事务级别 未提交 已提交 可重复读 序列化 十一、消息队列积压500万条数据如何处理只能操作临时扩容，以更快的速度去消费数据 十二、方法重写的注解的区别 一般来说，写与不写没什么区别，JVM可以自识别 写的情况下：即说明子类要覆盖基类的方法，基类必须存在方法 （控制类型public,protected，返回值，参数列表类型）与子类方法完成一致的方法，否则会报错（找不到被Override的方法）。 在不写@Override注解的情况下，当基类存在与子类各种条件都符合的方法时实现覆盖；如果条件不符合时，则是当成新定义的方法使用。 所以如果想覆盖基类方法时，最好还是写上@Override注解，这样有利于编译器帮助检查错误 十三、Springboot和Spring的区别SpringBoot是在Spring上面封装的，简化了xml配置，使开发、测试、部署更加方便。SpringBoot有如下特点： 嵌入式tomcat等 提供starters简化构建配置 尽可能自动化配置spring 使用java -jar 独立运行jar SpringBoot是基于Spring的一套快速开发整合包。 十四、Web攻击14.1 DDOS分布式拒绝服务攻击（distributed denial-of-service attack，DDoS）分布式拒绝服务攻击、 发送大量的正确请求到服务端，让服务端收到海量的数据后处理不过来导致服务无法使用。 14.2 CSRF跨站请求伪造（Cross-site request forgery，CSRF）。跨站点请求伪造。通过一些技术手段欺骗用户的浏览器去访问一个自己曾经认证过的网站并运行一些操作（如发邮件，发消息，甚至财产操作如转账和购买商品）。由于浏览器曾经认证过，所以被访问的网站会认为是真正的用户操作而去运行。这利用了web中用户身份验证的一个漏洞：简单的身份验证只能保证请求发自某个用户的浏览器，却不能保证请求本身是用户自愿发出的。 防范措施: 检查referer首部字段，检查这个首部字段并要求请求来源的地址在同一个域名下 添加校验token，不通过cookie进行校验 输入验证码，重要接口增加验证码验证，用户输入正确验证码后方可操作，让用户明白自己当前的操作。 14.3 XSS攻击跨站脚本攻击（Cross-Site Scripting, XSS），可以将代码注入到用户浏览的网页上，这种代码包括 HTML 和 JavaScript。是最普遍的Web应用安全漏洞。这类漏洞能够使得攻击者嵌入恶意脚本代码到正常用户会访问到的页面中，当正常用户访问该页面时，则可导致嵌入的恶意脚本代码的执行，从而达到恶意攻击用户的目的。 防范措施: 将cookie设置为HttpOnly可以防止JavaScript脚本调用 过滤特殊字符,例如将script转为其它字符 14.4 SQL注入服务器上的数据库运行非法的 SQL 语句，主要通过拼接来完成 防范措施: mysql关键字过滤，不允许用户输入sql关键字 使用预编译sql语句，没有拼接的过程 mybatis使用#{}传入数据 十五、Redis的List是如何实现的是使用的链表数据结构存储的数据。 版本3.2之前 压缩列表ziplist 双向列表linked list 版本3.2之后 快速列表quicklist 十六、程序运行慢生产如何调试 查看数据库是否有锁表，如果有锁表排查是否是程序导致的，并kill掉锁表线程 查看服务器CPU是否过高，如果CPU过高可以通过jtask查看 判断程序是一直慢还是突然慢，通过nginx日志筛选是否有第三方恶意工具网站 排查程序是sql执行慢，还是程序逻辑处理太多。sql慢就进行sql优化，程序逻辑太多的话就进行缓存处理 十七、集群环境中功能Session如何实现共享 利用公共的区域存储session例如用redis存储session实现sesison共享 多台服务器的sesison进行同步比如多台tomcat的session进行同步 利用新的机制鉴权，不用cookie-session机制。 十八、什么是线程安全，非线程安全多个线程去操作同一个数据不会出现问题叫线程安全，会出现问题就是非线程安全 https://github.com/gaoqisen/notes/blob/master/java/threadSecurity.md 十九、说一下观察者模式https://github.com/gaoqisen/notes/blob/master/patterm/observe.md 二十、Vue原理双向数据绑定的mvvm模式 https://github.com/gaoqisen/notes/blob/master/web/vueBase.md 二十一、范式第一范式: 数据库表中的任何属性都是原子性的, 不可再分 第二范式:数据表里的非主属性都要和这个数据表的候选键有完全依赖关系. 第三范式: 在满足 2NF 的同时, 数据表中的非属性与候选键不存在传递依赖性. 二十二、参考 hashmap: https://zhuanlan.zhihu.com/p/21673805 Arrays.sort: https://my.oschina.net/u/3286119/blog/2055991 ConCurrentHashMap: https://www.jianshu.com/p/d10256f0ebea redis list: https://zhuanlan.zhihu.com/p/102422311 范式: https://bigmorebig.github.io/2019/08/07/SQL%E8%BF%9B%E9%98%B6/ 攻击: https://github.com/CyC2018/CS-Notes/blob/master/notes/%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF.md]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>study</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java类加载的学习]]></title>
    <url>%2Fjava%2Fclassloader.html</url>
    <content type="text"><![CDATA[一、概述类加载过程 加载: 通过类加载器查找和导入Class文件 链接: 把类的二进制数据合并到JRE中 验证：检查载入class文件数据的正确性，为了确保当前的Class文件符合java虚拟机的要求，并且不会危害虚拟机自身的安全（文件格式验证、元数据验证、字节码验证、符号引用验证） 准备：给类变量(被static修饰的变量)分配内存,实例变量在实例变量初始化的时候会随对象一起分配在堆中。 解析: 将符号引用(javap反编译的就是符号引用)转化为直接引用(是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄)的过程 初始化: 类的静态变量，静态代码块等执行，类的构造器初始化操作等。虚拟机定义了5种会触发初始化的场景。 遇到new、getstatic、putstatic或invokestatic这四条字节码指令时，如果类没有进行初始化，则要先触发初始化； 使用java.lang.reflect包中的方法对类进行反射调用的时候； 初始化类时，若发现其父类还没有初始化，则先触发父类的初始化； 虚拟机启动的时候，虚拟机会先初始化用户指定的包含main()方法的那个类 当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。 二、类加载器 加载阶段是开发期相对来说可控性比较强，该阶段既可以使用系统提供的类加载器完成，也可以由用户自定义的类加载器来完成，开发人员可以通过定义自己的类加载器去控制字节流的获取方式 2.1 加载过程 通过全限定名称取此类的二进制字节流 将字节流的静态存储结构转换为方法区的运行时数据结构 在内存中生成这个class对象作为方法区数据的访问入口 2.2 JVM内置的ClassLoader BootstrpClassLoader: 启动类加载器，顶层的加载器，c++实现，负责加载JAVA_HOME/lib目录下面的jar包和类或者被 -Xbootclasspath参数指定路径下的类 ExtensionClassLoader: 扩展类加载器，主要加载JAVA_HOME/lib/ext目录下面的jar包和类或者java.ext.dirs系统变量指定的jar包 AppClassLoader: 应用程序类加载器，面向用户的加载器，加载当前应用的classpath下的所有jar包和类。 2.3 双亲委派模型如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器，如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式，即每个儿子都不愿意干活，每次有活就丢给父亲去干，直到父亲说这件事我也干不了时，儿子自己想办法去完成，这就是传说中的双亲委派模式。 优势: 避免重复的类加载，如果父类已经加载了子类就不会再次加载。 保证Java核心API不被篡改。比如黑客自定义了java.lang.String类，有了双亲委派模型后自定义的java.lang.String类就永远都不会被加载进内存。因为首先是最顶端的类加载器加载系统的java.lang.String类，最终自定义的类加载器无法加载java.lang.String类。 源码: 1234567891011121314151617181920212223242526272829303132//双亲委派模型的工作过程源码protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; // First, check if the class has already been loaded Class c = findLoadedClass(name); if (c == null) &#123; try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader //父类加载器无法完成类加载请求 &#125; if (c == null) &#123; // If still not found, then invoke findClass in order to find the class //子加载器进行类加载 c = findClass(name); &#125; &#125; if (resolve) &#123; //判断是否需要链接过程，参数传入 resolveClass(c); &#125; return c;&#125; 2.4 破坏双亲委派模型(深入理解java虚拟机) 向前兼容: 由于双亲委派模型是在JDK1.2之后才被引入的，而类加载器和抽象类java.lang.ClassLoader则是JDK1.0时候就已经存在，面对已经存在的用户自定义类加载器的实现代码，Java设计者引入双亲委派模型时不得不做出一些妥协。为了向前兼容，JDK1.2之后的java.lang.ClassLoader添加了一个新的proceted方法findClass()，在此之前，用户去继承java.lang.ClassLoader的唯一目的就是重写loadClass()方法，因为虚拟在进行类加载的时候会调用加载器的私有方法loadClassInternal()，而这个方法的唯一逻辑就是去调用自己的loadClass()。JDK1.2之后已不再提倡用户再去覆盖loadClass()方法，应当把自己的类加载逻辑写到findClass()方法中，在loadClass()方法的逻辑里，如果父类加载器加载失败，则会调用自己的findClass()方法来完成加载，这样就可以保证新写出来的类加载器是符合双亲委派模型的。 基础类调用用户的代码: 双亲委派模型很好地解决了各个类加载器的基础类统一问题(越基础的类由越上层的加载器进行加载)，基础类之所以被称为“基础”，是因为它们总是作为被调用代码调用的API。但是，如果基础类又要调用用户的代码，那该怎么办呢? 这并非是不可能的事情，一个典型的例子便是JNDI服务，它的代码由启动类加载器去加载(在JDK1.3时放进rt.jar)，但JNDI的目的就是对资源进行集中管理和查找，它需要调用独立厂商实现部部署在应用程序的classpath下的JNDI接口提供者(SPI, Service Provider Interface)的代码，但启动类加载器不可能“认识”之些代码，该怎么办？为了解决这个困境，Java设计团队只好引入了一个不太优雅的设计：线程上下文件类加载器(Thread Context ClassLoader)。这个类加载器可以通过java.lang.Thread类的setContextClassLoader()方法进行设置，如果创建线程时还未设置，它将会从父线程中继承一个；如果在应用程序的全局范围内都没有设置过，那么这个类加载器默认就是应用程序类加载器。了有线程上下文类加载器，JNDI服务使用这个线程上下文类加载器去加载所需要的SPI代码，也就是父类加载器请求子类加载器去完成类加载动作，这种行为实际上就是打通了双亲委派模型的层次结构来逆向使用类加载器，已经违背了双亲委派模型，但这也是无可奈何的事情。Java中所有涉及SPI的加载动作基本上都采用这种方式，例如JNDI，JDBC，JCE，JAXB和JBI等。 三、自定义类加载器3.1 什么时候会需要自定义类加载器 加密: 在类需要加密的时候可以自定义类加载器，这样就可以在读取到密文的类之后在解密之后进行类加载 非标准来源的类: 比如字节码是从网络获取，或者从数据库中读取，就可以指定来源加载类 动态创建: 根据实际的情况进行进行动态的创建类 3.2 自定义类加载器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * 自定义类加载器 */public class CustomClassLoader extends ClassLoader&#123; public CustomClassLoader() &#123; &#125; public CustomClassLoader(ClassLoader parent) &#123; super(parent); &#125; // 重写findClass方法 @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; File file = new File("/Users/jasongao/Desktop/People.class"); try&#123; byte[] bytes = getClassBytes(file); //defineClass方法可以把二进制流字节组成的文件转换为一个java.lang.Class Class&lt;?&gt; c = this.defineClass(name, bytes, 0, bytes.length); return c; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return super.findClass(name); &#125; // 通过File获取二进制流字节 private byte[] getClassBytes(File file) throws Exception &#123; // 这里要读入.class的字节，因此要使用字节流 FileInputStream fis = new FileInputStream(file); FileChannel fc = fis.getChannel(); ByteArrayOutputStream baos = new ByteArrayOutputStream(); WritableByteChannel wbc = Channels.newChannel(baos); ByteBuffer by = ByteBuffer.allocate(1024); while (true)&#123; int i = fc.read(by); if (i == 0 || i == -1) &#123; break; &#125; by.flip(); wbc.write(by); by.clear(); &#125; fis.close(); return baos.toByteArray(); &#125; public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException &#123; CustomClassLoader customClassLoader = new CustomClassLoader(); Class&lt;?&gt; clazz = Class.forName("People", true, customClassLoader); Object obj = clazz.newInstance(); System.out.println(obj); System.out.println(obj.getClass().getClassLoader()); &#125;&#125; 编写People类之后，用javac People.java即可生成class文件 参考 类加载: https://juejin.im/post/5a810b0e5188257a5c606a85 双亲委派模型优势: https://blog.csdn.net/weixin_38055381/article/details/80167881 破坏双亲委派模型: https://juejin.im/post/5d7bbea8e51d4561c541a74f 线程上下文: https://blog.csdn.net/yangcheng33/article/details/52631940]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s命令记录]]></title>
    <url>%2Flinux%2Fkubernetes.html</url>
    <content type="text"><![CDATA[一、来源 Infrastructure as a Service 基础设施即服务(IaaS) platform as a Service 平台即服务(PaaS) Software as a Service 软件即服务(SaaS) 一、名词介绍 kubernetes: 开源的 Docker 容器编排系统，它可以调度计算集群的节点，动态管理上面的作业，保证它们按用户期望的状态运行。通过使用「labels」和「pods」的概念，Kubernetes 将应用按逻辑单元进行分组，方便管理和服务发现。 12345678910优势:1. 快速创建、部署、扩展应用2. 开发和运行相分离，资源隔离，资源利用更高效3. 无缝对接新的功能4. 节省资源，优化硬件资源的使用5. 自动重启、自动部署、自动复制、自动扩缩容6. 模块化、插件化、可挂载、可组合7. 持续开发、集成和部署8. 开发，测试和生产环境一致性9. 分布式，弹性，微服务化 pods: 是一组紧密关联的容器集合，它们共享 IPC(进程间通信)、Network(网络) 和 UTS namespace(UTS 命名空间是 Linux 命名空间的一个子系统，主要作用是完成对容器 Hostname 和 Domain 的隔离，同时保存内核名称、版本、以及底层体系结构类型等信息)，是 Kubernetes 调度的基本单位。 labels: 键值对(key/value)标签，可以被关联到如 Pod 这样的对象上，主要作用是给用户一个直观的感受，比如这个 Pod 是用来放置数据库的 GUI: 用户图形界面，可以是 Web 用户界面，比如使用 kubernetes-dashboard 组件，用户可以通过 Dashboard 在 Kubernetes 集群中部署容器化的应用，可以查看集群中应用的运行情况，同时也能够基于 Dashboard 创建或修改部署、任务、服务等 Kubernetes 的资源。通过部署向导，用户能够对部署进行扩缩容，进行滚动更新、重启 Pod 和部署新应用。当然，通过 Dashboard 也能够查看 Kubernetes 资源的状态 kube-apiserver: 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API 注册和发现等机制 Kubernetes Master: Kubernetes 集群主节点，主要由 kube-apiserver、kube-scheduler、kube-controller-manager、etcd 四个模块组成 kubernetes Node: Kubernetes 集群子节点，主要由 kubelet、kube-proxy、runtime 三个模块组成 kubeadm: kubernetes 的集群安装工具，能够快速安装 kubernetes 集群，安装 kubernetes 主要是安装它的各个镜像，而 kubeadm 已经为我们集成好了运行 kubernetes 所需的基本镜像。但由于国内的网络原因，在搭建环境时，无法拉取到这些镜像。此时我们只需要修改为阿里云提供的镜像服务即可解决该问题。 kubelet: 运行在cluster所有节点上,负责启动POD和容器 kubectl: kebenetes的命令行工具,通过kubectl可以部署和管理应用，查看各种资源，创建，删除和更新组件 二、集群安装2.1 安装必备工具1apt-get update &amp;&amp; apt-get install -y kubelet kubeadm kubectl 2.2 kubeadm安装1234567891011# 导出配置文件kubeadm config print init-defaults --kubeconfig ClusterConfiguration &gt; kubeadm.yml# 查看所需镜像kubeadm config images list --config kubeadm.yml# 拉取镜像kubeadm config images pull --config kubeadm.yml# 安装主节点# 指定了初始化时需要使用的配置文件，其中添加 --upload-certs 参数可以在后续执行加入节点时自动分发证书文件。追加的 tee kubeadm-init.log 用以输出日志kubeadm init --config=kubeadm.yml --upload-certs | tee kubeadm-init.log# 安装子节点kubeadm join 192.168.81.110:6443 --token abcdef.0123456789abcdef --discovery-token-ca-cert-hash sha256:3eac1be34c9e324279ebd843087e7dd002b3102c7d14313aec490cd73b4138ad 2.3 常用命令1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 查看kubernetes api版本kubectl api-versions# 查看命名空间kubectl get namespace# 在主节点查看是否安装成功，检查node状态kubectl get nodes# 查看 Pods 状态watch kubectl get pods -n kube-system -o wide# 查看组件运行状态kubectl get cs # 输出如下 NAME STATUS MESSAGE ERROR scheduler Healthy ok # 调度服务，主要作用是将 POD 调度到 Node controller-manager Healthy ok # 自动化修复服务，主要作用是 Node 宕机后自动修复 Node 回到正常的工作状态 etcd-0 Healthy &#123;"health":"true"&#125; # 服务注册与发现# 检查master状态kubectl cluster-info# 使用 kubectl 命令创建两个监听 80 端口的 Nginx Pod（Kubernetes 运行容器的最小单元）kubectl run nginx --image=nginx --replicas=2 --port=80# 查看pods状态kubectl get pods# 查看已经部署的服务kubectl get deployment# 查看已经发布的服务kubectl get services# 使用负载均衡模式发布服务，让用户可以访问kubectl expose deployment nginx --port=80 --type=LoadBalancer# 查看服务详情kubectl describe service kubia-web-demo# 删除已经部署的服务kubectl delete deployment nginx# 删除已经发布的服务kubectl delete service nginx# 部署根据配置文件里面列出来的内容，升级现有的,内容可以只写需要升级的属性kubectl apply -f filename.yaml# 部署先删除所有现有的东西，重新根据yaml文件生成新的kubectl create -f filename.yaml# 通过ingress查看kubectl get ingress# 编辑ingress信息kubectl edit ingress nginx-web# 删除ingresskubectl delete ingress nginx-web# 查看ingress资源kubectl get pods -n ingress-nginx -o wide# 通过创建的svc可以看到已经把ingress-nginx service在主机映射的端口kubectl get svc -n ingress-nginx 三、部署 tomcat 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879# 创建该对象所使用的 Kubernetes API 的版本。通过kubectl api-versions可以查看版本apiVersion: apps/v1# 创建的对象的类型: Deployment、Job、Ingress、Service、Podkind: Deployment# Pod的一些meta信息，比如名称、namespace、标签等信息metadata: # 资源的名字，在同一个namespace中必须唯一 name: tomcat-app# Pod中容器的详细定义spec: # 定义标签选择器 selector: matchLabels: # 容器标签的名字，发布 Service 时，selector 需要和这里对应 app: tomcat # 副本数量 replicas: 2 # Pod的定义 template: metadata: # Pod的label labels: app: tomcat # 指定该资源的内容 spec: # 容器 containers: - name: tomcat image: tomcat:8.5.43 # 镜像拉取策略: Always不管镜像是否存在都会进行一次拉取,Never不管镜像是否存在都不会进行拉取,IfNotPresent:只有镜像不存在时，才会进行镜像拉取注意 imagePullPolicy: IfNotPresent ports: - containerPort: 8080---apiVersion: v1kind: Servicemetadata: name: tomcat-httpspec: ports: - port: 8080 targetPort: 8080 # ClusterIP, NodePort, LoadBalancer type: ClusterIP selector: app: tomcat---apiVersion: networking.k8s.io/v1beta1kind: Ingressmetadata: name: nginx-web annotations: # 指定 Ingress Controller 的类型 kubernetes.io/ingress.class: "nginx" # 指定我们的 rules 的 path 可以使用正则表达式 nginx.ingress.kubernetes.io/use-regex: "true" # 连接超时时间，默认为 5s nginx.ingress.kubernetes.io/proxy-connect-timeout: "600" # 后端服务器回转数据超时时间，默认为 60s nginx.ingress.kubernetes.io/proxy-send-timeout: "600" # 后端服务器响应超时时间，默认为 60s nginx.ingress.kubernetes.io/proxy-read-timeout: "600" # 客户端上传文件，最大大小，默认为 20m nginx.ingress.kubernetes.io/proxy-body-size: "10m" # URL 重写 nginx.ingress.kubernetes.io/rewrite-target: /spec: # 路由规则 rules: # 主机名，只能是域名，修改为你自己的 - host: k8s.test.com http: paths: - path: backend: # 后台部署的 Service Name serviceName: tomcat-http # 后台部署的 Service Port servicePort: 8080 四、深入学习介绍说明基础概念Horizoontal Pod Autoscaling(HPA): 扩容缩 StatefulSet: 解决有服务状态服务的问题 DameonSet: 确保全部挥、或者一些Node上运行一个Pod副本。比如没有node上都安装一个logstash Job: 负责批处理任务，只执行一次的任务。如备份等。 资源清单Pod控制器ReplicaSets(RC): 滚动更新 Horizoontal Pod Autoscaling(HPA): 扩容缩 StatefulSet: 解决有服务状态服务的问题 DameonSet: 确保全部挥、或者一些Node上运行一个Pod副本。比如没有node上都安装一个logstash Job: 负责批处理任务，只执行一次的任务。如备份等。 服务发现service 存储调度器安全HELM运维]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程安全的学习]]></title>
    <url>%2Fjava%2FthreadSecurity.html</url>
    <content type="text"><![CDATA[一、线程安全与非线程安全非线程安全: ArrayList、HashMap、StringBuilder。 线程安全: Vector、HashTable(ConcurrentHashMap)、StringBuffer HashMap与ConcurrentHashMap的区别 ConcurrentHashMap是线程安全的，HashMap不是线程安全的 ConcurrentHashMap对桶数组进行了分段，HashMap没有。 ConcurrentHashMap在每个分段上都用锁进行保护，从而让锁更精细一些，并发性能要好一些。HashMap没有锁机制。 在主线程中new了一个非线程安全的ArrayList，然后开1000个线程分别向这个ArrayList里面添加元素，每个线程添加100个元素，等所有线程执行完成后查看list的总数。之后又new一个Vector用同样的方法查看数量，对比结果。例子: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// ArrayList与Vector测试public class ListThread &#123; static final int count = 1000; public static void main(String[] args) throws InterruptedException &#123; // 线程不安全 for (int i = 0; i &lt; 10; i++) &#123; threadHandleArrayList(); &#125; // 线程安全 for (int i = 0; i &lt; 10; i++) &#123; threadHandleVector(); &#125; &#125; static void threadHandleVector() throws InterruptedException &#123; List&lt;Integer&gt; list = new Vector(); // 用来让主线程等待threadCount个子线程执行完毕 CountDownLatch countDownLatch = new CountDownLatch(count); for (int i = 0; i &lt; count; i++) &#123; new Thread("线程"+ (i+1))&#123; @Override public void run() &#123; for (int j = 0; j &lt; 100; j++) &#123; list.add(1); &#125; &#125; &#125;.start(); &#125; Thread.sleep(100); System.out.println(list.size()); &#125; static void threadHandleArrayList() throws InterruptedException &#123; List&lt;Integer&gt; list = new ArrayList(); // 用来让主线程等待threadCount个子线程执行完毕 CountDownLatch countDownLatch = new CountDownLatch(count); for (int i = 0; i &lt; count; i++) &#123; new Thread("线程"+ (i+1))&#123; @Override public void run() &#123; for (int j = 0; j &lt; 100; j++) &#123; list.add(1); &#125; &#125; &#125;.start(); &#125; Thread.sleep(100); System.out.println(list.size()); &#125;&#125; 多个线程操作同一个对象的话就需要使用线程安全的对象，如果在线程内部new的对象则完全没必要使用线程安全的，如果使用了反而会造成性能影响因为线程安全的加了锁的。 二、 死锁2.1 什么是线程死锁定义: 如果多个线程在操作同一个对象的时候相互等待，在没有人为干预的情况下无法打破这种僵局。这种情况就是死锁。例如，某计算机系统中只有一台打印机和一台输入设备，进程P1正占用输入设备，同时又提出使用打印机的请求，但此时打印机正被进程P2 所占用，而P2在未释放打印机之前，又提出请求使用正被P1占用着的输入设备。这样两个进程相互无休止地等待下去，均无法继续执行，此时两个进程陷入死锁状态如： 1234567891011121314151617181920212223242526272829303132333435363738public static void main(String[] args) &#123; Object a = new Object(); Object b = new Object(); new Thread("线程1")&#123; @Override public void run() &#123; synchronized (a) &#123; try &#123; System.out.println("给对象a加锁并访问对象b"); Thread.sleep(500); synchronized (b) &#123; System.out.println("获取对象b"); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;.start(); new Thread("线程2")&#123; @Override public void run() &#123; synchronized (b) &#123; try &#123; System.out.println("给对象b加锁并访问对象a"); Thread.sleep(500); synchronized (a) &#123; System.out.println("获取对象a"); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;.start(); &#125; 2.2 产生的原因 系统资源的竞争: 系统中有一些资源有限，多线程去处理的时候经常处理资源不够的情况。在线程的运行中，会因为争抢资源而陷入僵局，只有对不可剥夺的资源进行竞争才可能产生死锁。 线程顺序不对: 在运行的线程中由于顺序不对也会造成死锁。如: 线程1和2同时使用资源1和2，线程1在没有释放的情况下去获取资源2，线程2在没有释放的情况下去获取资源1。就会造成死锁。或者进程A等待进程B发的消息，进程B又在等待进程A 发的消息，可以看出进程A和B不是因为竞争同一资源，而是在等待对方的资源导致死锁。 2.3 必要条件 互斥条件：一个资源，或者说一个锁只能被一个线程所占用，当一个线程首先获取到这个锁之后，在该线程释放这个锁之前，其它线程均是无法获取到这个锁。 占有且等待：一个线程已经获取到一个锁，再获取另一个锁的过程中，即使获取不到也不会释放已经获得的锁。 不可剥夺条件：任何一个线程都无法强制获取别的线程已经占有的锁 循环等待条件：线程A拿着线程B的锁，线程B拿着线程A的锁 2.3 如何避免死锁必须满足以上的4个条件，只要其中一个条件不满足就不好产生死锁。 加锁顺序: 线程按照相同的顺序加锁。 加锁时限: 线程获取锁的过程中限制一定的时间，如果给定时间内获取不到，就算了，别勉强自己。这需要用到Lock的一些API 死锁检测: 死锁检测是一个更好的死锁预防机制，它主要是针对那些不可能实现按序加锁并且锁超时也不可行的场景。每当一个线程获得了锁，就在一个数据结构中记录一下如：线程A请求锁7，但是锁7这个时候被线程B持有，这时线程A就可以检查一下线程B是否已经请求了线程A当前所持有的锁。如果线程B确实有这样的请求，那么就是发生了死锁（线程A拥有锁1，请求锁7；线程B拥有锁7，请求锁1） 一个可行的做法是释放所有锁，回退，并且等待一段随机的时间后重试。这个和简单的加锁超时类似，不一样的是只有死锁已经发生了才回退，而不会是因为加锁的请求超时了。虽然有回退和等待，但是如果有大量的线程竞争同一批锁，它们还是会重复地死锁（编者注：原因同超时类似，不能从根本上减轻竞争）。 一个更好的方案是给这些线程设置优先级，让一个（或几个）线程回退，剩下的线程就像没发生死锁一样继续保持着它们需要的锁。如果赋予这些线程的优先级是固定不变的，同一批线程总是会拥有更高的优先级。为避免这个问题，可以在死锁发生的时候设置随机的优先级。 2.4 死锁检测 jstack: 是java虚拟机自带的一种堆栈跟踪工具。jstack用于打印出给定的java进程ID或core file或远程调试服务的Java堆栈信息。 Jstack工具可以用于生成java虚拟机当前时刻的线程快照。线程快照是当前java虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。 线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556JasonGaodeMacBook-Air:~ jasongao$ jps // 找到当前执行任务的进程号2770 App67397 DeathLock67396 Launcher65497 KotlinCompileDaemon6429967434 Jps64463 RemoteMavenServer36JasonGaodeMacBook-Air:~ jasongao$ jstack 67397 // 执行jstack命令查看当前进程堆栈信息2020-07-01 14:54:34Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.211-b12 mixed mode):"Attach Listener" #15 daemon prio=9 os_prio=31 tid=0x00007fc13b802000 nid=0x360b waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE"DestroyJavaVM" #14 prio=5 os_prio=31 tid=0x00007fc13b8e9800 nid=0x1003 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE"线程2" #13 prio=5 os_prio=31 tid=0x00007fc13b8e9000 nid=0x5503 waiting for monitor entry [0x0000700001555000] java.lang.Thread.State: BLOCKED (on object monitor) at com.gaoqisen.threadcecurity.DeathLock$2.run(DeathLock.java:34) - waiting to lock &lt;0x00000007aad54eb0&gt; (a java.lang.Object) - locked &lt;0x00000007aad54ec0&gt; (a java.lang.Object)"线程1" #12 prio=5 os_prio=31 tid=0x00007fc13a050800 nid=0x5303 waiting for monitor entry [0x0000700001452000] java.lang.Thread.State: BLOCKED (on object monitor) at com.gaoqisen.threadcecurity.DeathLock$1.run(DeathLock.java:17) - waiting to lock &lt;0x00000007aad54ec0&gt; (a java.lang.Object) - locked &lt;0x00000007aad54eb0&gt; (a java.lang.Object)......JNI global references: 1432// 线程死锁信息Found one Java-level deadlock:============================="线程2": waiting to lock monitor 0x00007fc13b83dca8 (object 0x00000007aad54eb0, a java.lang.Object), which is held by "线程1""线程1": waiting to lock monitor 0x00007fc13b839c08 (object 0x00000007aad54ec0, a java.lang.Object), which is held by "线程2"Java stack information for the threads listed above:==================================================="线程2": at com.gaoqisen.threadcecurity.DeathLock$2.run(DeathLock.java:34) - waiting to lock &lt;0x00000007aad54eb0&gt; (a java.lang.Object) - locked &lt;0x00000007aad54ec0&gt; (a java.lang.Object)"线程1": at com.gaoqisen.threadcecurity.DeathLock$1.run(DeathLock.java:17) - waiting to lock &lt;0x00000007aad54ec0&gt; (a java.lang.Object) - locked &lt;0x00000007aad54eb0&gt; (a java.lang.Object)Found 1 deadlock. jconsole: 是JDK自带的监控工具，在JDK/bin目录下可以找到。它用于连接正在运行的本地或者远程的JVM，对运行在Java应用程序的资源消耗和性能进行监控，并画出大量的图表，提供强大的可视化界面。而且本身占用的服务器内存很小，甚至可以说几乎不消耗。在命令行中敲入jconsole命令，会自动弹出以下对话框，选择进程67397，并点击“Connect”。 点击Threads后再点击Detect Deadlock 之后就可以查看死锁信息了。 三、参考 死锁： https://www.cnblogs.com/sthu/p/9660914.html 线程安全：https://blog.csdn.net/xiao__gui/article/details/8934832 死锁的4个必要条件: https://blog.csdn.net/rabbit_in_android/article/details/50530960]]></content>
      <categories>
        <category>Lock thread</category>
      </categories>
      <tags>
        <tag>thread</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2Fstudy%2Falgorithm.html</url>
    <content type="text"><![CDATA[一、基本概念 数据结构: 存储数据的不同方式如：数组、链表、 算法: 同一个问题的不同解决方法,算法往往是针对特定数据结构的 时间测量：计算算法时间差、幅度不够循环来凑(扩大数据量) 空间测算: 数据占用的空间越小越好 时间复杂度(Big O): 时间复杂度为O(n)随着处理数据量的增加，处理时间也会增加。时间复杂度为O(1)表示随着处理数据的规模增大但是处理的时间没有变化。 对数器: 检查算法是否正确，用足够多的样本和正确的算法计算结果样本去对比被验证的算法结果(用已有的排序算法和自己写的排序算法都去处理数据，之后将处理的结果对比一下是否一致) O(1): 表示操作一次之后就可以获取目标元素 O(n): 表示要检查n个元素来搜索目标 O(log n): 从数组的中间选择一个随机点进行查找，然后重复这个过程 O(n2): 一个算法时bai间的消耗是和其计du算步数成平方增长的 二、排序算法2.1 选择排序O(n2)先找到最小的数字然后把它放在列表的最前面。最简单最没用的排序算法，有优化空间,不稳定(没用)。原理是找到最小的数把它放在最前面。 123456789101112131415161718192021222324public static void main(String[] args) &#123; int[] arr = &#123;8,6,5,4,7,1,2,3,2&#125;; // 排序算法，每次找到最小的数字放在最前面 for (int i = 0; i&lt; arr.length - 1; i++) &#123; int minVal = i; // 找到最小数字的下标 for(int j = i+1; j &lt; arr.length; j++) &#123; if(arr[j] &lt; arr[minVal]) &#123; minVal = j; &#125; &#125; // 将最小的数字放在最前面 int tmp = arr[minVal]; arr[minVal] = arr[i]; arr[i] = tmp; &#125; // 遍历数组 for (int i = 0; i&lt; arr.length; i++) &#123; System.out.println(arr[i]); &#125; &#125; 2.2 冒泡排序从无序序列头部开始，进行两两比较，根据大小交换位置，直到最后将最大（小）的数据元素交换到了无序队列的队尾，从而成为有序序列的一部分；下一次继续这个过程，直到所有数据元素都排好序 123456789101112131415161718192021222324252627282930public class BubbleSort &#123; public static void main(String[] args) &#123; int[] a = &#123;9,6,5,2,3,4,80,7,1,10&#125;; for (int i = 0; i &lt; a.length; i++) &#123; for (int j = 1; j &lt; a.length; j++) &#123; int index = j-1; if(a[index] &gt; a[j]) &#123; swap(a, index, j); &#125; &#125; &#125; // 输出 for (int i = 0; i &lt; a.length; i++) &#123; if(i == (a.length - 1))&#123; System.out.print(a[i]); break; &#125; System.out.print(a[i]+ ", "); &#125; System.out.println(""); &#125; static void swap(int[] a, int start, int end) &#123; int temp = a[start]; a[start] = a[end]; a[end] = temp; &#125;&#125; 2.3 插入排序插入排序是一种简单直观的排序算法。它的基本思想是拿到当前值之后往前面的正确位置移动。 12345678910111213141516171819202122232425262728293031323334353637// 插入排序public class InsertionSort &#123; public static void main(String[] args) &#123; int[] a = &#123;9,6,5,2,3,4,80,7,1,10&#125;; for (int i = 0; i &lt; a.length; i++) &#123; // 通过当前值和前面的值比较，并把当前值放到恰当的位置 for (int j = i; j &gt; 0; j--) &#123; if(a[j] &lt; a[j-1]) &#123; swap(a, j, j-1); &#125; &#125; &#125; print(a); &#125; // 替换 static void swap(int[] a, int start, int end) &#123; int temp = a[start]; a[start] = a[end]; a[end] = temp; &#125; static void print(int[] a) &#123; // 输出 for (int i = 0; i &lt; a.length; i++) &#123; if(i == (a.length - 1))&#123; System.out.print(a[i]); break; &#125; System.out.print(a[i]+ ", "); &#125; System.out.println(""); &#125;&#125; 2.4 希尔排序将数组分为几段处理，不如15个数组元素分为每4个一组进行插入排序，之后在进行2个一组插入排序，之后在进行1个一组进行插入排序就可以了。这样缩短了数字之间的插入排序。希尔排序是不常用的排序方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 希尔排序public class ShellSort &#123; public static void main(String[] args) &#123; int[] a = &#123;9,6,5,2,3,4,80,7,1,10&#125;; // knuth序列 int h = 1; while( h &lt;= a.length / 3) &#123; h = h*3 +1; &#125; for (int gap = h; gap &gt; 0; gap = (gap -1)/3) &#123; for (int i = gap; i &lt; a.length; i++) &#123; for (int j = i; j &gt; gap -1 ; j-=gap) &#123; if(a[j] &lt; a[j-gap]) &#123; swap(a, j, j-gap); &#125; &#125; &#125; &#125; print(a); &#125; static void swap(int[] a, int start, int end) &#123; int temp = a[start]; a[start] = a[end]; a[end] = temp; &#125; static void print(int[] a) &#123; // 输出 for (int i = 0; i &lt; a.length; i++) &#123; if(i == (a.length - 1))&#123; System.out.print(a[i]); break; &#125; System.out.print(a[i]+ ", "); &#125; System.out.println(""); &#125;&#125; 2.5 快速排序 单轴排序 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273// 快速排序: 采用不断的比较和移动来实现排序// 对于给定的一组记录，选择一个基准元素,通常选择第一个元素或者最后一个元素,通过一趟扫描，// 将待排序列分成两部分,一部分比基准元素小,一部分大于等于基准元素,此时基准元素在其排好序// 后的正确位置,然后再用同样的方法递归地排序划分的两部分，直到序列中的所有记录均有序为止。public class QuickSort &#123; public static void main(String[] args) &#123; int[] arr = &#123; 6, 5, 9, 8, 3, 2, 1, 7, 10&#125;; sort(arr); print(arr); &#125; // 排序 static void sort(int[] arr) &#123; partition(arr, 0, arr.length-1); &#125; // 分区 static void partition(int[] arr, int left, int right)&#123; if(left &gt;= right) &#123; return; &#125; // 指针指向左边的第一个值 int i = left; // 已右边的数为基数(轴) int temp = arr[right]; // 右边的指针就是right-1 int j = right; // 当左边的值小于右边值的时候 while (i &lt; j) &#123; // 从左往右找大于或者基数的数字，并移动到arr.length-1的位置 while (i&lt;j &amp;&amp; arr[i] &lt;= temp) &#123; i++; &#125; if(i &lt; j) &#123; arr[j--] = arr[i]; &#125; // 从有右往左找小于或者等于基数的数字，并移动数字到i++的位置 while (i&lt;j &amp;&amp; arr[j] &gt; temp)&#123; j--; &#125; if(i &lt; j) &#123; arr[i++] = arr[j]; &#125; &#125; // 将基数放在i的位置 arr[i] = temp; // 递归循环轴左边的值 partition(arr, left, i-1); // 递归循环轴右边的值 partition(arr, i+1, right); &#125; static void swap(int[] a, int start, int end) &#123; int temp = a[start]; a[start] = a[end]; a[end] = temp; &#125; static void print(int[] a) &#123; // 输出 for (int i = 0; i &lt; a.length; i++) &#123; if(i == (a.length - 1))&#123; System.out.print(a[i]); break; &#125; System.out.print(a[i]+ ", "); &#125; System.out.println(""); &#125;&#125; 双轴快排 从两边同时查找 2.6 计数排序用于统计有特别多的重复数据的时候，比如2万个学生的年龄分布等。非比较排序。 2.7 基数排序通过每个数字的个位、十位、百位等进行计数排序之后就可以了]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GC学习笔记]]></title>
    <url>%2Fjava%2Fgc.html</url>
    <content type="text"><![CDATA[一、简介 serial(新): 一个CPU或一条GC线程进行垃圾回收,会出现STW。采用复制算法 parNew(新): serial的多线程版本,多条gc线程去回收(降低gc时间)。采用复制算法 parallel shavenge(新): 并行的多线程(追求CPU吞吐量)。采用复制算法 serial old(老): 单线程收集。标记-整理算法 parallel old(老): 多线程回收(追求CPU吞吐量)。标记-整理算法 CMS(老): 多线程回收(追求最短停顿时间)。标记-清除算法 G1(java9默认): 没有分代概念，将java堆分为相同的Region，回收最多垃圾数据的Regio ZGC: java11, 暂停时间不超过10ms,支持 4TB,JDK13 到了 16TB! 1234567# JDK版本默认垃圾收集器# jdk1.7 默认垃圾收集器Parallel Scavenge（新生代）+Serial Old（老年代）# jdk1.8 默认垃圾收集器Parallel Scavenge（新生代）+Serial Old（老年代）# jdk1.9 默认垃圾收集器G1# jdk10 默认垃圾收集器G1# 查看当前使用的是哪种回收策略，-XX:+Use后面的就是 -XX:+PrintGCDetails 亦可通过打印的GC日志的新生代、老年代名称判断java -XX:+PrintCommandLineFlags -version 二、垃圾回收算法2.1 标记-清除首先标记出所有需要回收的对象,在标记完成后统一回收所有被标记的 对象。它是最基础的收集算法,后续的算法都是对其不足进行改进得到。这种垃圾收集算法会带来两个明显的问题: 1. 效率问题。2. 空间问题(标记清除后会产生大量不连续的碎片) 2.2 标记-整理根据老年代的特点特出的一种标记算法,标记过程仍然与“标记-清除”算法一样,但后续步骤不是直接对可回收对象回收,而是让所有存活的对象向一端移动,然后直接清理掉端边界以外的内存 2.3 复制为了解决效率问题,“复制”收集算法出现了。它可以将内存分为大小相同的两块,每次使用其中的一 块。当这一块的内存使用完后,就将还存活的对象复制到另一块去,然后再把使用的空间一次清理掉。 这样就使每次的内存回收都是对内存区间的一半进行回收。 2.4 分代收集当前虚拟机的垃圾收集都采用分代收集算法,只是根据对象存活周期的不 同将内存分为几块。一般将java堆分为新生代和老年代,这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。比如在新生代中,每次收集都会有大量对象死去,所以可以选择复制算法,只需要付出少量对象的复制 成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的,而且没有额外的空间对它进行分配担保,所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。 三、垃圾收集器详解3.1 serialSerial(串行新生代)，serial old(老年代)收集器收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是 一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收 集工作,更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程( “Stop The World” ),直到它收集结束。 Serial收集器由于没有线程交互的开销,可以获得很高的单线程收集效率。Serial收集器对于运行在Client模式下的虚拟机来说是个不错的选择,简单而且高效。 3.2 parNewParNew收集器其实就是Serial收集器的多线程版本,除了使用多线程进行垃圾收集外,其余行为(控制参数、收集算法、回收策略等等)和Serial收集器完全一样。新生代采用复制算法,老年代采用标记-整理算法。它是许多运行在Server模式下的虚拟机的首要选择,除了Serial收集器外,只有它能与CMS收集器(真 正意义上的并发收集器,后面会介绍到)配合工作。新生代采用复制算法,老年代采用标记-整理算法。 3.3 Parallel ScavengeParallel Scavenge 收集器类似于ParNew 收集器。Parallel Scavenge收集器关注点是吞吐量(高效率的利用CPU)。CMS等垃圾收集器的关注点更多的是 用户线程的停顿时间(提高用户体验)。所谓吞吐量就是CPU中用于运行用户代码的时间与CPU总消耗时 间的比值。 Parallel Scavenge收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量,如 果对于收集器运作不太了解的话,手工优化存在的话可以选择把内存管理优化交给虚拟机去完成也是一 个不错的选择。 3.4 Serial OldSerial收集器的老年代版本,它同样是一个单线程收集器。它主要有两大用途:一种用途是在JDK1.5以及以前的版本中与Parallel Scavenge收集器搭配使用,另一种用途是作为CMS收集器的后备方案。 3.5 Parallel OldParallel Scavenge收集器的老年代版本。使用多线程和“标记-整理”算法。在注重吞吐量以及CPU资源 的场合,都可以优先考虑 Parallel Scavenge收集器和Parallel Old收集器。 3.6 CMSConcurrent Mark Sweep 收集器是一种以获取最短回收停顿时间为目标的收集器。它而非常符合在注重用户体验的应用上使用。是HotSpot虚拟机第一款真正意义上的并发收集器,它第一次实 现了让垃圾收集线程与用户线程(基本上)同时工作， “标记-清除”算法实现。运行分为四个步骤初始标记、并发标记、重新标记、并发清除: 初始标记: 暂停所有线程，记录所有与根(root)对象相连的对象，速度特别快 并发标记: 同时开启GC和用户线程,用一个闭包结构去记录可达对象。但在这个阶段结束,这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域,所以 GC线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。 重新标记: 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变 动的那一部分对象的标记记录,这个阶段的停顿时间一般会比初始标记阶段的时间稍⻓,远远比 并发标记阶段时间短 并发清除: 开启用户线程,同时GC线程开始对为标记的区域做清扫。 优点: 并发收集，低停顿。 缺点: 对CPU资源敏感，无法处理浮动垃圾，标记清除算法会导致大量空间碎片。 3.7 G1java9默认的收集器是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器.以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征。筛选回收进化特征： 并行与并发:G1能充分利用CPU、多核环境下的硬件优势,使用多个CPU(CPU或者CPU核心)来缩 短Stop-The-World停顿时间。部分其他收集器原本需要停顿Java线程执行的GC动作,G1收集器仍 然可以通过并发的方式让java程序继续执行。 分代收集:虽然G1可以不需要其他收集器配合就能独立管理整个GC堆,但是还是保留了分代的概 念。 空间整合:与CMS的“标记–清理”算法不同,G1从整体来看是基于“标记整理”算法实现的收集 器;从局部上来看是基于“复制”算法实现的。 可预测的停顿:这是G1相对于CMS的另一个大优势,降低停顿时间是G1 和 CMS 共同的关注点, 但G1 除了追求低停顿外,还能建立可预测的停顿时间模型,能让使用者明确指定在一个⻓度为M 毫秒的时间片段内。 G1收集器在后台维护了一个优先列表,每次根据允许的收集时间,优先选择回收价值最大的Region(这 也就是它的名字Garbage-First的由来)。这种使用Region划分内存空间以及有优先级的区域回收方式, 保证了GF收集器在有限时间内可以尽可能高的收集效率(把内存化整为零)，G1收集过程。 初始标记 标记与GC Roots直接关联的对象,停止所有用户线程,只启动一条初始标记线程,这个过程很快. 并发标记 进行全面的可达性分析,开启一条并发标记线程与用户线程并行执行.这个过程比较长. 最终标记 标记出并发标记过程中用户线程新产生的垃圾.停止所有用户线程,并使用多条最终标记线程并行执行. 筛选回收 回收废弃的对象.此时也需要停止一切用户线程,并使用多条筛选回收线程并行执行. 3.8 ZGCZGC是从JDK11中引入的一种新的支持弹性伸缩和低延迟垃圾收集器，ZGC可以工作在KB~TB的内存之下，作为一种并发的垃圾收集器，ZGC保证应用延迟不会超过10毫秒(即便在堆内存很大的情况下)，在JDK11中是以实验阶段的特性被发布出来的，到JDK13时，ZGC可以支持到16TB的堆内存，并且可以将未提交的内存归还给操作系统。 四、参考 垃圾回收算法: https://www.jianshu.com/p/114bf4d9e59e 垃圾收集器: https://cloud.tencent.com/developer/article/163396 ZGC: https://zhuanlan.zhihu.com/p/43608166]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java gc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对象的引用学习笔记]]></title>
    <url>%2Fjava%2Freference.html</url>
    <content type="text"><![CDATA[对象的强、软、弱、虚引用 强引用（只要有引用指向就不会被回收）一个对象被强引用时，就算抛出OOM异常也不会被GC回收。 12345678public static void main(String[] args) throws Exception&#123; // M写finalize方法，在垃圾回收的时候会被调用. 垃圾回收的线程和main主线程那个先执行，不可控。 M m = new M(); // 强引用 m = null; System.gc(); // 显示调用垃圾回收 System.out.println(m); // 输出 null System.in.read(); // 阻塞main线程，给垃圾回收线程时间去执行. 如果重写了finalize方法的话，就会执行该方法 &#125; 软引用（堆空间不够的时候，gc会去回收），可用来实现内存敏感的高速缓存。 1234567891011121314151617public static void main(String[] args) throws Exception&#123; // 在内存中，内存中开辟了一块10m的空间。m执行了SoftReference对象，SoftReference软引用指向了10m的内存数据 SoftReference&lt;byte[]&gt; m = new SoftReference&lt;byte[]&gt;(new byte[1024*1024*10]); System.out.println (m.get()); // 获取对象地址 System.gc(); Thread.sleep(500); // 给gc回收时间 System.out.println(m.get()); // 设置堆空间最大为20m的时候，前面m的软引用已经有10m的数据了。[-Xmx20M] // 这个时候在new一个硬引用的b有15m，这个时候堆空间不够20m，故gc会把软引用的数据清理掉。 // 在输出m的对象地址就为空 byte[] b = new byte[1024*1024*12]; System.out.println(m.get()); // 软引用特别适合作缓存 &#125; 弱引用（只要执行gc就会被回收），弱引用可以和一个引用队列(ReferenceQueue)联合使用,如果弱引用所引用的对象被垃圾回收,Java 虚拟机就会把这个弱引用加入到与之关联的引用队列中。 12345678public static void main(String[] args) &#123; // 弱引用 WeakReference&lt;M&gt; m = new WeakReference&lt;&gt;(new M()); System.out.println(m.get()); System.gc(); // gc回收时直接回收弱引用 System.out.println(m.get()); &#125; 虚引用（一直不会被引用，jvm会使用），虚引用主要用来跟踪对象被垃圾回收的活动 123456789101112131415161718192021222324252627282930public static void main(String[] args) &#123; // 用来管理直接内存（在对象被垃圾回收之后会执行一些操作） // 看m对象有没有指向堆外内存(不归gc管理的)，如果后指向，则清理堆外内存。 PhantomReference&lt;M&gt; m = new PhantomReference&lt;&gt;(new M(), QUEUE); System.out.println(m.get()); new Thread( () -&gt; &#123; while(true) &#123; list.add(new byte[1024*1024]); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); Thread.currentThread().interrupt(); &#125; System.out.println(m.get()); &#125; &#125;).start(); // 垃圾回收线程 new Thread(()-&gt;&#123; while (true) &#123; Reference&lt;? extends M&gt; poll = QUEUE.poll(); if(poll != null) &#123; System.out.println("虚引用被jvm回收" + poll); &#125; &#125; &#125;).start(); &#125; 虚引用与软引用和弱引用的一个区别在于: 虚引用必须和引用队列(ReferenceQueue)联合使用。当 垃 圾回收器准备回收一个对象时,如果发现它还有虚引用,就会在回收对象的内存之前,把这个虚引 用加入到与之关联的引用队列中。程序可以通过判断引用队列中是 否已经加入了虚引用,来了解被引 用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列,那么就可以在所引用 的对象的内存被回收之前采取必要的行动。 对象传值的三种方式：1. 通过方法的参数。2. 通过静态变量。3.通过ThreadLocal ThreadLocal 1234567891011121314151617181920212223242526// 线程私有的， 只有在同一个线程里面才可以拿到值 private static ThreadLocal&lt;People&gt; th = new ThreadLocal&lt;&gt;(); public static void main(String[] args)&#123; new Thread(() -&gt; &#123; try &#123; TimeUnit.MINUTES.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("th: " + th.get()); &#125;).start(); new Thread(() -&gt;&#123; try &#123; TimeUnit.MINUTES.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 在当前线程的map对象里面放 map.set(this, value); // set的时候Entry继承了WeakReference，防止内存泄漏。弱引用，只要没有对象指向 th.set(new People()); // 不用了一定要remove，不然也会内存泄漏 th.remove(); &#125;).start(); &#125; 学习网址: https://www.bilibili.com/video/BV1HD4y1Q71y?p=8]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java reference</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[filebeat学习笔记]]></title>
    <url>%2Ftool%2Ffilebeat.html</url>
    <content type="text"><![CDATA[一、概述Filebeat是一个日志文件托运工具，在你的服务器上安装客户端后，filebeat会监控日志目录或者指定的日志文件，追踪读取这些文件（追踪文件的变化，不停的读），并且转发这些信息到elasticsearch或者logstarsh中存放。filebeat是一个轻量级的logstash，当你需要收集信息的机器配置或资源并不是特别多时，使用filebeat来收集日志。日常使用中，filebeat十分稳定。 logstash 功能虽然强大，但是基于ruby的配置语法、依赖jdk、消耗系统资源等弊端，使得考虑其他方式来替换logstash，filebeat则是一个完美的替代者 二、安装 最新下载地址: https://www.elastic.co/cn/downloads/beats/filebeat 解压文件夹： 启动: sudo ./filebeat -e -c filebeat.yml docker安装 1234567891011mac: brew install filebeatlinux: wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.3.1-linux-x86_64.tar.gz tar -zxvf filebeat-7.3.1-linux-x86_64.tar.gz nohup ./filebeat -e -c filebeat.yml &gt;/dev/null 2&gt;&amp;1 &amp; // 后台启动将所有标准输出及标准错误输出到/dev/null空设备，即没有任何输出docker: docker pull docker.elastic.co/beats/filebeat:7.3.1 docker tag docker.elastic.co/beats/filebeat:7.3.1 filebeat docker run -d --name logstash 10.45.53.221:5000/filebeat docker run --name filebeat -d --link logstash -v ~/elk/yaml/filebeat.yml:/usr/share/filebeat/filebeat.yml -v ~/elk/logs/:/home/logs/ filebeat // 启动filebeat并关联logstash 三、配置文件1234567891011121314151617181920filebeat.ymlfilebeat.prospectors:- paths: - /home/user/elk/logs/order/*.log multiline: pattern: ^\d&#123;4&#125; negate: true match: after fields: doc_type: order- paths: - /home/user/elk/logs/customer/*.log multiline: pattern: ^\d&#123;4&#125; negate: true match: after fields: doc_type: customeroutput.logstash: # 输出地址 hosts: [&quot;logstash:5043&quot;]]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>filebeat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch学习]]></title>
    <url>%2Ftool%2Felasticsearch.html</url>
    <content type="text"><![CDATA[一、安装1.1 下载安装 下载安装包地址: https://www.elastic.co/cn/downloads/elasticsearch 修改config/elasticsearch.yml配置 12345678910111213141516171819202122232425262728293031323334353637# 集群名称cluster.name: web-application# ------------------------------------ Node ------------------------------------# 节点名称node.name: node-1# 增加一个自定义属性#node.attr.rack: r1# ----------------------------------- Paths ------------------------------------# 存储数据的目录(用逗号分隔)#path.data: /path/to/data# 日志路径#path.logs: /path/to/logs# ----------------------------------- Memory -----------------------------------# 启动时锁定内存:#bootstrap.memory_lock: truebootstrap.memory_lock: falsebootstrap.system_call_filter: false# ---------------------------------- Network -----------------------------------# 设置外网可以访问network.host: 0.0.0.0# 自定义端口#http.port: 9200# --------------------------------- Discovery ----------------------------------## 启动后去发现list里面主机节点是否启动 默认列表[&quot;127.0.0.1&quot;, &quot;[::1]&quot;]#discovery.seed_hosts: [&quot;host1&quot;, &quot;host2&quot;]# 初始化主节点cluster.initial_master_nodes: [&quot;node-1&quot;]# ---------------------------------- Gateway -----------------------------------# 整个集群启动之后#gateway.recover_after_nodes: 3# ---------------------------------- Various -----------------------------------# 删除索引时需要显示名称#action.destructive_requires_name: true# 启动输入密码访问xpack.security.transport.ssl.enabled: truexpack.security.enabled: true 操作命令 1234567891011121314// 增加elasticsearch用户adduser elasticsearch// 设置密码passwd elasticsearch// 更改文件的所属用户chown -R elasticsearch filename// 切换用户su elasticsearch// 解压tar -zxf XXX.tar.gz// 后台启动./elasticsearch -d// 修改密码，为多个用户分别设置密码bin/elasticsearch-setup-passwords interactive 验证:，浏览器访问http://ip:9200输入帐号密码后返回json串表示启动成功。 1.2 安装遇到的问题1.2.1 外网无法访问123vim config/elasticsearch.yml// 增加下面配置network.host: 0.0.0.0 1.2.2 启动报错 system call filters failed to install; check the logs and fix your configuration or disable system call filters at your own risk。 因为Centos6不支持SecComp，而ES5.2.1默认bootstrap.system_call_filter为true进行检测，所以导致检测失败，失败后直接导致ES不能启动。解决方法：在elasticsearch.yml中配置bootstrap.system_call_filter为false，注意要在Memory下面: 12bootstrap.memory_lock: falsebootstrap.system_call_filter: false max number of threads [1024] for user [elasticsearch] is too low, increase to at least [4096] 最大线程数[1024]太低，至少增加到[4096]。 修改/etc/security/limits.d/90-nproc.conf文件里面1024为4096 max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 最大虚拟内存区域vm.max_map_count [65530]太低，至少增加到[262144] 123vim /etc/sysctl.conf// 增加下面配置vm.max_map_count=655360 max file descriptors [65535] for elasticsearch process is too low, increase to at least[65536]。由于给帐号的最大打开文件个数或者最大打开线程数的限制，一直会报错，因此改一下限制(/etc/security/limits.conf)即可 123456// 增加下面配置 * soft nofile 65536 * hard nofile 131072 * soft nproc 2048 * hard nproc 4096 // 退出帐号重新登录(退出重新登录生效) 二、常用语法2.1 基本操作123456789101112131415161718192021222324252627# &lt;REST Verb&gt; http://localhost:9200/&lt;Index&gt;/&lt;Type&gt;/&lt;ID&gt;# &lt;請求類型&gt; &lt;请求地址&gt;/&lt;索引名&gt;/&lt;文档类型&gt;/&lt;文档ID&gt;# 数据库：数据库 表 行 列# el： 索引 类型 文档 字段# 检查集群的健康 Authorization 從/獲取GET /_cat/health?v# 查看索引返回：health status index uuid pri rep docs.count docs.deleted store.size pri.store.size 表明我们还没有索引在集群中GET /_cat/indices?v# 集群中的节点列表GET /_cat/nodes?v# 创建一个索引叫做&quot;customer&quot;PUT /customer?pretty# 索引一个简单的customer文档到customer索引，external类型，ID是1PUT /customer/external/1?pretty&#123; &quot;name&quot;: &quot;John Doe&quot;&#125;# 删除一个索引DELETE /customer?pretty# 删除全部索引DELETE /_all# 删除 多个索引DELETE /customer,customer1,customer2# 删除 模糊匹配DELETE /customer*# 删除一个文档DELETE /customer/external/2?pretty 2.2 search查询条件详解1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# 查询出所有问题文档匹配某个查询GET /centent/_search?q=title:123# 有多少文档匹配某个查询GET /centent/_search?q=title:123*&amp;size=0# 有没有文档匹配某个查询(terminated_early)GET /centent/_search?q=title:1234*&amp;size=0&amp;terminate_after=1# match和term的区别：match查询的时候,elasticsearch会根据你给定的字段提供合适的分析器,而term查询不会有分析器分析的过程，match查询相当于模糊匹配,只包含其中一部分关键词就行GET /_search&#123; &quot;_source&quot;: false, &quot;query&quot; : &#123; &quot;term&quot; : &#123; &quot;title&quot; : &quot;123&quot; &#125; &#125;&#125;# 查询全部GET /book/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;&#125;# 排序GET /book/_search &#123;&quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;name&quot; : &quot; java&quot; &#125;&#125;, &quot;sort&quot;: [ &#123; &quot;price&quot;: &quot;desc&quot; &#125; ]&#125;# 分页GET /book/_search &#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;from&quot;: 0, &quot;size&quot;: 1&#125;# 指定返回的字段GET /book/_search &#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;_source&quot;: [&quot;name&quot;, &quot;studymodel&quot;]&#125;# 匹配指定条件查询GET /test_index/_search &#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;test_field&quot;: &quot;test&quot; &#125; &#125;&#125; 2.3 返回数据详解1234567891011121314151617181920212223242526272829&#123; &quot;took&quot; : 97, #请求耗时多少毫秒 &quot;timed_out&quot; : false, #是否超时。默认情况下没有超时机制，也就是客户端等待Elasticsearch搜索结束（无论执行多久），提供超时机制的话，Elasticsearch则在指定时长内处理搜索，在指定时长结束的时候，将搜索的结果直接返回（无论是否搜索结束）。指定超时的方式是传递参数，参数单位是：毫秒-ms。秒-s。分钟-m。 &quot;_shards&quot; : &#123; # 分片 &quot;total&quot; : 1, #请求发送到多少个shard上 &quot;successful&quot; : 1, #成功返回搜索结果的shard &quot;skipped&quot; : 0, #停止服务的shard &quot;failed&quot; : 0 #失败的shard &#125;, &quot;hits&quot; : &#123; #匹配记录数 &quot;total&quot; : &#123; #返回了多少结果 &quot;value&quot; : 3, &quot;relation&quot; : &quot;eq&quot; # 关系 &#125;, &quot;max_score&quot; : 1.0, #搜索结果中，最大的相关度分数，相关度越大分数越高，_score越大，排位越靠前 &quot;hits&quot; : [ #搜索到的结果集合，默认查询前10条数据。 &#123; &quot;_index&quot; : &quot;centent&quot;, #数据所在索引 &quot;_type&quot; : &quot;centent&quot;, #数据所在类型 &quot;_id&quot; : &quot;4&quot;, #数据的id &quot;_score&quot; : 1.0, #数据的搜索相关度分数 &quot;_source&quot; : &#123; # 数据的具体内容。 &quot;id&quot; : 4, &quot;title&quot; : &quot;***&quot;, &quot;content&quot; : &quot;***&quot; &#125; &#125;] &#125;&#125;]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汇编基础]]></title>
    <url>%2Fstudy%2Fassembly.html</url>
    <content type="text"><![CDATA[一、进制 进制的意思可以理解为用多少个字符去表示数字(10进制就是用10个阿拉伯数字去计数，2进制可以用0和1进行计数)，自己也可以创造出特殊的字符进行计数 1.1 进制的计数123456一进制，逢1近1二进制，逢2近1...十进制，逢10近1 (0,1,2,3,4,5,6,7,8,9)...十六进制，逢16近1 （0,1,2,3,4,5,6,7,8,9,a,b,c,d,e,f） 用1-4的进制去表示10进制 12345678910# 一进制表示（1）1，2，3，41, 11, 111, 1111# 二进制表示（0，1）0，1，2，3，4, 5, 6, 70, 1, 10, 11, 100, 101, 110, 111# 三进制表示(0，1，2) 0，1，2，3，4, 5, 6, 7, 8, 90, 1, 2, 10, 11, 12, 20, 21, 22# 四进制表示(0, 1, 2, 3)0，1，2，3，4, 5, 6, 7, 8, 9, 100, 1, 2, 3, 10, 11, 12, 13, 20, 21, 22# 六进制表示(0, 1, 2, 3, 4, 5 ... 16)0, 1, 2, 3, 4, 5, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24 1.2 进制的运算1.2.1 8进制的加法表 1+1=2 1+2=3 2+2=4 1+3=4 2+3=5 3+3=6 1+4=5 2+4=6 3+4=7 4+4=10 1+5=10 2+5=7 3+5=10 4+5=11 5+5=12 1+6=7 2+6=10 3+6=11 4+6=12 5+6=13 6+6=14 1+7=10 2+7=11 3+7=12 4+7=13 5+7=14 6+7=15 7+7=16 1.2.2 8进制的乘法表 1*1=1 1*2=2 2*2=4 1*3=3 2*3=6 3*3=11 1*4=4 2*4=10 3*4=14 4*4=20 1*5=5 2*5=12 3*5=17 4*5=24 5*5=31 1*6=6 2*6=14 3*6=22 4*6=30 5*6=36 6*6=44 1*7=7 2*7=16 3*7=5 4*7=34 5*7=43 6*7=52 7*7=61 1.2.3 8进制的加法12345# 运算的本质就是计数 236+215 # 5+6等于13近1余3，3+4等于4加上之前的1为5，----- 453 1.2.4 8进制的减法1234 325-216 # 个位数5-6不够向前借1位就是15-6为7，十位数2被借了一位就是1-1位0，百位3-2位1----- 107 1.2.5 8进制的乘法12345678 123 *456 # 3*6为22进2余2，2*6为14加上之前的2为进1余6,1*6为6加上之前的1为7------ 762 # 3*5为17进1余7，2*5为12加上之前的1为进1余3，1*5为5加上之前的1为6 637 # 3*4为14近1余4，2*4为10加上之前的1为近1余1，1*4为4加上之前的1为5 514 # 2+0为2，6+7为15进1余5，7+3+4+1为17近1余7，6+1+1为10近1余0，5+1为6------ 60752 1.2.6 8进制的除法1234 56/12 # 除法就是要算乘法，最接近的数字。12*4为50不够，12*5为62多了。因此56/12为4还有余数－－－ 4 1.3 二进制计算机使用的就是二进制进行计数的 , 晶体管有电表示1没电表示0。从硬件中看计算机的信号限制在0-2伏低电压(用0表示)和2-5伏高电压(用1表示)的范围。计算机的物理构成是数字电路, 数字电路的基本构成是逻辑门电路，逻辑门电路的理论基础是布尔逻辑运算，而布尔运算的结果只有两种，二进制每一位正好能表示两种布尔运算的结果。故计算机的计算都是二进制 1个16进制数得用 4个二进制数才能表示，因此32位的计算机的内存地址由8个16进制表示。 1.4 Byte二进制数系统中，每个0或1就是一个位(bit)。字节是常用的计算机存储空间的大小。1个字节(Byte)就等于8个位(bit)。于是在无符号的情况下(没有正负之分),1个字节最大的容量就是2^8-1＝255，00000000 就是0，也就是说一个字节能存0-255这256个数字。如果有符号的话8个位的第一个格子用来表示正号或是负号，那么11111111 就是-2^7=-128，01111111 就是127 。这样算下来也是存储了256位，这就是为什么java中一个字节的大小取值范围是-128~127了。以下计算了java中所有的基本数据类型大小的取值范围（其中浮点类型的e+38表示是乘以10的38次方，同样，e-45表示乘以10的负45次方）: 类型 长度字节 范围 存储位数 byte(字节) 1 -128~127 2^8 short(短整型) 2 -32768~32767 2^16 int(整数) 4 -2147483648~2147483647 2^32 long(长整) 8 -9223372036854775808 ~ 9223372036854775807 2^64 char(字符) 2 0~65535 2^16 float(浮点) 4 3.402823e+38 ~ 1.401298e-45 2^32 double(双精度) 8 1.797693e+308~ 4.9000000e-324 2^64 boolean(布尔) 1 true~false 2^8 l 上面的字节可以看出在计算机中用一个数的最高位来存储符号，正数为0，负数为1。 二 原码、反码、补码 原码：将一个整数转换为的二进制就是原码,如: 5的原码为：0000 0101；-5的原码为1000 0101 反码: 正数的反码就是原码，负数的符号位一定是1其余与原码取反。如：如单字节的5的反码为：0000 0101；-5的反码为1111 1010（为了解决原码做减法的问题, 出现了反码）。 补码：正数的补码就是原码，负数的符号位一定是1之后反码+1就是补码。如：字节的5的补码为：0000 0101；-5的原码为1111 1011（发现用反码计算减法, 结果的真值部分是正确的.，有问题的就出现在”0”这个特殊的数值上，为了解决这个问题就有了补码）。 123456789# 例子:1# 原码 0 0 0 0 0 0 0 1# 反码 0 0 0 0 0 0 0 1# 补码 0 0 0 0 0 0 0 1# 例子:-1# 原码: 1 0 0 0 0 0 0 1# 反码: 1 1 1 1 1 1 1 0# 补码: 1 1 1 1 1 1 1 1 真值：因为第一位是符号位，所以机器数的形式值就不等于真正的数值。例如上面的有符号数 10000011，其最高位1代表负，其真正数值是 -3 而不是形式值131（10000011转换成十进制等于131）。所以，为区别起见，将带符号位的机器数对应的真正数值称为机器数的真值。 计算机中用加法代替了减法省去了减法器( 1-1 = 1+(-1) )，在计算机中负数的真值是用补码表示的。因为人脑可以知道第一位是符号位, 在计算的时候我们会根据符号位, 选择对真值区域的加减， 但是对于计算机, 加减乘数已经是最基础的运算, 要设计的尽量简单. 计算机辨别”符号位”显然会让计算机的基础电路设计变得十分复杂! 当需要一个减法时就等于加上它的相反数，既然其补码就是其相反数，我们加上其补码不就可以了。, 即: 1-1 = 1 + (-1) = 0 , 所以机器可以只有加法而没有减法, 这样计算机运算的设计就更简单了 三、位运算3.1 与运算(and &amp;)两个都为1才为1 12341011 00010101 0010----------0001 0000 3.2 或运算(or |)其中一个为1就为1 12340101 11011001 0001----------1101 1101 3.3 异或(xor ^)不相同为1 12341101 00011010 0011----------0111 0010 3.4 非(not ~)0就是，1就是0，单目运算。反码的过程就是非运算 1231110 0001----------0001 1110 3.5位运算（移动位）12340000 0001 # 10进制数字为10000 0010 # 左移动一位，10进制数字为2 (shl &lt;&lt;)高位丢弃，地位补00000 0100 # 左移动一位，10进制数字为4 (shl &lt;&lt;)0000 0010 # 右移动一位，10进制数字为2 (shr &gt;&gt;)地位丢弃，高位正数补0负数补1 操作位的移动就可以让数字成倍增长。汇编语法: 左移 shl，右移 shr，与 and，或 or，非 not，异或 xor。汇编直接操作的是二进制数据。 补充: 32位计算机和64位计算机的区别在于1. 处理数据的能力，理论上64位处理的数据要比32位高很多。2. 寻址能力。32位系统的最大寻址空间是2的32次方=4294967296（bit）= 4（GB）左右；而64位系统的最大寻址空间为2的64次方=4294967296（bit）的32次方，数值大于1亿GB。也就是意味着32位系统最多只能在4GB内存里找东西，64位系统就最大支持的内存高达亿位数， 四、位运行的加减乘除4+5=? 123456789101112131415161718192021222324252627282930313233340000 01000000 0101---------- # 手动算的话0+0为0，1+1进1余0，0+1位10000 1001 # 计算机执行原理# 一、4和5异或，不相同为1其他为0，如果不考虑近位，异或就可以计算出结果0000 01000000 0101---------0000 0001# 二、4和5与运算,两个都为1才为1(判断进位，如果运算结果为0则没有进位)0000 01000000 0101---------0000 0100# 三、将第二步与运算的结果左移一位0000 1000# 四、将第一步异或出来的结果和第三步左移的结果进行异或，不相同为1其他为00000 00010000 1000---------0000 1001# 五，将第一步的结果和第三步的结果进行与运行，判断是否有进位(结果都为0则没有进位)0000 00010000 1000---------0000 0000# 最终的结果就是最后一个与运算为0的上一个异或运算的结果0000 1001 4-5 = 4 + (-5) 123456789101112131415161718190000 01001111 1011---------- # 手动算的话1+0为1，0+1也为11111 1111 # 计算机执行原理# 一、4 + (-5)异或，不相同为1其他为0，如果不考虑近位，异或就可以计算出结果0000 01001111 1011---------1111 1111# 二、4 + (-5)与运算,两个都为1才为1(判断进位，如果运算结果为0则没有进位)0000 01001111 1011---------0000 0000# 最终的结果就是最后一个与运算为0的上一个异或运算的结果1111 1111 s 除法的本质就是减法，减法也是加法，故计算机只会加法。计算机语言的本质就是在进行位运算，都是通过电路实现的。 五、汇编通过指令来代替二进制的编码，用汇编指令就可以给计算机发送一些操作，之后计算机就进行操作。常用工具: Vc6（程序到汇编的理解）,OD，抓包工具，加解密工具 5.1 寄存器CPU 本身只负责运算，不负责储存数据。数据一般都储存在内存之中，CPU 要用的时候就去内存读写数据。但是，CPU 的运算速度远高于内存的读写速度，为了避免被拖慢，CPU 都自带一级缓存和二级缓存。基本上，CPU 缓存可以看作是读写速度较快的内存。但是，CPU 缓存还是不够快，另外数据在缓存里面的地址是不固定的，CPU 每次读写都要寻址也会拖慢速度。因此，除了缓存之外，CPU 还自带了寄存器（register），用来储存最常用的数据。也就是说，那些最频繁读写的数据（比如循环变量），都会放在寄存器里面，CPU 优先读写寄存器，再由寄存器跟内存交换数据。 早期的x86 CPU的8个寄存器: EAX,EBX,ECX,EDX,EDI,ESI,EBP,ESP 5.2 内存 堆(heap) 程序运行的时候，操作系统会给它分配一段内存，用来储存程序和运行产生的数据。这段内存有起始地址和结束地址，比如从0x1000到0x8000，起始地址是较小的那个地址，结束地址是较大的那个地址。程序运行过程中，对于动态的内存占用请求（比如新建对象，或者使用malloc命令），系统就会从预先分配好的那段内存之中，划出一部分给用户，具体规则是从起始地址开始划分（实际上，起始地址会有一段静态数据，这里忽略）。举例来说，用户要求得到10个字节内存，那么从起始地址0x1000开始给他分配，一直分配到地址0x100A，如果再要求得到22个字节，那么就分配到0x1020。这种因为用户主动请求而划分出来的内存区域，叫做 Heap（堆）。它由起始地址开始，从低位（地址）向高位（地址）增长。Heap 的一个重要特点就是不会自动消失，必须手动释放，或者由垃圾回收机制来回收。 栈(stack) 除了 Heap 以外，其他的内存占用叫做 Stack（栈）。简单说，Stack 是由于函数运行而临时占用的内存区域。栈里面通常存储函数里面的局部数据，每个函数被执行到都会新产生一个栈帧并压入到栈里面(入栈),程序执行完成之后就会释放栈帧。如果函数里面还有函数就会产生新的栈帧，指定里面的栈帧执行完成被释放之后，顶层的栈帧才会被释放，由此产生了先进后出的概念。 5.3 汇编指令汇编指令是汇编语言中使用的一些操作符和助记符，还包括一些伪指令（如assume，end），汇编指令同机器指令一一对应。每一种CPU都有自己的汇编指令集。 计算机是通过执行指令来处理数据的，为了指出数据的来源、操作结果的去向及所执行的操作，一条指令一般包含操作码和操作数两部分。 加法指令00000011写成汇编语言就是 ADD。只要还原成二进制，汇编语言就可以被 CPU 直接执行，所以它是最底层的低级语言。 1234567int add_a_and_b(int a, int b) &#123; return a + b;&#125;int main() &#123; return add_a_and_b(2, 3);&#125; gcc -S example.c 之后 1234567891011121314_add_a_and_b: push %ebx # 将 EBX 寄存器里面的值，写入_add_a_and_b这个帧 mov %eax, [%esp+8] # 将 ESP 寄存器里面的地址加上8个字节，得到一个新的地址，然后按照这个地址在 Stack 取出数据。根据前面的步骤，可以推算出这里取出的是2，再将2写入 EAX 寄存器 mov %ebx, [%esp+12] # 将 ESP 寄存器的值加12个字节，再按照这个地址在 Stack 取出数据，这次取出的是3，将其写入 EBX 寄存器。 add %eax, %ebx # 将 EAX 寄存器的值（即2）加上 EBX 寄存器的值（即3），得到结果5，再将这个结果写入第一个运算子 EAX 寄存器。 pop %ebx # 取出 Stack 最近写入的值（即 EBX 寄存器的原始值），再将这个值写回 EBX 寄存器（因为加法已经做完了，EBX 寄存器用不到了） ret # 用于终止当前函数的执行，将运行权交还给上层函数。也就是，当前函数的帧将被回收。_main: # 从_main标签开始执行，会在 Stack 上为main建立一个帧 push 3 # 将运算子放入 Stack，这里就是将3写入main这个帧 push 2 # 将2写入main这个帧 call _add_a_and_b # 表示调用add_a_and_b函数。这时，程序就会去找_add_a_and_b标签，并为该函数建立一个新的帧。 add %esp, 8 # 将 ESP 寄存器里面的地址，手动加上8个字节，再写回 ESP 寄存器。这是因为 ESP 寄存器的是 Stack 的写入开始地址，前面的pop操作已经回收了4个字节，这里再回收8个字节，等于全部回收。 ret # main函数运行结束，ret指令退出程序执行 5.4 内存复制在汇编中，当我们需要把内存中的数据从一个地方复制到另一个地方的时候就会用到EDI和ESI MOVS指令：移动数据 内存-内存 5.5 堆栈的指令汇编里把一段内存空间定义为一个栈，栈总是先进后出，栈的最大空间为 64K。由于 “栈” 是由高到低使用的，所以新压入的数据的位置更低，ESP 中的指针将一直指向这个新位置，所以 ESP 中的地址数据是动态的。 5.6 汇编函数 当应用程序需要相同代码时，不必多次重新编写代码，有时候最好创建包含代码的单一函数（function），然后可以在程序中的任何位置调用这个函数。函数包含完成特定例程所需的所有代码，而且不需要主程序中任何代码的帮助。数据从主程序传递给函数，然后结果返回给主程序。 5.7 堆栈传参主程序在调用子程序之前，将需要传递的参数依次压入堆栈，子程序从堆栈中取入口参数；子程序调用结束之前，将需要返回的参数依次压入堆栈，主程序在堆栈中取出参数 5.8 堆栈平衡 如果要返回父程序，则当我们在堆栈中进行堆栈操作的时候，一定要保证在RET这条指令之前，ESP指向的是压入的我们压入的地址 如果通过堆栈传递参数了。那么在程序执行完毕后，要平衡因参数导致的堆栈变化 六、 参考 汇编语言基础: http://c.biancheng.net/view/3534.html 原码、反码、补码: https://www.cnblogs.com/zhangziqiu/archive/2011/03/30/ComputerCode.html 汇编: https://www.bilibili.com/video/BV1ni4y1G7B9?p=8 入门: https://www.ruanyifeng.com/blog/2018/01/assembly-language-primer.html 32位计算机和64位计算机的区别: https://www.jianshu.com/p/d0e95bed5b60 内存复制指令: https://www.jianshu.com/p/bd0db6f54d81 参数传递：https://blog.csdn.net/u011640816/article/details/35981783 堆栈平衡：https://blog.csdn.net/qq_43573676/article/details/104376354 汇编函数：https://my.oschina.net/u/2537915/blog/698182]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>assembly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logstash安装学习]]></title>
    <url>%2Ftool%2Flogstash.html</url>
    <content type="text"><![CDATA[一、简介1.1 描述Logstash是用Ruby开发的软件，在配置文件中用{}定义作用域，处理数据的时候主要分3个方面去处理输入、过滤、输出。通过各种渠道去获取数据，在进行加工之后将数据输出的存储的容器。可以作为数据库之间的同步工具，最主要的作用是去获取日志文件结合elasticsearch去进行日志分析。内部主要的处理流程如下： 1.2 官网介绍Logstash 是免费且开放的服务器端数据处理管道，能够从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的“存储库”中。 1.3 实际应用 数据采集工具(主要用于日志采集)：最常用的就是ELK进行日志的收集，将各个服务中的日志采集后放入elasticsearch里面。之后用kibanna进行日志分析。 同步数据库(mysql/oracle)中的数据到elasticsearch里面进行快速的文档查找。一般mysql建议用阿里巴巴的canal进行数据同步，这种同步是通过binlog日志进行同步的，不会影响到数据库。如果同步周期比较大，也可以使用logstash进行同步，logstash是通过执行sql语句后将返回数据进行同步的。 二、安装 下载安装包,地址: https://www.elastic.co/cn/downloads/logstash 重要的就是配置文件，如下完成mysql到elasticserch的数据同步： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# 输入input &#123; jdbc &#123; jdbc_driver_library =&gt; &quot;/home/mysql-connector-java-5.1.10.jar&quot; jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot; jdbc_connection_string =&gt; &quot;jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false&quot; jdbc_user =&gt; &quot;root&quot; jdbc_password =&gt; &quot;123456&quot; # 设置监听间隔 各字段含义（从左至右）分、时、天、月、年，全为*默认含义为每分钟都更新 schedule =&gt; &quot;* * * * *&quot; # 查询sql，可以通过更新字段来区分那些是需要更新的 statement_filepath =&gt; &quot;/home/logstash-7.8.0/config/complete.sql&quot; # 记录最后的运行时间，注意目录需要创建好 last_run_metadata_path =&gt; &quot;/home/logstash-7.8.0/config/logstash_jdbc_last_run_oracle&quot; use_column_value =&gt; false tracking_column =&gt; &quot;update_time&quot; # 分页处理数据 jdbc_paging_enabled =&gt; &quot;true&quot; jdbc_page_size =&gt; &quot;50000&quot; # 类型，对象后面输出的类型 type =&gt; &quot;complete_corporate&quot; &#125;&#125;# 过滤filter &#123; # 用ruby解决相差8小时的时区问题, update_time必须要通过statement_filepath配置的sql可以查询出来 ruby &#123; code =&gt; &quot;event.set(&apos;update_time&apos;, event.get(&apos;update_time&apos;).time.localtime + 8*60*60)&quot; &#125;&#125;# 输出output &#123; if[type] == &quot;complete_corporate&quot;&#123; elasticsearch &#123; hosts =&gt; &quot;localhost:9200&quot; user =&gt; elastic password =&gt; elastic # 索引名 index =&gt; &quot;complete_corporate_index&quot; # 文档名 document_type =&gt; &quot;complete_corporate&quot; # 文档ID(主键) document_id =&gt; &quot;%&#123;body_card_no&#125;&quot; &#125; &#125; # 将数据输出到控制台 stdout &#123; codec =&gt; json_lines &#125;&#125; 操作命令 123456// 解压缩tar -zxf xxx.tar.gz// 指定配置文件启动命令./logstash -f jdbc_sync.conf// 后台运行启动命令nohup ./logstash -f jdbc_sync.conf &amp; 三、配置3.1 input，数据的来源 file: 输入为文件类型，通常可以去读取日志 123456789101112131415161718192021input&#123; file&#123; #path属性接受的参数是一个数组，其含义是标明需要读取的文件位置 path =&gt; [‘pathA’，‘pathB’] #表示多就去path路径下查看是够有新的文件产生。默认是15秒检查一次。 discover_interval =&gt; 15 #排除那些文件，也就是不去读取那些文件 exclude =&gt; [‘fileName1’,‘fileNmae2’] #被监听的文件多久没更新后断开连接不在监听，默认是一个小时。 close_older =&gt; 3600 #在每次检查文件列 表的时候， 如果一个文件的最后 修改时间 超过这个值， 就忽略这个文件。 默认一天。 ignore_older =&gt; 86400 #logstash 每隔多 久检查一次被监听文件状态（ 是否有更新） ， 默认是 1 秒。 stat_interval =&gt; 1 #sincedb记录数据上一次的读取位置的一个index sincedb_path =&gt; ’$HOME/. sincedb‘ #logstash 从什么 位置开始读取文件数据， 默认是结束位置 也可以设置为：beginning 从头开始 start_position =&gt; ‘beginning’ #注意：这里需要提醒大家的是，如果你需要每次都从同开始读取文件的话，关设置start_position =&gt; beginning是没有用的，你可以选择sincedb_path 定义为 /dev/null &#125; &#125; jdbc: 输入为数据库，同步数据是可以使用 1234567891011121314151617181920212223242526272829303132333435363738394041input&#123; jdbc&#123; #jdbc sql server 驱动,各个数据库都有对应的驱动，需自己下载 jdbc_driver_library =&gt; &quot;/etc/logstash/driver.d/sqljdbc_2.0/enu/sqljdbc4.jar&quot; #jdbc class 不同数据库有不同的 class 配置 jdbc_driver_class =&gt; &quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot; #配置数据库连接 ip 和端口，以及数据库 jdbc_connection_string =&gt; &quot;jdbc:sqlserver://200.200.0.18:1433;databaseName=test_db&quot; #配置数据库用户名 jdbc_user =&gt; #配置数据库密码 jdbc_password =&gt; #上面这些都不重要，要是这些都看不懂的话，你的老板估计要考虑换人了。重要的是接下来的内容。 # 定时器 多久执行一次SQL，默认是一分钟 # schedule =&gt; 分 时 天 月 年 # schedule =&gt; * 22 * * * 表示每天22点执行一次 schedule =&gt; &quot;* * * * *&quot; #是否清除 last_run_metadata_path 的记录,如果为真那么每次都相当于从头开始查询所有的数据库记录 clean_run =&gt; false #是否需要记录某个column 的值,如果 record_last_run 为真,可以自定义我们需要表的字段名称， #此时该参数就要为 true. 否则默认 track 的是 timestamp 的值. use_column_value =&gt; true #如果 use_column_value 为真,需配置此参数. 这个参数就是数据库给出的一个字段名称。当然该字段必须是递增的，可以是 数据库的数据时间这类的 tracking_column =&gt; create_time #是否记录上次执行结果, 如果为真,将会把上次执行到的 tracking_column 字段的值记录下来,保存到 last_run_metadata_path 指定的文件中 record_last_run =&gt; true #们只需要在 SQL 语句中 WHERE MY_ID &gt; :last_sql_value 即可. 其中 :last_sql_value 取得就是该文件中的值 last_run_metadata_path =&gt; &quot;/etc/logstash/run_metadata.d/my_info&quot; #是否将字段名称转小写。 #这里有个小的提示，如果你这前就处理过一次数据，并且在Kibana中有对应的搜索需求的话，还是改为true， #因为默认是true，并且Kibana是大小写区分的。准确的说应该是ES大小写区分 lowercase_column_names =&gt; false #你的SQL的位置，当然，你的SQL也可以直接写在这里。 #statement =&gt; SELECT * FROM tabeName t WHERE t.creat_time &gt; :last_sql_value statement_filepath =&gt; &quot;/etc/logstash/statement_file.d/my_info.sql&quot; #数据类型，标明你属于那一方势力。单了ES哪里好给你安排不同的山头。 type =&gt; &quot;my_info&quot; &#125; #注意：外载的SQL文件就是一个文本文件就可以了，还有需要注意的是，一个jdbc&#123;&#125;插件就只能处理一个SQL语句， #如果你有多个SQL需要处理的话，只能在重新建立一个jdbc&#123;&#125;插件。&#125; beats: 输入为接收端口 12345678input &#123; beats &#123; #接受数据端口 port =&gt; 5044 #数据类型 type =&gt; &quot;logs&quot; &#125;&#125; redis: 输入为redis 123456789input&#123; redis &#123; host =&gt;&quot;192.168.200.21&quot; port =&gt;&quot; 6379&quot; db =&gt;&quot;6&quot; data_type =&gt;&quot;list&quot; key=&quot;demo&quot; &#125;&#125; 3.2 filter，数据的处理 date: 处理时间格式 123456filter &#123; date &#123; # 解析名为logdate的字段以设置Logstash时间戳 match =&gt; [ &quot;logdate&quot;, &quot;MMM dd yyyy HH:mm:ss&quot; ] &#125;&#125; grok: 将非结构化事件数据分析到字段中。 这个工具非常适用于系统日志 12345filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;IP:client&#125; %&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; %&#123;NUMBER:bytes&#125; %&#123;NUMBER:duration&#125;&quot; &#125; &#125;&#125; dissect: 使用分隔符将非结构化事件数据提取到字段中。 解剖过滤器不使用正则表达式，速度非常快。 12345filter &#123; dissect &#123; mapping =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;ts&#125; %&#123;+ts&#125; %&#123;+ts&#125; %&#123;src&#125; %&#123;prog&#125;[%&#123;pid&#125;]: %&#123;msg&#125;&quot; &#125; &#125;&#125; mutate: 使用最频繁的操作，可以对字段进行各种操作，比如重命名、删除、替换、更新等 12345filter&#123; mutate&#123; convert =&gt; &#123;&quot;age&quot; =&gt; &quot;integer&quot;&#125; &#125;&#125; 3.3 output，数据的输出 elasticsearch：将数据导入到elasticsearch 12345678910111213141516171819# 输出output &#123; if[type] == &quot;complete_corporate&quot;&#123; elasticsearch &#123; hosts =&gt; &quot;localhost:9200&quot; user =&gt; elastic password =&gt; elastic # 索引名 index =&gt; &quot;complete_corporate_index&quot; # 文档名 document_type =&gt; &quot;complete_corporate&quot; # 文档ID(主键) document_id =&gt; &quot;%&#123;body_card_no&#125;&quot; &#125; &#125; stdout &#123; codec =&gt; json_lines &#125;&#125; jdbc：将数据导入的数据库 1234567891011output &#123; jdbc &#123; driver_jar_path =&gt; &quot;/path/mysql-connector-java-5.1.40.jar&quot; driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot; connection_string =&gt; &quot;jdbc:mysql://sss:8840/testcase&quot; username =&gt; &quot;root&quot; password =&gt; &quot;123456&quot; statement =&gt; [&quot;INSERT INTO test ( val, name_val, level_val, source_name, version ) VALUES (?,?,?,?,?)&quot;,&quot;code&quot;,&quot;name&quot;,&quot;level&quot;,&quot;source_name&quot;,&quot;current_version&quot;] &#125; stdout &#123;&#125;&#125; redis：将数据导入到redis 123456789output &#123; redis &#123; host =&gt;&quot;192.168.200.21&quot; port =&gt;&quot; 6379&quot; db =&gt;&quot;6&quot; data_type =&gt;&quot;list&quot; key=&quot;demo&quot; &#125;&#125; file：将数据生成文件 123456789output&#123; if [type] != &quot;file&quot; &#123; file&#123; path =&gt; &quot;/home/app/logbak/%&#123;+YYYY.MM.dd&#125;-file.txt&quot; # 设置根据原始数据格式保存，不会带Json格式 codec =&gt; line &#123;format =&gt; &quot;%&#123;[collectValue]&#125;&quot;&#125; &#125; &#125;&#125; json: 将字段内容为json格式的数据进行解析 123456filter &#123; json &#123; source =&gt; &quot;message&quot; #要解析的字段名 target =&gt; &quot;msg_json&quot; #解析后的存储字段，默认和message同级别 &#125;&#125; geoip: 根据ip地址提供对应的地域信息，比如经纬度、城市名等 12345filter &#123; geoip &#123; source =&gt; &quot;clientip&quot; &#125;&#125; ruby: 最灵活的插件，可以以ruby语言来随心所欲的修改Logstash Event对象 1234567891011filter&#123; ruby&#123; code =&gt; &apos;size = event.get(&quot;message&quot;).size; event.set(&quot;message_size&quot;,size)&apos; &#125;&#125;ruby &#123; code =&gt; &quot;event.set(&apos;@read_timestamp&apos;,event.get(&apos;@timestamp&apos;))&quot;&#125; 四、遇到的问题4.1 时区问题Elasticsearch 内部，对时间类型字段，是统一采用 UTC 时间，存成 long 长整形数据的！对日志统一采用 UTC 时间存储，是国际安全/运维界的一个通识——欧美公司的服务器普遍广泛分布在多个时区里。使用ruby过滤就可以了。 4.2 和filebeat的对比选择filebeat是一个轻量级的日志收集器，如果每台服务器上面都安装一个logstash的话会造成性能的浪费。常用的做法就是通过filebeat将日志收集起来发送给logstash，之后logstash将数据同步给elasticsearch或者数据库。 五、参考 输入(input): https://yq.aliyun.com/articles/152043?utm_content=m_27192 过滤(filter): https://blog.csdn.net/wfs1994/article/details/80862952 输出(output): https://www.cnblogs.com/niutao/p/10909461.html]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>logstash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM学习]]></title>
    <url>%2Fjava%2Fjvm.html</url>
    <content type="text"><![CDATA[一、JVM运行时数据区 1.1 线程私有 程序计数器(Program Counter Register) 本地方法栈(Native Method Stack) 虚拟机栈(VM Stack) 1.2 线程共享 堆(Heap) 方法区(Method Area) 二、名词解释2.1 程序计数器指向当前线程所执行的字节码指令的行号(地址)，是一块较小的内存空间。是线程在让出时间片的时候记录的行号，下次线程获取到时间片之后就可以从程序计数器记录的行号处执行程序。各个线程之间的程序计数器独立存储互不影响，是唯一一个不会出现内存溢出的区域，字节码解释器通过改变程序计数器来依次读取指令,从而实现代码的流程控制。 2.2 本地方法栈和虚拟机栈类似，区别就是虚拟机栈执行的是java方法服务，本地方法栈执行的Native方法服务。 2.3 虚拟机栈也叫java栈，由多个栈帧组成。栈帧是虚拟机进行方法调用和执行的数据结构。一个方法从调用开始到执行完成，就是一个栈帧在虚拟机中的入栈到出栈的过程。每个栈帧都包含局部变量表、方法出口、操作数栈、动态链接。 局部变量表: 存放方法参数和方法内部定义的局部变量 操作数栈：操作栈，后入先出栈。调用其他方法时通过操作数栈进行传递参数 动态链接：堆中的对象是指向方法区中的一个类元信息的，类元信息是指向具体的类的，通过动态链接，就可以让对象直接指向类 方法出口：方法结束的时候要进行当前栈帧出栈，方法正常返回或者出现异常返回数据是用来帮助恢复上层方法的执行状态。 2.4 堆Java虚拟机中内存最大的一块，是垃圾回收最重要的区域也叫gc堆。用来存放对象实例，几乎所有的对象实例和数组都在这里分配内存。按照垃圾回收的分代垃圾回收算法可以分为新生代、老年代 新生代：新生代又分为伊甸园和幸存区 伊甸园(eden)：新生的对象都存放到此区域，在进行一次垃圾回收(minor GC)之后就会将对象的年龄加1，并把对象移动到幸存区 幸存区有两个为了在进行一次垃圾清理之后把幸存的对象存放在另一块区域From Survivor、To Suvrivor。每次清理都会将对象的年龄加1，默认对象的年龄达到15岁(通过参数 - XX:MaxTenuringThreshold设置)之后就会把对象移动到老年代 老年代：老年代中的对象生命周期长、存活率高、回收的速度就比较慢(major GC)。但是当老年代的内存满了之后就会出发一次完整的垃圾回收(full gc 新生代老年代的完整回收会造成STW) 2.5 方法区2.5.1 永久代保存被加载过的每一个类的信息，这些信息由类加载器在加载类的时候，从类的源文件中抽取出来，static变量信息也保存在方法区中(类的元数据)。方法区是线程共享的如果多个线程使用一个类的时候如果这个类没有被加载，则只有一个线程去加载类信息，其他线程等待(永久代就是HotSpot虚拟机对虚拟机规范中方法区的一种实现方式java8之前) 2.5.2 元空间HotSpot虚拟机在java8之后已经取消了永久代，改为元空间，类的元信息被存储在元空间中。元空间没有使用堆内存，而是与堆不相连的本地内存区域。所以，理论上系统可以使用的内存有多大，元空间就有多大，所以不会出现永久代存在时的内存溢出问题。这项改造也是有必要的，永久代的调优是很困难的，虽然可以设置永久代的大小，但是很难确定一个合适的大小，因为其中的影响因素很多，比如类数量的多少、常量数量的多少等。永久代中的元数据的位置也会随着一次full GC发生移动，比较消耗虚拟机性能。同时，HotSpot虚拟机的每种类型的垃圾回收器都需要特殊处理永久代中的元数据。将元数据从永久代剥离出来，不仅实现了对元空间的无缝管理，还可以简化Full GC以及对以后的并发隔离类元数据等方面进行优化。 2.5.3 扩展 JDK版本 方法区的实现 运行时常量池所在的位置 JDK6 PermGen space（永久代） PermGen space（永久代） JDK7 PermGen space（永久代） Heap（堆） JDK8 Metaspace（元空间） Heap（堆） 为什么java8要移除永久代 字符串存在永久代中，容易出现性能问题和内存溢出 类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出 永久代会为 GC 带来不必要的复杂度，并且回收效率偏低 三、参考 元空间： https://www.jianshu.com/p/66e4e64ff278 虚拟机栈：https://www.jianshu.com/p/ecfcc9fb1de7 永久代和元空间的区别：https://blog.csdn.net/xiaojin21cen/article/details/104267301 执行引擎：https://juejin.im/entry/589546638d6d8100583615ee]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于WebCenter的一些想法]]></title>
    <url>%2Fjava%2FwebCenterIdea.html</url>
    <content type="text"><![CDATA[在前一家公司上班的时候写了两个官网和一个教育类型的网站这种网站都需要一个后台的管理系统用来管理后台用户、权限、角色，这些功能都差不多是一样的，后台的UI框架结构也是一样的。开始的时候是用jQuery+html写了头部、菜单栏、底部这些公用的html，之后又用Vue写了头部、菜单栏、底部。基本上每个后台管理项目都需要写这些公用的模块，前前后后都写了好多次这种代码。在空闲的时候想了一下，如果后面还有这种类似的网站的话，也是避免不了会写这种重复的代码，感觉会有如下几种弊端: 为了简化开发直接复制之前的代码，在复制代码之后需要花大量的时间去调试程序排查是否有复制遗漏的地方。 每次都重写这种代码的话，工作量势必会增加，而且还是重复性的工作。 想利用了面向对象三大特征之一的封装特征，把这些公用的功能都封装在一起。以后就不用在写这种重复的代码了。这段时间公司也在使用XXL-JOB分布式调度工具，XXL-JOB就是一个服务端和多个客服端的模式，服务端负责调度其他的客户端。于是就想有一个服务端专门负责管理用户、权限、角色、菜单这些功能。然后客服端去调用服务端提供的接口就可以实现这些重复的功能了。于是在空闲的时候就开发了一个乞丐版的Webcenter如下: 服务端：提供SSO单点登录功能、用户管理、角色管理、系统管理、菜单管理、权限管理等功能。 客户端脚手架: 用来初始化SpringBoot项目和Vue后台项目，目的就是为了不写重复的代码。 有了这个服务端之后，以后开发后台管理系统只需要启动服务端，然后利用客服端脚手架即可快速创建后台管理系统。在已经安装了redis和mysql的情况下基本上只需要10分钟就可以进行自己业务逻辑的开发了。也不知道功能怎么样，希望大家提供宝贵的意见。项目地址：https://github.com/gaoqisen/gqs-webcenter]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单的权限管理小工具]]></title>
    <url>%2Fjava%2Fwebcenter.html</url>
    <content type="text"><![CDATA[GQS-WEBCENTER, 一个轻量级的WEB中心，简单的权限管理(乞丐版) 一、简介1.1 概述之前开发了好几个后台的管理系统，每次都需要写一遍登录逻辑、菜单路由、用户管理、角色管理、权限管理这些功能。为了以后再开发这种系统的时候不用再写这些重复的程序，就把这些通用的功能抽象成为了一个简单的权限管理服务(WebCenter)，WebCenter专门负责单点登录、权限管理、菜单配置、用户管理、角色管理、系统管理等。为了在创建系统的时候更简单，于是开发了一个gqs-webcenter-client.jar并上传到了中央仓库，之后创建系统的时候只需要引入这个jar包就可以集成WebCenter。每次创建项目的时候后端都需要添加配置引入jar包，前端都需要配置动态路由，为了简化到都不用复制重复的代码，于是开发了一个web-cli的npm脚手架。在安装脚手架之后就可以直接初始化项目并进行业务逻辑的开发。 1.2 特性 简单：安装好WebCenter服务端后，后端项目引入gqs_webcenter_client.jar。前端利用webc脚手架初始化项目，即可进行业务逻辑的开发。 动态：服务端可以动态配置各个系统的菜单、菜单图标、角色、权限、以及REST接口的权限。 1.3 功能 用户管理：增加多个用户，管理用户的账号密码等 角色管理：动态分配角色的权限，前端页面进行权限控制之后，可以实现不同的角色登录展示不同的菜单。 REST接口管理：各个系统注册到服务端后可以配置接口的调用权限（所有人可以访问、登录后可以访问、必须有权限才可以访问） 系统管理：给各个系统分配clientId和密匙，用于系统的单点登录 菜单管理：管理各个系统的菜单、路由、图标等。 1.4 下载 介绍 地址 后端 https://github.com/gaoqisen/gqs-webcenter 前端 https://github.com/gaoqisen/webcenter-vue-cli 1.5 环境Maven3+Jdk1.8+Mysql5.7+Vue3.10.0+Webpack4.0.0+ 二、快速入门2.1 运行Webcenter服务端2.1.1 方式一(docker 推荐) 先执行 docker network create net_webcenter 创建网络。该docker-compose安装了redis、mysql和webcenter3个服务，是否暴露端口可以自行修改。如果本地已经安装了mysql和redis可以只安装my_webcenter容器，安装的时候需要将容器之前的容器名改为db_mysql和db_redis并创建net_webcenter网络将db_mysql和db_redis加入到该网络中。启动成功之后将sql导入到数据库中访问 http://localhost:8000 即可。docker容器通信可以参考: https://www.cnblogs.com/kevingrace/p/6590319.html 123456789101112131415161718192021222324252627282930313233343536373839404142434445version: &apos;2.0&apos;services: db_mysql: restart: always image: mysql:5.7.22 container_name: db_mysql ports: - 3306:3306 environment: TZ: Asia/Shanghai MYSQL_ROOT_PASSWORD: 123456 command: --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci --explicit_defaults_for_timestamp=true --lower_case_table_names=1 --max_allowed_packet=128M --sql-mode=&quot;STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZERO&quot; volumes: - ./mysqldata:/var/lib/mysql networks: - net db_redis: image: redis container_name: db_redis command: redis-server --requirepass 123456 restart: always ports: - &quot;6379:6379&quot; volumes: - ./redisdata:/data networks: - net my_webcenter: image: registry.cn-hangzhou.aliyuncs.com/gqs/webcenter:1.0.1 container_name: my_webcenter ports: - &quot;8000:8000&quot; networks: - netnetworks: net: external: # 请先创建net_webcenter网络 name: net_webcenter 2.1.2 方式二(jar包) 环境准备 请先安装Redis、Mysql、JDK1.8。 获取 “WebCenter数据库初始化SQL脚本(/db/webcenter.sql)” 并执行。 获取jar包 github: https://github.com/gaoqisen/gqs-webcenter/releases gitee: https://gitee.com/gaoqisen/gqs-webcenter/releases 网盘: https://c-t.work/s/8db595c7ac4f44 密码: 7x8yr4 启动jar包 1234// 默认mysql密码123456，redis密码123456启动nohub jara -Xms1024m -Xmx1024m -jar webcenter-console-1.0.0.jar// 修改mysql密码，redis密码nohup java -Xms1024m -Xmx1024m -jar webcenter-console-1.0.0.jar --spring.database.username=root --spring.database.password=23456 --spring.redis.password=23456 即可访问http://localhost:8000 。 2.2 客户端搭建2.1 方式一(前后端不分离)1234567891011121314// 全局安装webcenter客服端脚手架npm install webc-cli -g// 之前有安装的需要更新到1.0.3版本npm update webc-cli -g// 安装成功之后执行webc命令, 查看是否安装成功webc // 快速搭建项目(搭建的直接就是SpringBoot项目,通过IntelliJ IDEA可以直接运行，前端Vue代码放在src/main/resources/webpage目录下)webc boot// 进入到前端目录cd demo/src/main/resources/webpage// 安装依赖，如果没有安装cnpm需要先安装：npm install cnpmcnpm install// 启动前端服务npm run dev 快速搭建的项目main方法启动之后接口通过http://localhost:8001/ArtifactID 访问 前端项目启动后，开发环境通过http://localhost:8080 访问即可 本地开发时将webcenter.client.forestage配置设置为true，方便本地vue开发。打包上线时改为false。 打包上线运行时，需要先在/src/main/resources/webpage目录下npm run build(将vue静态文件打包到resources/public里面)之后在maven clean install。 打包上线后ArtifactID就是上下文路径，通过http://localhost:8001/ArtifactID 进行访问，如：http://localhost:8001/demo 前后端不分离搭建后，打包为一个jar包，静态文件通过SpringBoot内置的tomcat访问。前后端分离的项目前端静态文件可以用nginx进行代理。(前后端不分离的搭建成功之后就可以开发业务逻辑了) 开发环境搭建完成之后，需要启动3个服务。（Webcenter服务端:8000, Vue前端8080，Maven后端8001） IntelliJ IDEA打开vue的node_modules会出现假死现象，解决办法： Editor&gt;&gt;File Types&gt;&gt;在Ignore files and folders中添加;node_modules 2.2 方式二(前后端分离) 2.2.1 创建Maven后端 创建出springBoot项目之后可以把配置文件改为yml格式，因为后面的配置都是基于yml的。如果需要用properties格式的话可以在https://www.toyaml.com/index.html 里面进行转换。创建成功之后引入maven依赖、添加配置、创建WebCenterConfig.java即可。 Maven引入依赖 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;dependency&gt; &lt;groupId&gt;com.github.gaoqisen&lt;/groupId&gt; &lt;artifactId&gt;gqs-webcenter-client&lt;/artifactId&gt; &lt;version&gt;1.0.1&lt;/version&gt;&lt;/dependency&gt;### pom.xml测试用例&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;demo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;demo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.gaoqisen&lt;/groupId&gt; &lt;artifactId&gt;gqs-webcenter-client&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 添加application.yml的配置 12345678910111213141516171819202122232425262728293031server: port: 8001 servlet: context-path: /samplespring: jackson: default-property-inclusion: non_null date-format: yyyy-MM-dd HH:mm:ss time-zone: GMT+8 application: name: webcenter-sample ### 需要和服务端的redis是同一个 redis: host: localhost password: 123456 port: 6379 timeout: 60000webcenter: # 服务端 server: host: localhost # 如果服务端端口改了的话，此处的端口应保持一致 port: 8000 # 通过服务端的系统管理里面获取 clientid: WZUIIXWZUIIX secretkey: qOIWRbzeFvOnXUYTspfSt2ibfJPe1vtG ### 客服端配置，是否前后端分离，用于单点登录的地址跳转。forestage为false时，host和port可以不写 client: forestage: true host: localhost port: 8080 创建WebCenterConfig.java文件，用于将客户端交给spring管理 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Configurationpublic class WebCenterConfig extends WebMvcConfigurerAdapter &#123; @Bean public SecurityInterceptor securityInterceptor() &#123; return new SecurityInterceptor(); &#125; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(securityInterceptor()).excludePathPatterns(&quot;/static/*&quot;) .excludePathPatterns(&quot;/error&quot;).addPathPatterns(&quot;/**&quot;); &#125; @Bean @DependsOn(&quot;webCenterConsole&quot;) public WebCenterClientBeanFactory springClientBeanFactory() &#123; return new WebCenterClientBeanFactory(); &#125; @Bean public WebCenterInitializing webCenterInitializing() &#123; return new WebCenterInitializing(); &#125; @Bean public WebCenterConsole webCenterConsole()&#123; WebCenterConsole webCenterConsole = new WebCenterConsole(); return webCenterConsole; &#125; @Bean @DependsOn(&quot;redisConnectionFactory&quot;) public ApiController apiController() &#123; return new ApiController(); &#125; @Bean public RedisTemplate&lt;String, String&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; StringRedisTemplate template = new StringRedisTemplate(redisConnectionFactory); template.afterPropertiesSet(); return template; &#125;&#125; 2.2.2 创建Vue前端12345678// 全局安装webcenter客服端脚手架npm install webc-cli -g// 安装成功之后执行webc命令, 查看是否安装成功webc // 查看所有的脚手架webc list// 初始化一个名为sample的前端项目（集成了动态菜单和单点登录）webc init webcenter sample 完成上面的搭建之后，启动Maven后端和Vue前端就可以直接开发自己的业务逻辑了。 三、功能介绍3.1 系统配置给各个系统分配clientId和密匙，应用名称必须和客户端的spring.application.name一致。每新建一个系统都需要生成不同的clientId和密钥，并更改系统的配置。 3.2 权限配置权限配置在新建角色的时候进行配置，如果需要修改权限要在修改角色里面进行修改（修改操作是将之前角色和权限的关联信息全部删除之后，新增选择的权限）。修改角色的权限之后，需要用户退出后重新登陆生效。前端的页面权限用如下代码实现： 1234// 权限将斜杠改为冒号即可。@PathVariable类型的接口去掉/&#123;*&#125;如:// sys/menu/save, sys:menu:save// sys/menu/info/&#123;id&#125;, sys:menu:info&lt;el-button v-if=&quot;isAuth(&apos;sys:menu:save&apos;)&quot; &gt;新增&lt;/el-button&gt; 3.3 菜单配置菜单分为目录和菜单两种，需要单独给每个系统添加菜单和目录，目录可以多层级。路由就是创建的.vue文件的路径。如:/sys/log, 就在views/sys里面创建log.vue。动态路由就会自动路由到log.vue里面。菜单创建好之后需要给对应的角色赋予菜单权限，子系统退出后重新登录生效。 3.4 REST接口配置 后端接口通过@ApiOperation注解标识接口名称，如：@ApiOperation(“接口备注”) rest接口有3种权限：公开、登录、权限。客户端启动之后自动注册接口到服务端默认为公开所有人都可以访问的权限。改为登录接口之后，访问的权限就必须登录之后才可以访问。需要权限的接口级别最高必须在权限里面给角色配置了权限才可以访问。 四、脚手架介绍1234567// 命令webc -h // 查看命令帮助webc -V // 查看版本号webc add // 增加模版webc list // 查看所有的模版webc init webcenter sample // 通过webcenter模版创建一个名为sample的项目webc boot // 快速创建一个springBoot项目 webc add: 可以自己写前端的脚手架。会替换package.json里面用户信息描述等。 webc boot: 创建的是一个固定的格式，包含springBoot和Vue前端的代码。vue代码在resources/webpage里面。在本地开发的时候可以启动两个端口如：8001后端代码，8080前端代码。后面打包的时候在webpage目录下运行npm run build就会把前端的静态代码打包到resources/public里面，在项目根目录下运行maven clean install就可以把前端代码和后端代码打成一个包，开发的时候可以是前后端分离的开发模式，打包之后就是一个jar包，简化了前后端分离的nginx配置。如果需要前后端分离部署的话，只需要把resources/public里面的静态文件拷贝到其他目录下面，nginx指定路径就可以了。 五、结构4.1 Webcenter项目结构12345678910111213──gqs-webcenter ├── db // 数据库 │ └── webcenter.sql // 数据库初始化脚本 ├── gqs-webcenter-client // 客服端 ├── gqs-webcenter-common // 通用工具 ├── gqs-webcenter-component // 通用组件 │ ├── gqs-webcenter-redis // redis组件 │ ├── gqs-webcenter-webapi // swagger组件 ├── gqs-webcenter-console // 控制台，需要编译打包的模块 ├── gqs-webcenter-sample // 简单的客服端例子 ├── gqs-webcenter-service // 服务层，数据访问层 ├── gqs-webcenter-webpage // 前端项目,build之后将静态文件打包到了 gqs-webcenter-console的resource/public里面 └── readme.md // 项目介绍 4.2 数据库结构 名称 表名 描述 sys_code 系统编码表 用来保存系统信息、clientId、密匙等 sys_code_menu 系统菜单关联表 系统和菜单的对应关系 sys_menu 菜单表 保存菜单和目录信息 sys_rest rest接口表 保存各个系统的REST接口和权限 sys_role 角色表 角色的相关信息 sys_role_menu 角色菜单关联表 角色可以查看的菜单 sys_role_rest 角色接口关联表 角色可以访问的接口 sys_user 用户表 用户的相关信息 sys_user_role 角色表 用户关联的角色，一个用户对应多个角色 4.3 Vue项目引入的主要插件。 名称 介绍 版本 地址 element-ui 饿了么后端UI框架 2.8.2 https://element.eleme.cn/2.8/#/zh-CN/component/installation fortawesome 图标库 5.13 http://www.fontawesome.com.cn/faicons/ vue-router 路由 3.0.7 https://cn.vuejs.org/v2/guide/routing.html vuex 状态管理 3.3.0 https://vuex.vuejs.org/zh/ axios HTTP库 0.19.2 http://www.axios-js.com/zh-cn/docs/ 4.4 Vue结构123456789101112131415├── build // 构建├── config // 配置文件├── index.html // 入口文件├── node_modules // 依赖下载的包├── package.json // 依赖├── src | ├── App.vue // 入口 | ├── assets // 静态文件 | ├── components // 组件 | ├── main.js // 入口js文件 | ├── router // 路由 | ├── store // 状态状态管理 | ├── utils // 工具 | └── views // 视图，需要开发的代码位置└── static // 静态文件 六、问答 SpringBoot项目依赖了webcenter-client.jar后集成了那些功能？ 答: 提供了单点登录、动态菜单、动态权限功能。 前端Vue通过脚手架初始化之后有那些功能？ 答：实现了动态路由，菜单直接在服务端的菜单管理里面进行配置。 客服端与服务端之间如何通信？ 答: 之间的通信通过Redis的异步消息队列实现。 七、参考 动态路由：https://github.com/renrenio/renren-fast-vue 脚手架开发：https://juejin.im/post/5c94fef7f265da60fd0c15e8 Maven上传jar包: https://www.sojson.com/blog/250.html]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java springBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 的一些基础命令]]></title>
    <url>%2Fjava%2Fcommand.html</url>
    <content type="text"><![CDATA[1234567891011121314// 查看java运行程序的端口jps// 查看java线程jstack 23606 &gt; test.txt// java性能分析jstat -gc 23606// 查看java内存jmap -dump:format=b,file=test.bin 23579// 查看汇编指令javap -c filename// java控制台jconsole// 查看jvmjvisualvm]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java base</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql存储过程 －学习笔记]]></title>
    <url>%2Fdatabase%2FmsqlStoredProcedure.html</url>
    <content type="text"><![CDATA[一、优势启动服务器后或者第一次执行后(可以设置)就可以把存储过程加载到高速缓存中,这样以后调用起来就不用再通过编译，执行效率当然就高。另外执行存储过程只需要传递几个参数，用语句就需要传递整个sql语句，有效减少网络数据的传递. 二、存储过程1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798-- 创建测试表create table admin_user_1( id int null, role int null);-- 查看视图SELECT * from information_schema.VIEWS;SELECT * from information_schema.TABLES;show procedure status where db='gqs_1';show create procedure gqs_1.test;DROP PROCEDURE gqs_1.test;-- 存储过程 创建一个通过ID删除数据的过程CREATE PROCEDURE delete_matches(IN a_id INTEGER)TEST1:BEGIN DELETE FROM admin_user_0 WHERE id = a_id;END TEST1;-- 查看存储过程show create procedure delete_matches;-- 调用过程call delete_matches(0);-- 定义变量1、用户变量名一般以@开头。2、滥用用户变量会导致程序难以理解及管理select '123' into @a;select @a;set @a = '456';set @a = 1+1+3;-- 在存储过程中使用用户变量CREATE PROCEDURE test() select concat(@add, 'success');set @add = 'ok';call test();-- if elsecreate procedure test1(in args int)begin declare a int; set a = args +1; if a = 2 then INSERT INTO gqs_1.admin_user_1 (id, role) VALUES (6, 8); end if; if args = 0 then update gqs_1.admin_user_1 set role = 6 where id = 8; else update gqs_1.admin_user_1 set role = 5 where id = 8; end if;end;call test1(0);-- casecreate procedure test2(in args int)begin declare a int; set a = args +1; case a when 0 then INSERT INTO gqs_1.admin_user_1 (id, role) VALUES (6, 8); when 1 then update gqs_1.admin_user_1 set role = 8 where id = 8; else update gqs_1.admin_user_1 set role = 5 where id = 8; end case;end;call test1(0);-- for 在操作钱检查结果create procedure test3(in args int)begin declare a int; set a = args +1; while a &lt;6 do INSERT INTO gqs_1.admin_user_1 (id, role) VALUES (a, 8); set a=a+1; end while;end;call test3(2);-- repeat···· end repea 在操作后检查结果create procedure test4()begin declare a int; set a =0; repeat INSERT INTO gqs_1.admin_user_1 (id, role) VALUES (a, 8); set a=a+1; until a &gt;= 5 end repeat;end;call test4();-- loop ·····endloopcreate procedure test5()begin declare a int; set a =0; l:loop INSERT INTO gqs_1.admin_user_1 (id, role) VALUES (a, 8); set a=a+1; if a &gt;=5 then leave l; end if; end loop;end;call test5(); 三、事件调度器Event Scheduler 语法 123456789101112131415161718 -- []: 表示可选，[|]: 单选create[definer = &#123; user | current_user &#125;] // 定义者event[if not exists]event_name // 时间名on schedule schedule // 调度规则// on schedule子句// 1. at timestamp用于创建单次执行的事件，timestamp执行事件执行的时间(如果指定的时间是过去的时间，则会产生一个warning)，时间可以是具体的时间字符串或者是一个datetime类型的表达式(如current_timestamp)：// 如果要指定将来某个时间，直接使用at timestamp，例：at '2017-08-08 08:08:08'；// 如果要指定将来某个时间间隔，可利用interval关键字(interval关键字可以进行组合，at timestamp + INTERVAL 2 HOUR、 + INTERVAL 30 MINUTE)// 2. every子句用于创建重复执行的事件，如果每分钟执行一次，则可以：EVERY 1 MINUTE。// 当然，every子句可以指定一个开始事件和结束时间，通过STARTS和ENDS关键字来表示，具体语法与前面类似// 例如：EVERY 12 HOUR STARTS CURRENT_TIMESTAMP + INTERVAL 30 MINUTE ENDS CURRENT_TIMESTAMP + INTERVAL 4 WEEK。[on completion [not] preserve] //注意特定时间执行的事件，如果设置了该参数，执行完毕后，事件将被删除，不想删除的话可以设置成on completion preserve[enable | disable | disable on slave] // 系统将执行这个事件[comment 'comment'] // 描述do event_body; // 事件体，可以是单行 SQL 语法，或是 BEGIN……END 语句块 例子 123456789101112131415161718192021222324-- 查看事件调度器是否开启SHOW VARIABLES LIKE 'event_scheduler';SELECT @@event_scheduler;-- 开启事件触发器SET GLOBAL event_scheduler = ON;-- 创建一个事件，并调用存储过程CREATE DEFINER=`root`@`localhost` EVENT `test_sche_event` ON SCHEDULE EVERY 5 SECOND STARTS '2016-07-12 22:11:50' ON COMPLETION NOT PRESERVE ENABLE DO CALL `add`;-- 每秒插入一条数据CREATE EVENT e_test ON SCHEDULE EVERY 1 SECOND DO INSERT INTO gqs_1.admin_user_1 (id, role) VALUES (8);-- 每秒插入一条数据通过存储过程CREATE EVENT e_test1 ON SCHEDULE EVERY 1 SECOND DO CALL test();-- 临时关闭事件ALTER EVENT e_test1 DISABLE;-- 开启事件ALTER EVENT e_test1 ENABLE;-- 删除事件DROP EVENT IF EXISTS e_test1; 四、springBoot调用存储过程12@Query(value = &quot;call test(?1) &quot;, nativeQuery = true)int selectdByLike(@Param(&quot;pname&quot;) String pname);]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>mysql procudure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx实现反向代理百度]]></title>
    <url>%2Fnetwork%2FreverseProxy.html</url>
    <content type="text"><![CDATA[反向代理(负载均衡)百度百科反向代理服务器位于用户与目标服务器之间，但是对于用户而言，反向代理服务器就相当于目标服务器，即用户直接访问反向代理服务器就可以获得目标服务器的资源。同时，用户不需要知道目标服务器的地址，也无须在用户端作任何设定。反向代理服务器通常可用来作为Web加速，即使用反向代理作为Web服务器的前置机来降低网络和服务器的负载，提高访问效率 反向代理的用途是将防火墙后面的服务器提供给internet用户访问。同时还可以完成诸如负载均衡等功能 对外是透明的，访问者并不知道自己访问的是代理。对访问者而言，他以为访问的就是原始服务器 对比正向代理(翻墙) 正向代理用途是为了在防火墙内的局域网提供访问internet的途径。另外还可以使用缓冲特性减少网络使用率 正向代理允许客户端通过它访问任意网站并且隐蔽客户端自身，因此你必须采取安全措施来确保仅为经过授权的客户端提供服务 两者的区别在于代理的对象不一样：正向代理代理的对象是客户端，反向代理代理的对象是服务端 安装nginx12345678910111213version: '3.1'services: nginx: restart: always image: nginx container_name: nginx ports: - 8080:80 - 8081:8081 volumes: - ./conf/nginx.conf:/etc/nginx/nginx.conf - ./conf/test.conf:/etc/nginx/test.conf - ./html:/usr/share/nginx/html 创建文件夹12conf // 文件夹下放nginx.conf和test.confhtml // 文件夹下面放html80/index.html文件 nginx.conf123456789101112131415161718192021222324252627282930313233343536373839# 启动进程,通常设置成和 CPU 的数量相等worker_processes 1;events &#123; # epoll 是多路复用 IO(I/O Multiplexing) 中的一种方式 # 但是仅用于 linux2.6 以上内核,可以大大提高 nginx 的性能 use epoll; # 单个后台 worker process 进程的最大并发链接数 worker_connections 1024;&#125;http &#123; # 设定 mime 类型,类型由 mime.type 文件定义 include mime.types; default_type application/octet-stream; # sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用， # 必须设为 on，如果用来进行下载等应用磁盘 IO 重负载应用，可设置为 off，以平衡磁盘与网络 I/O 处理速度，降低系统的 uptime. sendfile on; # 连接超时时间 keepalive_timeout 65; # 设定请求缓冲 client_header_buffer_size 2k; # 配置虚拟主机 192.168.141.121 server &#123; # 监听的 IP 和端口，配置 192.168.141.121:80 listen 80; # 虚拟主机名称这里配置 IP 地址 server_name 192.168.141.121; # 所有的请求都以 / 开始，所有的请求都可以匹配此 location location / &#123; # 使用 root 指令指定虚拟主机目录即网页存放目录 # 比如访问 http://ip/index.html 将找到 /usr/local/docker/nginx/html/html80/index.html # 比如访问 http://ip/item/index.html 将找到 /usr/local/docker/nginx/html/html80/item/index.html root /usr/share/nginx/html/html80; # 指定欢迎页面，按从左到右顺序查找 index index.html index.htm; &#125; &#125; # 引入其他配置 include test.conf;&#125; test.conf12345678910111213141516171819202122232425262728293031323334353637## Basic reverse proxy server #### backend for 16.32 ##upstream uicps &#123;# server 192.168.16.32:59002 weight=1; server www.baidu.com;&#125; ## Start 16.32 ##server &#123; listen 8081; server_name localhost; # access_log logs/proxy34.access.log main;# error_log logs/proxy34.error.log; root html; index index.html index.htm index.php; ## send request back to 16.32 ## location / &#123; proxy_pass http://uicps; #Proxy Settings proxy_redirect off; proxy_set_header Host www.baidu.com; # $host;不能使用$host变量 proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; proxy_max_temp_file_size 0; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; &#125;&#125; 使用docker-compose up启动之后访问http://localhost:8081/，访问到如下页面表示成功。]]></content>
      <categories>
        <category>netword</category>
      </categories>
      <tags>
        <tag>netword</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络原理]]></title>
    <url>%2Fstudy%2FcomputerNetworkTheory.html</url>
    <content type="text"><![CDATA[第一章 计算机网络概述的习题什么是计算机网络将有独立功能的多台计算机，通过通信设备线路链接起来，在网络软件的支持下，实现彼此之间资源共享和数据通信的整个系统。 网络协议的三要素是什么？每个要素的含义是什么？协议三要素: 语法、语义、时序 语法：定义实体之间交换信息的格式与结构，或定义实体之间传递信息的电平等。 语义：定义实体之间交换的信息中需要发送哪些控制信息，这些控制信息的具体含义，以及针对不同含义的控制信息，接受信息端应如何响应。 时序：也成为同步，定义实体之间交换信息的顺序以及如何匹配或适应彼此的速度。 计算机网络的功能是什么在不同主机之间实现快速的信息交换。通过信息交换，计算机网络可实现资源共享这一核心功能，包括硬件资源共享，软件资源共享和信息资源共享。 按网络覆盖范围划分，主要有哪几类计算机网络？各有什么特点？有个域网、局域网、城域网、广域网 个域网：个人设备通过无线通信技术构成的小范围网络，实现个人设备间的数据传输，比如蓝牙技术实现个人设备的互连等（1-10m左右的范围）。 局域网：部署在办公室、办公楼、厂区、校园等局部区域内。采用高速有线或者无线连接主机。（10m-1km） 城域网：覆盖一个城市范围的网络（5-50km） 广域网：覆盖范围在几十到几千千米，跨越更大的地理空间，可以实现异地城域网或局域网的互连。 按网络拓扑划分，主要有哪几类计算机网络？各有什么特点？有星形拓扑结构、总线型拓扑结构、环形拓扑结构、网状拓扑结构、树状拓扑结构、混合拓扑结构。 星形拓扑结构：包括一个中央节点、网络中的主机通过点对点的通信链路与中央节点连接 总线形拓扑结构：采用一条广播信道作为公共传输介质，称为总线，所有节点都和总线连接，节点间的通信都通过共享的总线进行 环形拓扑结构：所有的节点连成一个闭合的环，环中的数据传输通常是单向（也可双向）传输 网状拓扑结构：通过多条链路与不同的节点直接连接 树状拓扑结构：总线形和星形拓扑的网络扩展。 混合拓扑结构：由两种以上简单的拓扑结构网络混合连接而成的网络 计算机网络结构主要包括哪几部分？每部分的主要功能是什么？网络边缘、接入网络、网络核心 网络边缘：连接到网络上的所有端系统 接入网络：是实现网络边缘的端系统与网络核心连接与接入的网络 网络核心：通信链路互连的分组交换设备构成的网络，是实现网络边缘中主机之间的数据中继与转发 简要描述你了解的接入网络，这些接入网络都有什么特点？经常使用的是那类接入网络？ 电话拨号接入：用电话网络接入，方便实现分散的家庭用户接入网络。但是宽带有限 非对称用户线路ADSL：用现有的电话网络的用户线路接入，主要用于家庭用户接入。上行宽带比下行宽带小 混合光钎同轴电缆HFC接入网络：有限电视网络接入，当用户数量较大时，HFC没有ADSL接入速率快 局域网：企业、学校等机构组建的网络，光钎到户之后，很多家庭也采用局域网实现网络接入 移动接入网络：只要利用移动通信网络，智能手机移动终端等接入网络。 请简述电路交换工作过程以及电路交换的特点。过程：建立电路、传输数据、拆除电路特点：有连接的，在通信时需要先建立电路连接，在通信过程中独占一个信道，通信结束后拆除电路连接。优点是实时性高，时延和时延抖动都较小。缺点是：对于突发性数据传输，信道利用率低，传输速率单一。 什么是报文交换？什么是分组交换？试比较两者的优势。 报文交换：发送方把要发送的信息附加上发送／接受主机的地址以及其他控制信息，构成一个完整的报文。然后以报文为单位在交换网络的各结点之间以存储－转发的方式传送 优点：线路利用率高。不会出现通信双方空闲时信道也要被占用的情况。 分组交换：将报文分割成较小的数据块，每个数据块附加上地址、序号等控制信息构成数据分组，每个分组独立传输到目的地，目的地将收到的分组重新组装，还原为报文 优点：交换设备存储容量要求低、交换速度快、可靠传输效率高、更加公平 OSI参考模型包括几层？每层的主要功能是什么？包括七层 物理层：传输介质上实现无结构比特流传输 数据链路层：相邻结点之间数据可靠而有效的传输 网络层：将分组通过交换网络传输至目的地的主机 传输层：端到端的层次，两个主机的进程之间 会话层：用户与用户之间的连接 表示层：处理应用实体间交换数据的语法 TCP/IP参考模型包括几层？每层主要包括哪些协议？包括四层 应用层： TCP/IP 传输层： UDP 网络互联层：ICMP、IGMP、BGP、OSPF、RIP、路由协议 网络接口层 考虑两台主机A和主机B由一条宽带为R(bi/s)、长度为D(m)的链路互连，信号传播速率为V(m/s)。假设主机A从t=0时刻开始向主机B发送分组，分组长度为L位。试求: 传播延迟(时延)dp：传播时延dp = 信道长度(m) / 电磁波在信道上的传播速率(m/s) = D / V 传输延迟dt = 数据帧长度(b) / 信道带宽(b/s) = L / R 总延迟de = 传播时延 + 传输延迟 = D / V + L / R dp &gt; dt意味着最早发送的信号没有到达目的主机之前，数据分组的最后一个比特已经发送出来了，所以分组的第一个比特在距离主机的V * dt米的链路上 时延带宽积 = 传播时延 带宽 = D / V R = 512，解之得D = 1280米 假设主机A向主机B以存储-转发的分组交换方式发送一个大文件。主机A到达主机B的路径上有3段链路，其速率分别是R1=500kbps，R2=2Mbps，R3=1Mbps。试求： 假设网络没有其他流量，则传送该文件的吞吐量是多少？ 假定网络中没有其他流量，R = min{R1+R2+R3} = min{500kbps,2Mbps,1Mbps} = 500kbps 假设文件大小为4MB，则传输该文件到主机B大约需要多少时间？ T = 4MB/R = 4*10^3/500kbps = 64s 计算机网络 时延、发送时延、传输时延、处理时延、排队时延、时延带宽积时延：指数据从网络的一端传送到另一端所需的时间 发送时延（传输时延）：是主机或路由器发送数据帧所需要的时间，也就是从发送数据帧的第一个比特算起，到该帧的最后一个比特发送完毕所需的时间，发送时延 = 数据帧长度(b) / 信道带宽(b/s) 传播时延：是电磁波在信道中传播一定的距离需要花费的时间，传播时延 = 信道长度(m) / 电磁波在信道上的传播速率(m/s) 发送时延（传输时延）发生在机器的内部的发送器中，而传播时延则发生在机器外部的传输信道媒体上。 处理时延：主机或路由器在收到分组时要花费一定的时间进行处理，例如分析分组的首部、从分组中提取数据部分、进行差错或查找适当的路由等等 排队时延：分组在经过网络传输时，要经过许多的路由器。但分组在进入路由器后要现在输入队列中排队等待处理。在路由器确定了转发接口后，还要在输出队列中排队等待转发 数据在网络中经历的总时延就是以上四种时延之和：总时延 = 发送时延 + 传播时延 + 处理时延 + 排队时延 时延带宽积：时延带宽积 = 传播时延 * 带宽 假设主机A向主机B发送一个L=1500B的分组，主机A到达主机B的路径上有3端链路、2个分组交换机，3段链路长度分别为D1=5000km、D2=4000km、D3=1000km;每段链路的传输速率均为R=2Mbit/s,信号传播速率为V=250000km/s,分组交换机处理每个分组的时延为dc=3ms,试求： 若以存储－转发的分组交换方式，则该分组从主机A到达主机B的端到端时延是多少？ 链路时延：D / V ＝ (5000km+4000km+1000km)/250000km/s=0.04s 总时延为：链路时延＋2分组时延 ＝ 40ms + 2 * 3ms = 46ms 若dc=0, 且不采取存储－转发的分组交换方式，而是分组交换机直接转发收到的每个分组（即直通交换），则该分组从主机A到达主机B的端到端时延是多少？ 时延： D / V ＝ (5000km+4000km+1000km)/250000km/s=0.04s=40ms 如图所示网络。A在t=0时刻开始向C发送一个2Mbits的文件；B在t=0.1+e秒（e为无限趋近于0的小正实数）向D发送一个1Mbits的文件。忽略传播延迟和结点处理延迟。 请回答下列问题： 如果图中网络采用存储-转发方式的报文交换，则A将2Mbits的文件交付给C需要多长时间？B将1Mbits的文件交付给D需要多长时间？ 如果图中网络采用存储-转发方式的分组交换，分组长度为等长的1kbits，且忽略分组头开销以及报文的拆装开销，则A将2Mbits的文件交付给C需要大约多长时间？B将1Mbits的文件交付给D需要大约多长时间？ 报文交换与分组交换相比，哪种交换方式更公平？（即传输数据量小用时少，传输数据量大用时长）答 由于A先发报文所以，A的报文在路由器的队列中排在B的报文前面，所以A交付2Mbits报文需要时间为：2/10+2/20+2/10=0.5s=500ms； B将1Mbits的文件交付给D需要时间为：1/10+2/20(排队时间) +1/20+1/10=0.35s=350ms。 从t=0时刻到t=0.1s，A发送了1000个分组，用时：1000×1000/10000000=0.1s，从t=0.1s时刻起与B共享连接路由器的链路，平均各共享到带宽10Mbps，A大约再用时：1/10+2×1000/10000000=0.1002s交付剩余的1000个分组，故A向C交付2Mbits文件大约需要(0.1+0.1002)s≈0.2s；B向D交付1Mbits文件需要时间大约为：1/10+2×1000/10000000=0.1002s≈0.1s。 分组交换比报文交换更公平。 第二章 网络应用的习题计算机网络应用可以分为哪几种体系结构的应用类型？各种应用类型的特点是什么？从体系结构角度可以分为：客户/服务器(C/S)结构、纯P2P结构和混合结构3种类型 客户/服务器(C/S)结构的特点：客户和客户之间不直接进行通信，客户只是与服务器进行通信。纯P2P结构的特点：所有通信都是在对等的通信方之间直接进行，通信双方没有传统意义上的客户与服务器之分。混合结构的特点：将C/S应用与P2P应用相结合，既有中心服务器的存在，又有对等端间的直接通信。 为什么说客户/服务器通信方式是网络应用通信的基本方式？因为主动发起通信的一方就是客户，被动接受通信的一方就是服务器。人们平时使用就是这种网络 网络应用通信过程中，需要用哪些信息标识一个应用进程？通过运行的主机 IP地址以及套接字所绑定的端口标识应用进程 简述域名系统的层次结构 名字空间是层次结构的，类似Windows的文件名。它可看作是一个树状结构，域名系统不区分树内节点和叶子节点，而统称为节点，不同节点可以使用相同的标记。 一个节点的域名是由从该节点到根的所有节点的标记连接组成的，中间以点分隔。 第二层节点的域名称为二级域名，依此类推 请举例说明，什么是DNS递归解析过程？什么是DNS迭代解析过程？递归解析过程：在进行域名查询时，本地域名服务器如果没有被查询域名的信息，则代理主机查询根域名服务器或其他服务器，直到得到被查询域名的IP地址，最后将解析结果发送给主机。迭代解析过程：提供迭代查询服务的域名服务器不会代理客户的查询请求，而是将最终的结果或者下一步要查询的域名服务器直接响应给查询客户。 什么是本地域名服务器？主机是如何确定本地域名服务器的？默认域名服务器就是本地域名服务器。是主机在进行域名查询过程中首先被查询的域名服务器。需要域名解析的时候会先去本地域名服务器查询，如果查询到了就直接返回结果，如果没有查询到才会查询其他的域名服务器。 简述HTTP1.0获取一引用10个小JPEG图片网页的通信过程 建立TCP连接 在建立的TCP连接基础上向服务器发送一个HTTP请求报文 服务器接收到报文之后从指定的路径中检索出html的文件并封装到一个HTTP响应报文中，发送给客户进程 服务器进程通知TCP断开TCP连接 客户端接收到响应报文后，断开TCP连接 之后引入10个图片，重复前4个步骤 什么是非持久的HTTP？什么是非流水方式的持久HTTP？什么是流水方式的持久HTTP？简述交互过程。 非持久连接是指HTTP客户与HTTP服务端建立TCP连接之后，通过该链接发送HTTP请求报文，接收HTTP响应报文，然后断开链接。 非流水方式的持久：客户端在通过持久连接收到前一个响应报文后，才能发出对下一个对象的请求报文。 流水方式的持久：在通过持久连接接收到前一个对象的响应报文之前，连续依次发送对后续对象的请求报文，然后再通过该链接依次接收服务器发回的响应报文。 假设你在浏览某网页时点击了一个超链接，URL为“https://www.kicker.com.cn/index.html ”，且该URL对应的IP地址在你的计算机上没有缓存；文件index.html引用了8个小图像。域名解析过程中，无等待的一次DNS解析请求与响应时间记为RTTd，HTTP请求传输Web对象过程的一次往返时间记为RTTh。请回答下列问题： 你的浏览器解析到URL对应的IP地址的最短时间是多少？最长时间是多少？ 若浏览器没有配置并行TCP连接，则基于HTTP1.0获取URL链接Web页完整内容（包括引用的图像，下同）需要多长时间（不包括域名解析时间，下同）？ 若浏览器配置5个并行TCP连接，则基于HTTP1.0获取URL链接Web页完整内容需要多长时间？ 若浏览器没有配置并行TCP连接，则基于非流水模式的HTTP1.1获取URL链接Web页完整内容需要多长时间？基于流水模式的HTTP1.1获取URL链接Web页完整内容需要多长时间？答 浏览器解析到URL对应的IP地址的最短时间是：RTTd；（2分）最长时间是：5RTTd。（2分） 若浏览器没有配置并行TCP连接，则基于HTTP1.0获取URL链接Web页完整内容需要的时间：18RTTh。（2分） 若浏览器配置5个并行TCP连接，则基于HTTP1.0获取URL链接Web页完整内容需要的时间：6RTTh。（2分） 若浏览器没有配置并行TCP连接，则基于非流水模式的HTTP1.1获取URL链接Web页完整内容需要的时间：10RTTh；（2分）基于流水模式的HTTP1.1获取URL链接Web页完整内容需要的时间：3RTTh。（2分） 电子邮件主要由哪几部分构成？ 邮件服务器 简单邮件传输协议（SMTP） 用户代理 邮件读取协议 简述SMTP发送邮件过程 首先请求与服务器端的25端口建立TCP链接 通过3个阶段的应用层交互完成邮件的传输 握手阶段：声明自己的身份 邮件传输阶段：向服务器通告邮件发送者与邮件接收者的邮箱地址然后开始邮件数据的传输 关闭阶段：关闭TCP链接 FTP的“外带控制”特性是什么含义？控制连接和数据连接各有什么特点？用途分别是什么？FTP专门使用一个独立的控制连接传输控制信息，与传输文件信息进行分离，所以将FTP这种控制信息的传送方式称为带外控制。 控制连接在整个回话假期一直保持打开数据连接用于实际传送文件内容 考虑向N个对等方（用户）分发F=15Gb的一个文件。该服务器具有us=30Mbps的上传速率，每个对等方的下载速率di=2Mbps，上传速率为u。请分别针对客户-服务器分发模式和P2P分发模式两种情况，对于N=10、100和1000以及u=500kbps、1Mbps和2Mbps的每种组合，绘制最小分发时间图表。（注：k=103、M=106、G=10^9） 简述TCP客户端与TCP服务器程序的socketAPI基本函数调用过程。 调用socket()函数创建SOCK_STREAM类型的主套接字ms 调用bind()函数绑定本地端点地址 嗲用listen()函数置主套接字ms为监听模式 调用accpt()函数通过主套接字调用成功，返回(创建)连接套接字ss 简述UDP客户端与UDP服务器的socketAPI基本函数调用过程。 调用socket()函数创建SOCK_DGRAM类型的主套接字ums 调用bind()函数绑定本地端点地址 客户程序运行后，创建本地SOCK_DGRAM类型的套接字ucs 客户端与服务器程序通过调用sendto()和recvfrom()函数实现数据发送接收。 通信结束后，客服程序通过调用close()函数释放套接字ucs 服务器程序继续调用recvfrom()函数，通过套接字ums接收下一个客户发送过来的数据报 第三章 传输层的习题实现可靠数据传输的主要措施是哪些？这些措施主要用于解决那些问题？ 差错检测：利用差错编码实现数据包传输过程中的比特差错检测。数据发送方对需要检测差错的数据，然后将编码后的数据发送给接收方；接收方一句相同的差错编码规则，检验数据传输过程中是否发生比特差错。 确认：接收方向发送方反馈接收状态。 重传：发送方重新发送接收方没有正确接收的数据。 序号：确保数据按序提交 计时器：解决数据丢失问题。当数据丢失，但是接收方不会收到数据包，也就不会对丢失的包进行确认，计时器就是解决这一问题，当计时器超时，发送方就会将数据包重发。 UDP与TCP分别如何实现复用与分解https://www.cnblogs.com/oxspirt/p/6496434.html 请画出TCP报文端结构，并简要说明各个字段的主要作用？https://www.cnblogs.com/findumars/p/7990823.html 源端口、目标端口: 标识发送该报文段的源端口和目的端口，用于多路复用／分解来自或送到上层应用的数据 序列号、确认号: 对每个应用层数据的每个字节进行编号，因此每个TCP报文段的序号是该段所封装的应用层数据的第一个字节的序号 首部长度: 指出TCP段的首部长度。 保留字段：保留为今后使用，目前值为0 URG：表示本报文段中发送的数据是否包含紧急数据。URG=1，表示有紧急数据。后面的紧急指针字段只有当 URG=1 时才有效。 ACK：表示是否前面的确认号字段是否有效。ACK=1，表示有效。只有当 ACK=1 时，前面的确认号字段才有效。TCP 规定，连接建立后，ACK 必须为 1。 PSH：告诉对方收到该报文段后是否应该立即把数据推送给上层。如果为 1，则表示对方应当立即把数据提交给上层，而不是缓存起来。 RST：只有当 RST=1 时才有用。如果你收到一个 RST=1 的报文，说明你与主机的连接出现了严重错误（如主机崩溃），必须释放连接，然后再重新建立连接。或者说明你上次发送给主机的数据有问题，主机拒绝响应。 SYN：在建立连接时使用，用来同步序号。当 SYN=1，ACK=0 时，表示这是一个请求建立连接的报文段；当 SYN=1，ACK=1 时，表示对方同意建立连接。SYN=1，说明这是一个请求建立连接或同意建立连接的报文。只有在前两次握手中 SYN 才置为 1。 FIN：标记数据是否发送完毕。如果 FIN=1，就相当于告诉对方：“我的数据已经发送完毕，你可以释放连接了” 接收窗口：表示现在运行对方发送的数据量。也就是告诉对方，从本报文段的确认号开始允许对方发送的数据量。 校验和：提供额外的可靠性。具体如何校验，参考其他资料。 紧急指针：标记紧急数据在数据字段中的位置。 选项部分：其最大长度可根据 TCP 首部长度进行推算。TCP 首部长度用 4 位表示，那么选项部分最长为：(2^4-1)*4-20=40 字节。 填充字段：是为了使整个首部长度是4字节的整数倍 TCP为何采用三次握手来建立连接，若采用二次握手可以吗？为什么？不可以，采用三次握手是为了确保连接双方彼此完全清楚对方状态，从而保证可靠、稳定的建立连接，同时，通过三次握手建立连接还可以有效预防过期、失效的连接请求到达后，导致无效连接的建立。三次握手缺一不可。因为网络存在数据丢失，第二次握手控制段可能丢失，这样主动发起连接的一方由于没有收到第二次握手控制段，则无法建立连接，而接受连接建立的一方则认为连接已建立，从而出现无效链接。另外，二次握手建立连接，也无法避免失效连接请求。 请说明TCP建立连接与断开连接的过程，并给出主要状态转移 Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。 Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给 Client以确认连接请求，Server进入SYN_RCVD状态。 Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位A-CK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1 ，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHE- D状态，完成三次握手，随后Client与Server之间可以开始传输数据了。 由于TCP连接时全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭。 数据传输结束后，客户端的应用进程发出连接释放报文段，并停止发送数据，客户端进入FIN_WAIT_1状态，此时客户端依然可以接收服务器发送来的数据。 服务器接收到FIN后，发送一个ACK给客户端，确认序号为收到的序号+1，服务器进入CLOSE_WAIT状态。客户端收到后进入FIN_WAIT_2状态。 当服务器没有数据要发送时，服务器发送一个FIN报文，此时服务器进入LAST_ACK状态，等待客户端的确认 客户端收到服务器的FIN报文后，给服务器发送一个ACK报文，确认序列号为收到的序号+1。此时客户端进入TIME_WAIT状态，等待2MSL（MSL：报文段最大生存时间），然后关闭连接 TCP如何保证可靠数据传输？ 序列号、确认应答、超时重传 12345 数据到达接收方，接收方需要发出一个确认应答，表示已经收到该数据段，并且确认序号会说明了它下一次需要接收的数据序列号。如果发送发迟迟未收到确认应答，那么可能是发送的数据丢失，也可能是确认应答丢失，这时发送方在等待一定时间后会进行重传。这个时间一般是2*RTT(报文段往返时间）+一个偏差值。 窗口控制与高速重发控制/快速重传（重复确认应答） 123456789 TCP会利用窗口控制来提高传输速度，意思是在一个窗口大小内，不用一定要等到应答才能发送下一段数据，窗口大小就是无需等待确认而可以继续发送数据的最大值。如果不使用窗口控制，每一个没收到确认应答的数据都要重发。使用窗口控制，如果数据段1001-2000丢失，后面数据每次传输，确认应答都会不停地发送序号为1001的应答，表示我要接收1001开始的数据，发送端如果收到3次相同应答，就会立刻进行重发；但还有种情况有可能是数据都收到了，但是有的应答丢失了，这种情况不会进行重发，因为发送端知道，如果是数据段丢失，接收端不会放过它的，会疯狂向它提醒. 拥塞控制 12345678910111213141516171819 如果把窗口定的很大，发送端连续发送大量的数据，可能会造成网络的拥堵（大家都在用网，你在这狂发，吞吐量就那么大，当然会堵），甚至造成网络的瘫痪。所以TCP在为了防止这种情况而进行了拥塞控制。慢启动：定义拥塞窗口，一开始将该窗口大小设为1，之后每次收到确认应答（经过一个rtt），将拥塞窗口大小*2。拥塞避免：设置慢启动阈值，一般开始都设为65536。拥塞避免是指当拥塞窗口大小达到这个阈值，拥塞窗口的值不再指数上升，而是加法增加（每次确认应答/每个rtt，拥塞窗口大小+1），以此来避免拥塞。将报文段的超时重传看做拥塞，则一旦发生超时重传，我们需要先将阈值设为当前窗口大小的一半，并且将窗口大小设为初值1，然后重新进入慢启动过程。快速重传：在遇到3次重复确认应答（高速重发控制）时，代表收到了3个报文段，但是这之前的1个段丢失了，便对它进行立即重传。然后，先将阈值设为当前窗口大小的一半，然后将拥塞窗口大小设为慢启动阈值+3的大小。这样可以达到：在TCP通信时，网络吞吐量呈现逐渐的上升，并且随着拥堵来降低吞吐量，再进入慢慢上升的过程，网络不会轻易的发生瘫痪。 请分别简述GBN协议和SR协议的工作过程GBN: 协议的发送端缓存能力较高，可以在未得到确认前连续发送多个分组，因此GBN协议的发送窗口 Ws&gt;=1。GBN接收端缓存能力很低，只能接收到1个按序到达的分组，不能缓存未按序到达的分组，通常称GBN协议的接收端无缓存能力。因此，GBN协议的接收窗口Wr=1。SR: 可以基于流水线方式连续发送多个分组，通常情况下，可以提高信道利用率。（收发都弄个缓存器，专搞乱序的分组消息。 接收方就可以对每个分组单独确认！） 说明TCP滑动窗口机制，对比TCP滑动窗口与GBN协议的异同窗口滑动协议是TCP使用的一种流量控制方法。该协议允许发送方在停止并等待接收确认报文前可以连续发送多个分组。由于发送方不必每发一个分组就停下来等待确认，因此该协议可以加速数据的传输。只有在接收窗口向前滑动时（与此同时也发送了确认），发送窗口才有可能向前滑动。收发两端的窗口按照以上规律不断地向前滑动，因此这种协议又称为滑动窗口协议。 TCP与UDP的主要区别是什么？ TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接 TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付Tcp通过校验和，重传控制，序号标识，滑动窗口、确认应答实现可靠传输。如丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。 UDP具有较好的实时性，工作效率比TCP高，适用于对高速传输和实时性有较高的通信或广播通信。 每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信 TCP如何实现拥赛控制？TCP的拥赛控制是从端到端的角度，推测网络是否发生拥塞，如果推断网络发生拥塞，则立即将数据发送速率降下来，以便缓解网络拥塞。TCP的拥塞控制采用的也是窗口机制，通过调节窗口的大小实现对发送数据速率的调整。 假设甲乙双方采用GBN协议发送报文端，甲已经发送了编号为0~7的报文段，当计时器超时时，若甲只收到0号和3号报文段的确认，则甲需要重发的报文段是那些？答案：4-7号帧。因为GBN不只是超时重传的特点，它还有累计确认的功能，即：发一个确认N，表示前N个帧都已正确收到。超时重传一旦发生，就重发最后确认帧之后的所有帧。 第四章 网络层的习题网络层提供的主要功能是什么？网络层关注的是如何将承载传输层报文段的网络层数据报从源主机送达目的主机。 说明转发和路由的含义，有什么区别和联系？ 转发：当通过一条输入链路接收到一个分组后，路由器需要决策通过那条输出链路将分组发送出去，并将分组从输入接口转移到输出接口。 路由选择：当分组从源主机流向目的主机时，必须通过某种方式决定分组经过的路由或路径，计算分组所经过的路径的算法被称为路由选择算法，或称为路由算法。 路由就是路径的选择，转发就是将数据包从选定的路径发送出去。 对比虚电路网络和数据报网络的优缺点虚电路技术特点：在数据传输之前必须通过虚呼叫设置一条虚电路。适用于两端之间长时间的数据交换。 优点：可靠，保持顺序 缺点：若有故障，则经过故障点的数据全部丢失。数据报特点：在目的地需要重新组装报文。 优点：若有故障发生可绕过故障点 缺点：不能保证顺序到达，丢失不能立即知晓 虚电路网络如何建立虚电路？虚电路网络分组转发的依据是什么？在建立每条电路时，网络会为电路分配独享资源，沿某条电路传输的数据，只占用分配给该电路的资源。 根据分组所携带的VCID判断所属的虚电路，从而决策如何转发分组，并确保分组沿对应的虚电路送达目的。 实现异构网络互连的主要方法有哪些？典型实现同构网络互连的网络设施是什么？有协议转换、构建虚拟互联网络。同构网络互连的典型技术是隧道技术。 路由器有哪些部分组成？各部分主要功能是什么？输入端口、交换结构、输出端口、路由处理器 输入端口：负责从物理接口接收信号，还原数据链路层帧，提取IP数据报，根据IP数据报的目的IP地址检索路由表，决策需要将该IP数据报交换到那个输出端口。 交换结构：具体的转发工作，包括基于内存交换、基于总线交换、基于网络交换 输出端口：输出端口首先提供一个缓存排队功能，排队交换到该端口的待发送分组，并从队列中不断取出分组进行数据链路层数据桢的封装，通过物理线路端接发送出去。 路由处理器: 路由处理器就是路由器的CPU,负责执行路由器的各种指令，包括路由协议的运行、路由计算以及路由表的更新维护等。 网络层出现拥塞的原因是什么？有哪些网络层拥塞控制策略？由于众多的用户随机的将信息送入网络，是网络中需要传输的信息总量经常大于其传输能力，以至于某些网络节点因缓冲区已满，无法接收新到达的分组，此时就发生了所谓的拥塞现象。主要原因：缓冲区容量有限、传输路线的宽带有限、网络结点的处理能力有限、网络中某些部分发生了故障。控制措施：流量感知路由、准入控制、流量调节、负载脱落。 请将IP网络183.164.128.0/17划分为等长的8个子网，并分别给出每个子网的子网地址、子网掩码、IP地址总数、可分配IP地址数和可分配 IP地址范围 由于2的3次方等于8，因此，划分8个等长子网，需要借用3位主机位作为子网位。已知当前掩码为17位，借用3位后的掩码应该是20位，即255.255.240.0。8个子网网络地址如下：183.164.128.0，183.164.144.0，183.164.160.0，183.164.176.0，183.164.192.0，183.164.208.0，183.164.224.0，183.164.240.0。 简述ICMP的主要功能是进行主机或路由器间的网络层差错报告与网络探测 解释网络地址转换(NAT)的工作原理，如何实现NAT穿透？ 借助于NAT，私有（保留）地址的”内部”网络通过路由器发送数据包时，私有地址被转换成合法的IP地址，一个局域网只需使用少量IP地址（甚至是1个）即可实现私有地址网络内所有计算机与Internet的通信需求 目前常用的针对UDP的NAT 穿透（NAT Traversal）方法主要有：STUN、TURN、ICE、uPnP等。其中ICE方式由于其结合了STUN和TURN的特点，所以使用最为广泛。针对TCP的NAT穿透技术目前仍为难点。实用的技术仍然不多。 IPv6提出的动机是什么？IPv6相比于IPv4其数据报格式有什么特点?动机是IPv4地址耗尽的问题，NAT不能彻底解决IPv4问题。 特点: IPv6具有更大的地址空间。IPv4中规定IP地址长度为32，最大地址个数为2^32；而IPv6中IP地址的长度为128，即最大地址个数为2^128。与32位地址空间相比，其地址空间增加了2^128-2^32个。 IPv6使用更小的路由表。IPv6的地址分配一开始就遵循聚类（Aggregation）的原则，这使得路由器能在路由表中用一条记录（Entry）表示一片子网，大大减小了路由器中路由表的长度，提高了路由器转发数据包的速度。 IPv6增加了增强的组播（Multicast）支持以及对流的支持（Flow Control），这使得网络上的多媒体IPv6的长分布式结构图 应用有了长足发展的机会，为服务质量（QoS，Quality of Service）控制提供了良好的网络平台。 IPv6加入了对自动配置（Auto Configuration）的支持。这是对DHCP协议的改进和扩展，使得网络（尤其是局域网）的管理更加方便和快捷。 IPv6具有更高的安全性。在使用IPv6网络中用户可以对网络层的数据进行加密并对IP报文进行校验，在IPV6中的加密与鉴别选项提供了分组的保密性与完整性。极大的增强了网络的安全性。 六：允许扩充。如果新的技术或应用需要时，IPV6允许协议进行扩充。 更好的头部格式。IPV6使用新的头部格式，其选项与基本头部分开，如果需要，可将选项插入到基本头部与上层数据之间。这就简化和加速了路由选择过程，因为大多数的选项不需要由路由选择。 新的选项。IPV6有一些新的选项来实现附加的功能。 简述链路状态路由选择算法原理？链路状态选路算法的工作原理如下 ： 在参与链路状态选路的路由器集合中，每个路由器都需要通过某种机制来了解自己所连接的链路及其状态。 各路由器都能够将其所连接的链路的状态信息通知给网络中的所有其他路由器，这些链路信息包括链路状态、费用以及链路两端的路由器等。 链路状态信息的通过链路状态分组（LSP）来向整个网络发布。一个LSP通常包含源路由器的标识符、相邻路由器的标识符，以及而知之间链路的费用。每一个LSP都将被网络中的所有的路由器接收，并用于建立网络整体的统一拓扑数据库。由于网络中所有的路由器都发送LSP，经过一段时间以后，每一个路由器都保持了一张完整的网络拓扑图，再在这个拓扑图上，利用最短通路算法（例如Dijkstra算法等），路由器就可以计算出从任何源点到任何目的地的最佳通路。 削减距离向量路由选择算法可以产生的无穷计数问题的措施毒性立传技术最大有效费用度量值 比较RIP、OSPF、GBP的异同。RIP是一种基于距离向量路由选择算法的IGP。OSPE对权值表示的意义没有限制，可以是跳数，也可以是链路的宽带等，OSPF只关心在给定的节点、边和边的权值的集合下，如何求解最短路径。GBP: 实现跨自治系统的路由信息交换，是Internet的标准EGP 第五章 数据链路层与局域网的习题链路层协议能够向网络层提供哪些可能的服务？ 无确认的无连接服务 有确认的无连接服务 有确认的面向连接服务 为什么有些网络用纠错码而不用检错和重传机制？请给出两个理由。 服务的实时性要求，如果使用检错机制，那么没有时间重传。 如果传输质量比较差，那么错误率会非常高，几乎所有的帧都要重传，在这种情况下纠错比检错重传效率更高。差错编码的检错或纠错能力与什么有关? 与编码集的汉明距离有关。 考虑在低负载的情况下，纯ALOHA与时隙ALOHA相比，哪个延迟更小？纯ALOHA可以立即开始发送，在负载低的情况下，碰撞小，传输成功可能性大，基本上没有延迟。在分槽ALOHA，需要等待下一个时间槽到达才能发送。会产生半个时间槽的延迟。]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringSecurity]]></title>
    <url>%2Fjava%2FspringSecurity.html</url>
    <content type="text"><![CDATA[官方 OAuth sql 1https://github.com/spring-projects/spring-security-oauth/blob/master/spring-security-oauth2/src/test/resources/schema.sql pom.xml 12345&lt;!-- Spring Security --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt; &lt;/dependency&gt; 配置创建配置类123456789101112131415161718192021222324252627@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter &#123;&#125;``` ### 配置用户信息```java@Bean @Override protected UserDetailsService userDetailsService() &#123; return new UserDetailsServiceImpl(); &#125; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; // 通过数据库创建 auth.userDetailsService(userDetailsService());// // 在内存中创建用户// auth.inMemoryAuthentication()// .withUser("user").password(passwordEncoder().encode("123456")).roles("USER")// .and()// .withUser("admin").password(passwordEncoder().encode("admin888")).roles("ADMIN"); &#125; 配置拦截路径1234567891011121314151617@Override protected void configure(HttpSecurity http) throws Exception &#123; // 自定义login.html登录界面 http.formLogin().loginPage("/login") // .loginProcessingUrl("/login) //form 表单action .failureHandler(failureHandler) .successHandler(successHandler) //.usernameParameter("uname") //.passwordParameter("psd") .and() .authorizeRequests() // 一定要把自定义登录界面给放开权限。即.antMatchers("/login").permitAll(),否则就是死循环。 .antMatchers("/login").permitAll() // 除了login.html页面以外都需要身份认证 （一定要记得添加这一句，否则就是死循环） .anyRequest() .authenticated(); &#125; 启用HTTPS12345678910@Override protected void configure(HttpSecurity http) throws Exception &#123; http.authorizeRequests() .anyRequest().permitAll() .and() .requiresChannel() .antMatchers("/bankInfo").requiresSecure() // enable HTTPS .antMatchers("/").requiresInsecure(); // disable HTTPS &#125; 禁用CSRF12345678@Override protected void configure(HttpSecurity http) throws Exception &#123; http.authorizeRequests() .anyRequest().permitAll() .and() .csrf().disable(); &#125; 启用默认登录页12345678@Override protected void configure(HttpSecurity http) throws Exception &#123; http.authorizeRequests() .anyRequest().permitAll() .and() .formLogin(); &#125; 自定义登录页面1234567891011121314// 指定URL@Override protected void configure(HttpSecurity http) throws Exception &#123; http.authorizeRequests() .anyRequest().permitAll() .and() .formLogin().loginPage("/login"); &#125; // 指定自定义页面 @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController("/login").setViewName("login"); &#125; 测试 登录获取code 1http://localhost:8082/oauth/authorize?client_id=client&amp;response_type=code 通过code获取token 1curl -X POST -H &quot;Content-Type: application/x-www-form-urlencoded&quot; -d &apos;grant_type=authorization_code&amp;code=7JpO0c&apos; &quot;http://client:secret@localhost:8082/oauth/token&quot; 通过token获取数据 1curl --location --request GET &quot;http://localhost:8081/contents&quot; --header &quot;Content-Type: application/json&quot; --header &quot;Authorization: Bearer 23e0070c-4fc6-4e6f-a3e8-9e170c8e74e6&quot;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leaf练习]]></title>
    <url>%2Ftool%2Fleaf.html</url>
    <content type="text"><![CDATA[官方服务开源: https://tech.meituan.com/2019/03/07/open-source-project-leaf.html 官方ID生成: https://tech.meituan.com/2017/04/21/mt-leaf.html GitHub: https://github.com/Meituan-Dianping/Leaf docker安装123456789101112// 克隆git clone https://github.com/funtl/Leaf.gitcd Leafmvn clean install -DskipTests// 构建cd leaf-dockerchmod +x build.sh./build.sh// 运行docker-compose up -d 使用1234#segment号段模式。需要建立DB表，并配置leaf.jdbc.url, leaf.jdbc.username, leaf.jdbc.password如果不想使用该模式配置leaf.segment.enable=false即可curl http://localhost:8080/api/segment/get/leaf-segment-test#snowflake雪花模式。算法取自twitter开源的snowflake算法。如果不想使用该模式配置leaf.snowflake.enable=false即可curl http://localhost:8080/api/snowflake/get/test]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Leaf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot+Nacos+Dubbo实现RPC远程调用]]></title>
    <url>%2Ftool%2Fnacos.html</url>
    <content type="text"><![CDATA[Nacos文档: https://nacos.io/zh-cn/docs/what-is-nacos.html docker安装nacos12345// 克隆git clone https://github.com/nacos-group/nacos-docker.gitcd nacos-docker// docker-compose安装docker-compose -f example/standalone-derby.yaml up 访问：http://127.0.0.1:8848/nacos/，账号密码均为nacos。 创建通用模块api接口如下:1234package com.gtk.dubbo.provider.service;public interface ProviderService &#123; String hi();&#125; 创建dubbo的providerpom.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.gtk&lt;/groupId&gt; &lt;artifactId&gt;gtk-devops-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../../gtk-devops-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;gtk-alibaba-dubbo-provider&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;gtk-alibaba-dubbo-provider&lt;/name&gt; &lt;inceptionYear&gt;2018-Now&lt;/inceptionYear&gt; &lt;properties&gt; &lt;dubbo.version&gt;2.6.6&lt;/dubbo.version&gt; &lt;dubbo-spring-boot.version&gt;0.2.1.RELEASE&lt;/dubbo-spring-boot.version&gt; &lt;dubbo-registry-nacos.version&gt;0.0.1&lt;/dubbo-registry-nacos.version&gt; &lt;dubbo-serialization-kryo.version&gt;2.6.6&lt;/dubbo-serialization-kryo.version&gt; &lt;alibaba-spring-context-support.version&gt;1.0.2&lt;/alibaba-spring-context-support.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.gtk&lt;/groupId&gt; &lt;artifactId&gt;gtk-alibaba-dubbo-api&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo-registry-nacos&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo-registry-nacos.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 高速序列化依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo-serialization-kryo&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo-serialization-kryo.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo-spring-boot.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.spring&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;$&#123;alibaba-spring-context-support.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 解决： java.lang.NoClassDefFoundError: io/netty/channel/EventLoopGroup --&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.32.Final&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.gtk.consumer.NacosConsumerApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.yml123456789101112131415161718192021222324252627282930313233spring: main: allow-bean-definition-overriding: true application: name: dubbo-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848server: port: 10102dubbo: application: name: dubbo-provider registry: address: nacos://127.0.0.1:8848 scan: basePackages: com.gtk.dubbo.provider.service protocol: name: dubbo port: -1 # 高速序列化 serialization: kryo provider: # 负载均衡配置的值分别是：random(默认随机)，roundrobin(轮循)，leastactive(最少活跃调用数)，consistenthash(一致性 Hash) loadbalance: roundrobinmanagement: endpoints: web: exposure: include: "*" 实现类1234567891011121314151617package com.gtk.dubbo.provider.service.impl;import com.alibaba.dubbo.config.annotation.Service;import com.gtk.dubbo.provider.service.ProviderService;import org.springframework.beans.factory.annotation.Value;@Servicepublic class ProviderServiceImpl implements ProviderService&#123; @Value("$&#123;server.port&#125;") private String port; @Override public String hi() &#123; return "服务提供者提供" + port; &#125;&#125; 创建dubbo的consumerpom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.gtk&lt;/groupId&gt; &lt;artifactId&gt;gtk-devops-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../../gtk-devops-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;gtk-alibaba-dubbo-consumer&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;gtk-alibaba-dubbo-consumer&lt;/name&gt; &lt;inceptionYear&gt;2018-Now&lt;/inceptionYear&gt; &lt;properties&gt; &lt;dubbo.version&gt;2.6.6&lt;/dubbo.version&gt; &lt;dubbo-spring-boot.version&gt;0.2.1.RELEASE&lt;/dubbo-spring-boot.version&gt; &lt;dubbo-registry-nacos.version&gt;0.0.1&lt;/dubbo-registry-nacos.version&gt; &lt;dubbo-serialization-kryo.version&gt;2.6.6&lt;/dubbo-serialization-kryo.version&gt; &lt;alibaba-spring-context-support.version&gt;1.0.2&lt;/alibaba-spring-context-support.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.gtk&lt;/groupId&gt; &lt;artifactId&gt;gtk-alibaba-dubbo-api&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!-- &lt;dependency&gt;--&gt; &lt;!-- &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;--&gt; &lt;!-- &lt;artifactId&gt;spring-cloud-starter-dubbo&lt;/artifactId&gt;--&gt; &lt;!-- &lt;/dependency&gt;--&gt; &lt;!-- &amp;lt;!&amp;ndash; Dubbo &amp;ndash;&amp;gt;--&gt; &lt;!-- &lt;dependency&gt;--&gt; &lt;!-- &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt;--&gt; &lt;!-- &lt;artifactId&gt;dubbo&lt;/artifactId&gt;--&gt; &lt;!-- &lt;/dependency&gt;--&gt; &lt;!-- &amp;lt;!&amp;ndash; Dubbo Registry Nacos 因为Apache Dubbo 2.7.1版本构建的时候没有把dubbo-registry-nacos打到all-in-one的包中，这里只有手动处理一下。而2.7.1依赖的是nacos-client不是最新版，这里也升级到最新版。&amp;ndash;&amp;gt;--&gt; &lt;!-- &lt;dependency&gt;--&gt; &lt;!-- &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt;--&gt; &lt;!-- &lt;artifactId&gt;dubbo-registry-nacos&lt;/artifactId&gt;--&gt; &lt;!-- &lt;version&gt;2.7.1&lt;/version&gt;--&gt; &lt;!-- &lt;/dependency&gt;--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo-registry-nacos&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo-registry-nacos.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo-serialization-kryo&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo-serialization-kryo.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo-spring-boot.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.spring&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;$&#123;alibaba-spring-context-support.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 解决： java.lang.NoClassDefFoundError: io/netty/channel/EventLoopGroup --&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.32.Final&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.gtk.consumer.NacosConsumerApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.yml123456789101112131415161718192021222324252627282930313233spring: main: allow-bean-definition-overriding: true application: name: dubbo-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848server: port: 10201dubbo: application: # 花了2小时解决。此处把-写成了_ 报错：Caused by: java.lang.IllegalStateException: Invalid name="com.alibaba.dubbo.config.ApplicationConfig#0" contains illegal character, only digit, letter, '-', '_' or '.' is legal. name: dubbo-consumer qos-enable: false registry: address: nacos://127.0.0.1:8848 scan: basePackages: com.gtk.dubbo.provider.service protocol: name: dubbo port: -1 # 高速序列化 想要使用 Kryo 序列化只需要 DTO/Domain/Entity 这类传输对象实现序列化接口即可， # 无需额外再做配置，如：public class User implements Serializable&#123;&#125;。 Dubbo 已经自动将 JDK 中的常用类进行了注册 serialization: kryomanagement: endpoints: web: exposure: include: "*" 实现类1234567891011121314151617181920package com.gtk.nacos.dubbo.controller;import com.alibaba.dubbo.config.annotation.Reference;import com.gtk.dubbo.provider.service.ProviderService;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class ConsumerController &#123; @Reference private ProviderService providerService; @RequestMapping("hi") public String hi() &#123; return providerService.hi(); &#125;&#125; 须知 服务提供者启动服务之后， 服务消费者进行消费。访问服务消费者的接口返回了服务提供者的端口号表示成功。 在 Provider 和 Consumer 项目启用 Kryo 高速序列化功能，两个项目的配置方式相同 12345678910111213// pom.xml&lt;properties&gt; &lt;dubbo-kryo.version&gt;2.7.2&lt;/dubbo-kryo.version&gt;&lt;/properties&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-serialization-kryo&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo-kryo.version&#125;&lt;/version&gt;&lt;/dependency&gt;// application.ymldubbo: protocol: serialization: kryo 服务提供者默认实现了随机的负载均衡策略，可以使用如下配置进行设置。 12# 负载均衡配置的值分别是：random(默认随机)，roundrobin(轮循)，leastactive(最少活跃调用数)，consistenthash(一致性 Hash)dubbo:provider:loadbalance: roundrobin 源码地址: [https://github.com/gaoqisen/gtk-devops-scd](https://github.com/gaoqisen/gtk-devops-scd)]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>nacos dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SkyWalking练习]]></title>
    <url>%2Ftool%2FskyWalking.html</url>
    <content type="text"><![CDATA[一、安装SkyWalking安装ElasticSearch1234567891011version: '3.3'services: elasticsearch: image: wutang/elasticsearch-shanghai-zone:6.3.2 container_name: elasticsearch restart: always ports: - 9200:9200 - 9300:9300 environment: cluster.name: elasticsearch 需要用docker的地址（docker inspect id）获取docker容器的ip。如果填写localhost会出现com.netflix.zuul.exception.ZuulException: Forwarding error的报错信息。（花了2个小时解决问题） 访问http://localhost:9200/出现json字符串表示安装并启动成功。 下载SkyWalking下载地址: http://skywalking.apache.org/zh/downloads/ 更改配置下载的gz包解压之后，在根目录的config目录里面找到application.yml并修改配置 启动在根目录的bin目录里面执行startup.sh或者startup.bat启动程序。启动程序成功之后，访问http://localhost:8080/出现以下页面表示成功。 二、使用SkyWalkingidea启动方式在此处添加以下内容123-javaagent:D:\Workspace\Others\hello-spring-cloud-alibaba\hello-spring-cloud-external-skywalking\agent\skywalking-agent.jar-Dskywalking.agent.service_name=nacos-provider-Dskywalking.collector.backend_service=localhost:11800 只需要添加环境变量即可，之后启动程序会自动实现链路追踪 java启动方式1java -javaagent:/path/to/skywalking-agent/skywalking-agent.jar -Dskywalking.agent.service_name=nacos-provider -Dskywalking.collector.backend_service=localhost:11800 -jar yourApp.jar 链路追踪之后]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>SkyWalking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络基础]]></title>
    <url>%2Fnetwork%2Fbase.html</url>
    <content type="text"><![CDATA[网络基础计算机网络的定义 计算机技术与通行技术的结合产生了计算机网络 协议三要素 语法：实体之间交换信息的格式和结构，或者定义实体之间传输信号的电平等 语义：定义实体之间交换的信息中需要发送那些控制信息、信息的含义、不同含义的控制信息、接收信息端如何响应等。 时序：定义实体之间交换信息的顺序以及如何匹配或适应彼此的速度 计算机网络分类按照范围 个域网：个人设备通过无线通信技术构成小范围的网络。 局域网：办公室、办公楼、厂区、校园等局部区域内的网络。 城域网：覆盖一个城市的网络通常在5-10km。 广域网：范围几十到几千米，跨越很大的地理空间，可以实现异地城域网。 按拓扑结构分类 星形拓扑结构：一个中央点，主机通过点对点通信链路与中央节点链接。 总线型拓扑结构：一条广播信道作为公共传输介质（总线），所有节点与总线链接，节点之间的通信通过共享总线进行 环形拓扑结构：通信链路将所有的节点连成一个闭合环。 网状拓扑图：多条链路与不同的节点直接链接。 树形拓扑图：是总线和星形拓扑网络的扩展。 混合拓扑图：由两种以上拓扑图混合链接而成的网络。 交换方式 电路交换网络 报文交换网络 分组交换网络 网络用户属性 共用网：国家或企业出资建设，面向公众提供免费或收费服务的网络 私有网：由某个组织（政府或者企业等）出资建设，专门面向组织内部业务提供的网络服务 网络结构 网络边缘: 链接到网络上的所有端系统构成了边缘网络 接入网络: 实现了网络边缘的端系统与网络核心链接与接入的网络 电话拨号接入 非对称数字用户线路ADSL 混合光纤同轴电缆HFC接入网络 局域网络 移动接入网络 网络核心: 由通信链路互连的分组交换设备构成的网络，是实现网络边缘中主机之间的数据中继与转发。 数据交换 实现网络核心数据中继与转发的关键技术是数据交换 电路交 建立电路 传输数据 拆除电路 报文交换: 发送方把要发送的消息加上一些接收主机的信息等，构成一个完整的报文，然后已报文为单位在交换网络的各个节点之间已存储/转发的方式传送到接收主机 分组交换：把报文分成较小的数据块传输，接收方接收后还原报文 优点 交换设备存储容量要求低 交换速度快 可靠传输效率高 更加公平 长度的确认： 分组长度与延迟时间 分组长度与误码率 网络性能 速率／带宽：网络单位时间内传送的数据量，传输的快慢就是传输速率又是也叫带宽。 时延：数据从网络中的一个节点到另一个节点所需要的时间，又叫延迟。 节点处理时延 排队时延 传输时延 传播时延 时延带宽积：物理链路传播时延与链路带宽的乘积 丢包率：网络拥塞是会造成丢包 吞吐量：在单位时间内原主机通过网络向目的主机实际送达的数据量 计算机网络分层体系结构 计算机网络所划分的层次以及各层协议的集合成为计算机网络体系结构。 OSI参考模型 TCP/IP参考模型]]></content>
      <categories>
        <category>netword</category>
      </categories>
      <tags>
        <tag>netword</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaIO]]></title>
    <url>%2Fjava%2Fio.html</url>
    <content type="text"><![CDATA[JavaIO##简介 IO操作面临很多问题，信息量的巨大，网络的环境等等，因为IO不仅仅是对本地文件、目录的操作，有时对二进制流、还有一部分是网络方面的资源，所以多种原因直接造成IO操作无疑是耗时且复杂多变的。Java对IO的支持是个不断的演变过程，经过了很多的优化，直到JDK1.4以后，才趋于稳定，在JDK1.4中，加入了nio类，解决了很多性能问题。 含义百科定义Java的核心库java.io提供了全面的IO接口。包括：文件读写、标准设备输出等。Java中IO是以流为基础进行输入输出的，所有数据被串行化写入输出流，或者从输入流读入。 组成1、基于字节操作的I/O接口：InputStream和OutputStream（在java.io包下） 2、基于字符操作的I/O接口：Writer和Reader（在java.io包下） 3、基于磁盘操作的I/O接口：File（在java.io包下） 4、基于网络操作的I/O接口：Socket（不在java.io包下） 分类数据来源 文件（file）：FileInputStream、FileOutputStream、FileReader、FileWriter 数组（[]）： 字节数组（byte[]）：ByteArrayInputStream、ByteArrayOutputStream 字符数组（char[]）：CharArrayReader、CharArrayWriter 管道操作：PipedInputStream、PipedOutputStream、PipedReader、PipedWriter 基本数据类型：DataInputStream、DataOutputStream 缓冲操作：BufferedInputStream、BufferedOutputStream、BufferedReader、BufferedWriter 打印：PrintStream、PrintWriter 对象序列化反序列化：ObjectInputStream、ObjectOutputStream 转换：InputStreamReader、OutputStreWriter 数据传输方式 区别 读写单位不同，字节流以字节为单位（一个字节为8bit位），字符流以字符为单位 操作对象不同，字节流可以处理任何数据 字符流只能处理字符相关类型数据 字节流在操作的时候本身是不会用到缓冲区(内存)的，是与文件本身直接操作的，而字符流在操作的时候是使用到缓冲区的 在所有的硬盘上保存文件或是进行传输的时候都是以字节的方式进行的，包括图片也是按照字节完成，而字符是只有在内存中才会形成的，所以使用字节操作是最多的。 实战字节操作I/O1234567891011121314151617181920212223242526272829303132333435public static void main(String[] args) throws Exception&#123; //—————————— OutputStream, write输出byte[] // 文件本身不存在，则会为用户自动创建新文件 File f= new File("/Users/jasongao/Desktop/test.txt") ; // 通过子类实例化父类对象, 通过对象多态性，进行实例化。 // new FileOutputStream(f,true) ; // 此处表示在文件末尾追加内容 OutputStream out = new FileOutputStream(f); String str = "Hello World!!!" ; // 只能输出byte数组，所以将字符串变为byte数组 byte b[] = str.getBytes() ; // 将内容输出，保存文件 out.write(b) ; //—————————— OutputStream, write输出byte String str2 = "\r\nHello World2!!!" ; byte c[] = str2.getBytes() ; // 采用循环方式写入,每次只写入一个内容 for(int i=0;i&lt;c.length;i++)&#123; out.write(c[i]) ; &#125; out.close() ; //—————————— InputStream, read输入byte[] InputStream input = new FileInputStream(f) ; // 所有的内容都读到此数组之中 byte d[] = new byte[1024] ; // 读取内容,可以 返回长度、byte等 int len =input.read(d) ; input.close() ; System.out.println("读入数据的长度：" + len); System.out.println("内容为：" + new String(d)) ; System.out.println("内容为：" + new String(d,0,len)) ;&#125; 字符操作I/O123456789101112131415161718private static void character() throws IOException&#123; //—————————— Writer, write输出byte[] File f= new File("/Users/jasongao/Desktop/test.txt"); Writer out = new FileWriter(f) ; // 通过对象多态性，进行实例化 // 第3步、进行写操作 String str = "Hello World!!!666" ; // 准备一个字符串 out.write(str); out.close(); //—————————— Reader, write输出byte[] Reader input = new FileReader(f) ; // 所有的内容都读到此数组之中 char c[] = new char[1024] ; int len = input.read(c) ; input.close() ; System.out.println("内容为：" + new String(c,0,len)); &#125; 磁盘操作I/O123456789101112131415161718192021222324252627282930313233private static void file() throws IOException&#123; String path = "/Users/jasongao/Desktop/test.txt"; File myFile = new File(path); //判断文件是否存在 if (!myFile.exists()) &#123; // 创建文件夹， mkdir()只会建立一级的文件夹 myFile.mkdir(); // mkdirs()可以建立多级文件夹 myFile.mkdirs(); // 创建新文件 myFile.createNewFile(); // 删除文件夹 myFile.delete(); //读取文件名称 myFile.getName(); //读取文件路径(相对路径) myFile.getPath(); //读取文件绝对路径 myFile.getAbsolutePath(); //读取文件的父级路径 new File(myFile.getAbsolutePath()).getParent(); //读取文件的大小 myFile.length(); //判断文件是否被隐藏 myFile.isHidden(); //判断文件是否可读 myFile.canRead(); //判断文件是否可写 myFile.canWrite(); //判断文件是否为文件夹 myFile.isDirectory(); &#125; &#125; 各种转换1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * 将str转换为inputStream * @param str * @return */public static InputStream strConvertInputStream(String str) &#123; ByteArrayInputStream is = new ByteArrayInputStream(str.getBytes()); return is;&#125;/** * 将inputStream转换为str * @param is * @return * @throws IOException */public static String inputStreamConvertStr(InputStream is) throws IOException &#123; StringBuffer sb; BufferedReader br = null; try &#123; br = new BufferedReader(new InputStreamReader(is)); sb = new StringBuffer(); String data; while ((data = br.readLine()) != null) &#123; sb.append(data); &#125; &#125; finally &#123; br.close(); &#125; return sb.toString();&#125;/** * 将file转换为inputStream * @param file * @return * @throws FileNotFoundException */public static InputStream fileConvertInputStream(File file) throws FileNotFoundException &#123; return new FileInputStream(file);&#125;/** * 将inputStream转化为file * @param is * @param file 要输出的文件目录 */public static void inputStreamConvertFile(InputStream is, File file) throws IOException &#123; OutputStream os = null; try &#123; os = new FileOutputStream(file); int len = 0; byte[] buffer = new byte[8192]; while ((len = is.read(buffer)) != -1) &#123; os.write(buffer, 0, len); &#125; &#125; finally &#123; os.close(); is.close(); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java io</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSI参考模型]]></title>
    <url>%2Fnetwork%2FOSI.html</url>
    <content type="text"><![CDATA[OSI参考模型含义背景第一个网络体系结构，即系统网络体系结构（SNA，System Network Architecture）于1974年，由IBM公司提出，此后，许多公司纷纷提出各自的网络体系结构。这些网络体系结构虽然都是采用了分层技术，但是层次的划分、功能分配与采用的技术均不同。随着信息技术的飞速发展，各种计算机的联网和各种计算机网络的互联成为迫切需要解决的问题。OSI模型正式在这样的背景下提出的。 百科定义 OSI（Open System Interconnect），即开放式系统互联。 一般都叫OSI参考模型，是ISO组织在1985年研究的网络互联模型。该体系结构标准定义了网络互联的七层框架（物理层、数据链路层、网络层、传输层、会话层、表示层和应用层），即OSI开放系统互连参考模型。 简介为了更好地促进互联网络的研究和发展，国际标准化组织ISO制定了网络互连的七层框架的一个参考模型，称为开放系统互连参考模型，简称OSI/RM(Open System Internetwork Reference Model)。 [2] OSI参考模型是一个具有7层协议结构的开放系统互连模型，是由国际标准化组织在20世纪80年代早期制定的一套普遍适用的规范集合，使全球范围的计算机可进行开放式通信。 七层详解 应用层（针对特定应用的协议，参考模型的最底层） 应用层该协议在所需要传送的数据的前端附加一个首部信息。该首部信息里面会标明了内容和收件人。而当接受方接收到该数据后，会分析数据首部和数据正文，最终实现邮件传输。 表示层（设备固有数据格式和网络标准数据格式的转换） 表示层的作用是把数据从某个计算机特定的数据格式转换为网络通用的标准数据格式，同时可以反转过来。其目的就是为了统一网络数据格式。即便是一段简单的文字也有着众多的编码格式，例如：UTF-8、UTF-16和EUC-JP等等。而表示层之间为了能够识别编码格式也会在数据前端附加首部信息。 会话层（通信之间的管理） 会话层主要负责决定使用何种连接方式，例如在发送邮件的时候可以选择每一封发送完成后重新建立连接发送，也可以选择一个连接同时发送数个邮件，甚至可以同时建立数个连接发送。会话层也会在数据前端记录数据传送顺序的信息。（会话层负责决定建立连接和断开连接的十几，而传输层才是进行实际的建立和断开处理）。 传输层（管理节点之间的数据传输） 传输层主要负责是建立连接和断开连接，并确保信息是否达到目标地址，它会在通信两端的计算机进行确认，如果数据没有达到，它会进行重发。为了确保可靠性，也会在数据前端加上首部信息以识别这一分层的数据。 网络层（网络地址和路由的选择） 网络层中主要负责的是基于目的地址，在众多的数据链路中，将数据从发送端发送到接收端。网络层中会把目的地址的相关信息放在首部发送到下一层。 数据链路层（互连设备之间传送和识别数据帧） 数据的传输实际还是通过物理的传输方式，而数据链路层实际就是在互连的设备之间进行数据处理。 物理层（界定连接器和网线的规格） 物理层则是将0，1的数据转为电信号或者光信号给物理传输介质，而连接这些物理传输介质的设备之间是通过MAC地址（物理地址或硬件地址）传输。因此，物理层会把MAC地址作为首部信息放在数据前端，将其发送到网络。]]></content>
      <categories>
        <category>network</category>
      </categories>
      <tags>
        <tag>network OSI参考模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty]]></title>
    <url>%2Fjava%2Fnetty.html</url>
    <content type="text"><![CDATA[Netty 官网https://netty.io/ 技术来源解决什么问题 原生的Java NIO使用起来没那么方便，而且还有很多bug，Netty把它封装之后，提供了一个易于操作的使用模式和接口，方便用户使用起。 可以实现自己的HTTP服务器，FTP服务器，UDP服务器，RPC服务器，WebSocket服务器，Redis的Proxy服务器，MySQL的Proxy服务器等等 含义百科定义 Netty是由JBOSS提供的一个java开源框架，现为 Github上的独立项目。Netty提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。 也就是说，Netty 是一个基于NIO的客户、服务器端编程框架，使用Netty 可以确保你快速和简单的开发出一个网络应用，例如实现了某种协议的客户、服务端应用。Netty相当于简化和流线化了网络应用的编程开发过程，例如：基于TCP和UDP的socket服务开发。 “快速”和“简单”并不用产生维护性或性能上的问题。Netty 是一个吸收了多种协议（包括FTP、SMTP、HTTP等各种二进制文本协议）的实现经验，并经过相当精心设计的项目。最终，Netty 成功的找到了一种方式，在保证易于开发的同时还保证了其应用的性能，稳定性和伸缩性。 未完待续]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaNIO]]></title>
    <url>%2Fjava%2Fnio.html</url>
    <content type="text"><![CDATA[JavaNIO简介 在高并发的环境下，线程数量会比较多，System load也会比较高，于是就有了NIO Java NIO 是 java 1.4 之后新出的一套IO接口，这里的的新是相对于原有标准的Java IO和Java Networking接口。NIO提供了一种完全不同的操作方式。NIO中的N可以理解为Non-blocking，不单纯是New。 它支持面向缓冲的，基于通道的I/O操作方法。 随着JDK 7的推出，NIO系统得到了扩展，为文件系统功能和文件处理提供了增强的支持。 由于NIO文件类支持的这些新的功能，NIO被广泛应用于文件处理。 对比 传统IO流想要处理多个客户端的Socket请求，它必须要不断的创建新的线程来专门为连入的Socket请求进行处理，如果连入的Socket请求很多，并且来自不同的IP或者端口就必须要不断的创建线程，对系统资源会造成很大的占用。 IO1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package study.base;import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.net.InetSocketAddress;import java.net.ServerSocket;import java.net.Socket;public class SocketCaseIO &#123; public static ServerSocket server = null; public static void main(String[] args) throws IOException &#123; // TODO Auto-generated method stub init(); System.out.println("Finish init!"); while (true) &#123; Socket socket = server.accept(); System.out.println("Client connected!" + socket.getPort()); try &#123; SocketProcess socketProcess = new SocketProcess(socket); System.out.println("Start thread!"); Thread thread = new Thread(socketProcess); thread.start(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; private static void init() throws IOException &#123; server = new ServerSocket(); server.setSoTimeout(0); server.setReuseAddress(true); server.bind(new InetSocketAddress(4495)); &#125;&#125;class SocketProcess implements Runnable &#123; private static Socket socket = null; public SocketProcess(Socket socket) &#123; SocketProcess.socket = socket; &#125; @Override public void run() &#123; InputStream rd = null; OutputStream bw = null; try &#123; rd = socket.getInputStream(); bw = socket.getOutputStream(); byte[] ReqBuff = new byte[1000]; System.out.println("Ready receive the request message!"); while (rd.read(ReqBuff) &gt; 0) &#123; System.out.println("start"); System.out.println(new String(ReqBuff)); System.out.println("finish"); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); try &#123; rd.close(); bw.close(); socket.close(); &#125; catch (IOException e1) &#123; // TODO Auto-generated catch block e1.printStackTrace(); &#125; &#125; &#125;&#125; NIO123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116package study.base;import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel;import java.util.Iterator;public class SocketCaseNIO &#123; // 通道管理器 private Selector selector; /** * 获得一个ServerSocket通道，并对该通道做一些初始化的工作 * @param port 绑定的端口号 * @throws IOException */ public void initServer(int port) throws IOException &#123; // 获得一个ServerSocket通道 ServerSocketChannel serverChannel = ServerSocketChannel.open(); // 设置通道为非阻塞 serverChannel.configureBlocking(false); // 将该通道对应的ServerSocket绑定到port端口 serverChannel.socket().bind(new InetSocketAddress(port)); // 获得一个通道管理器 this.selector = Selector.open(); // 将通道管理器和该通道绑定，并为该通道注册SelectionKey.OP_ACCEPT事件,注册该事件后， // 当该事件到达时，selector.select()会返回，如果该事件没到达selector.select()会一直阻塞。 serverChannel.register(selector, SelectionKey.OP_ACCEPT); System.out.println("OP_ACCEPT"); &#125; /** * 采用轮询的方式监听selector上是否有需要处理的事件，如果有，则进行处理 * @throws IOException */ public void listen() &#123; System.out.println("服务端启动成功！"); // 轮询访问selector while (true) &#123; // 当注册的事件到达时，方法返回；否则,该方法会一直阻塞 try &#123; selector.select(); // 获得selector中选中的项的迭代器，选中的项为注册的事件 Iterator&lt;SelectionKey&gt; ite = this.selector.selectedKeys().iterator(); while (ite.hasNext()) &#123; SelectionKey key = (SelectionKey) ite.next(); // 删除已选的key,以防重复处理 ite.remove(); // 客户端请求连接事件 if (key.isAcceptable()) &#123; ServerSocketChannel server = (ServerSocketChannel) key.channel(); // 获得和客户端连接的通道 SocketChannel channel = server.accept(); // 设置成非阻塞 channel.configureBlocking(false); // 在这里可以给客户端发送信息哦 channel.write(ByteBuffer.wrap(new String("向客户端发送了一条信息").getBytes())); // 在和客户端连接成功之后，为了可以接收到客户端的信息，需要给通道设置读的权限。 channel.register(this.selector, SelectionKey.OP_READ); // 获得了可读的事件 &#125; else if (key.isReadable()) &#123; read(key); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * 处理读取客户端发来的信息 的事件 * * @param key * @throws IOException */ public void read(SelectionKey key) throws IOException &#123; try &#123; // 服务器可读取消息:得到事件发生的Socket通道 SocketChannel channel = (SocketChannel) key.channel(); // 创建读取的缓冲区 ByteBuffer buffer = ByteBuffer.allocate(100); int statusCode = channel.read(buffer); // System.out.println("length:" + statusCode); if (statusCode != -1) &#123; byte[] data = buffer.array(); String msg = new String(data).trim(); System.out.println("服务端收到信息：" + msg); ByteBuffer outBuffer = ByteBuffer.wrap(msg.getBytes()); channel.write(outBuffer);// 将消息回送给客户端 &#125; else &#123; channel.close(); &#125; &#125; catch (Exception e) &#123; &#125; &#125; /** * 启动服务端测试 * * @throws IOException */ public static void main(String[] args) throws IOException &#123; SocketCaseNIO server = new SocketCaseNIO(); server.initServer(4496); server.listen(); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java JavaNIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP/IP]]></title>
    <url>%2Fnetwork%2FTCPIP.html</url>
    <content type="text"><![CDATA[TCP/IP时间轴TCP/IP的起源可以追溯到由美国国防部(DoD)高级研究计划局(DARPA)在二十世纪六十年代后期和七十年代早期进行的研究。下面摘要列出了TCP/IP发展史上的一些重大事件： 1970年，ARPANET主机开始使用网络控制协议(NCP)，这就是后来的传输控制协议(TCP)的雏形。 1972年，Telnet协议推出。Telnet用于终端仿真以连接相异的系统。在二十世纪七十年代早期，这些系统使用不同类型的主机。 1973年，文件传输协议(FTP)推出。FTP用于在相异的系统之间交换文件。 1974年，传输控制协议(TCP)被详细规定下来。TCP取代NCP，它为人们提供了更可靠的通信服务。 1981年，Internet协议(IP)(又称IP版本4[IPv4])被详细规定下来。IP为端到端传递提供寻址和路由功能。 1982年，国防通信署(DCA)和ARPA建立了传输控制协议(TCP)和Internet协议 (IP)作为TCP/IP协议套件。 1983年，ARPANET将NCP替换为TCP/IP。 1984年，域名系统(DNS)推出。DNS可将域名(如www.example.com)解析为IP地址(如192.168.5.18)。 1995年，Internet服务提供商(ISP)开始向企业和个人提供Internet接入。 1996年，超文本传送协议(HTTP)推出。万维网使用HTTP。 1996年，第一套IP版本6(IPv6)标准发布。 百科定义TCP/IP（Transmission Control Protocol/Internet Protocol，传输控制协议/网际协议）是指能够在多个不同网络间实现信息传输的协议簇。TCP/IP协议不仅仅指的是TCP 和IP两个协议，而是指一个由FTP、SMTP、TCP、UDP、IP等协议构成的协议簇， 只是因为在TCP/IP协议中TCP协议和IP协议最具代表性，所以被称为TCP/IP协议。 来源TCP/IP 模型是由 OSI 模型演化而来，TCP/IP 模型将 OSI 模型由七层简化为五层（一开始为四层），应用层、表示层、会话层统一为应用层。 计算机协议协议就是计算机与计算机之间通过网络实现通信时事先达成的一种“约定”。这种“约定”使那些由不同厂商的设备、不同的CPU以及不同的操作系统组成的计算机之间，只要遵循相同的协议就能够实现通信。反之，如果所使用的协议不同，就无法实现通信。这就好比两个人使用不同国家的语言说话，怎么也无法相互理解。协议可以分为很多种，每一种协议都明确地界定了它的行为规范。两台计算机之间必须能够支持相同的协议，并遵循相同协议进行处理，这样才能实现相互通信。 组成 物理层：计算机在传递数据的时候传递的都是0和1的数字，而物理层关心的是用什么信号来表示0和1，是否可以双向通信，最初的连接如何建立以及完成连接如何终止,总之，物理层是为数据传输提供可靠的环境。 数据链路层：数据链路层位于物理层和网络层之间，用来向网络层提供数据，就是把源计算机网络层传过来的信息传递给目标主机。 如何将数据组合成数据帧(Frame)，帧是数据链路层的传输单位 数据链路的建立、维护和拆除 帧包装、帧传输、帧同步 帧的差错恢复 流量控制 网络层: 网络层位于传输层和数据链路层之间,用于把数据从源主机经过若干个中间节点传送到目标主机,并向传输层提供最基础的数据传输服务,它要提供路由和选址的工作。 选址: 交换机是靠MAC来寻址的，而因为MAC地址是无层次的,所以要靠IP地址来确认计算机的位置,这就是选址。 路由: 在能够选择的多条道路之间选择一条最短的路径就是路由的工作。 传输层：传输层是面向连接的、可靠的的进程到进程通信的协议。TCP提供全双工服务，即数据可在同一时间双向传播。TCP将若干个字节构成一个分组，此分组称为报文段(Segment)。提供了一种端到端的连接。传输层的协议主要有TCP 和 UDP， TCP(Transimision Control Protocal)是一种可靠的、面向连接的协议，传输效率低。 UDP(User Datagram Protocal)是一种不可靠的、无连接的服务，传输效率高。 TCP功能：主要是将数据进行分段打包传输，对每个数据包编号控制顺序，运输中丢失、重发和丢弃处理。 TCP三次握手![https://gaoqisen.github.io/GraphBed/201911/20191113222432.png](https://gaoqisen.github.io/GraphBed/201911/20191113222923.png) 第一次握手: 建立连接。客户端发送连接请求，发送SYN报文，将seq设置为0。然后，客户端进入SYN_SEND状态，等待服务器的确认。 第二次握手: 服务器收到客户端的SYN报文段。需要对这个SYN报文段进行确认，发送ACK报文，将ack设置为1。同时，自己还要发送SYN请求信息，将seq为0。服务器端将上述所有信息一并发送给客户端，此时服务器进入SYN_RECV状态。 第三次握手: 客户端收到服务器的ACK和SYN报文后，进行确认，然后将ack设置为1，seq设置为1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。 TCP四次挥手 先由客户端向服务器端发送一个FIN，请求关闭数据传输。 当服务器接收到客户端的FIN时，向客户端发送一个ACK，其中ack的值等于FIN+SEQ 然后服务器向客户端发送一个FIN，告诉客户端应用程序关闭。 当客户端收到服务器端的FIN是，回复一个ACK给服务器端。其中ack的值等于FIN+SEQ 应用层: 常见协议有HTTP(超文本传输)、HTTPS 、FTP (文件传输)、SMTP(简单邮件传输)、DNS(域名服务器)、NFS(网络文件系统)等]]></content>
      <categories>
        <category>netword</category>
      </categories>
      <tags>
        <tag>netword</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaSocket]]></title>
    <url>%2Fjava%2Fsocket.html</url>
    <content type="text"><![CDATA[JavaSocket含义 解决网络通信问题。可以直接使用这些类和接口，来专注于解决问题，而不用关注通信细节。 百科定义套接字（socket）是一个抽象层，应用程序可以通过它发送或接收数据，可对其进行像对文件一样的打开、读写和关闭等操作。套接字允许应用程序将I/O插入到网络中，并与网络中的其他应用程序进行通信。网络套接字是IP地址与端口的组合。 简单调用方式 客服端 12345678910111213141516171819202122232425262728293031323334/* * java.net.Socket * 封装了TCP协议 * 使用它可以与远程计算机连接并进行 * 数据交换,实现通讯的目的 */public static void main(String[] args) &#123; try &#123; /* * 初始化Socket。初始化需要传入两个参数 * 参数1:远端计算机IP地址 * 参数2:远端计算机的服务端口 * IP地址用来找到服务端所在的计算机端口用来连接上该计算机上的服务端应用程序 * 实例化Socket的过程就是连接的过程若远端计算机没有响应会抛出异常 */ System.out.println("正在连接服务端..."); Socket socket = new Socket( "localhost",8088 ); System.out.println("与服务端建立连接!"); /* * Socket的方法: * OutputStream getOutputStream() * 用于获取一个输出流,通过该输出流写出的字节会发送至远端计算机.而远端计算机可以通过 * 输入流读取. */ OutputStream out = socket.getOutputStream(); OutputStreamWriter osw = new OutputStreamWriter(out,"UTF-8"); PrintWriter pw = new PrintWriter(osw,true); pw.println("你好!服务端!"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 服务端 123456789101112131415161718192021222324252627282930313233343536373839404142/* * java.net.ServerSocket * 运行在服务端的ServerSocket的主要 * 作用是: * 1:向OS申请服务端口(客户端通过该端口 * 与服务端建立连接) * 2:监听服务端口,等待客户端连接,一旦一个 * 客户端连接后,就会创建一个Socket实例 * 与该客户端进行交互. */public static void main(String[] args) &#123; try &#123; /* * 初始化ServerSocket需要指定服务端口若该端口已经被其他应用程序占用则会 * 抛出异常 */ ServerSocket server = new ServerSocket(8088); /* * ServerSocket的方法 * Socket accept()该方法用来监听申请的服务端口,该方法是一个阻塞方法,直到一个 * 客户端通过该端口与服务端建立连接,这里便会自动创建一个Socket * 并返回,通过该Socket可以与刚连接的客户端进行交互. */ System.out.println("等待客户端连接..."); Socket socket = server.accept(); System.out.println("一个客户端连接了!"); /* * Socket提供的方法: * InputStream getInputStream() * 通过获取的输入流可以读取远端计算机 * 发送过来的数据 */ InputStream in = socket.getInputStream(); InputStreamReader isr = new InputStreamReader(in,"UTF-8"); BufferedReader br = new BufferedReader(isr); String message = br.readLine(); System.out.println("客户端说:"+message); &#125; catch (Exception e) &#123; e.printStackTrace(); System.out.println("服务端启动失败!"); &#125;&#125; 简单聊天室 服务端 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168package study.base;import java.io.*;import java.net.InetAddress;import java.net.ServerSocket;import java.net.Socket;import java.util.ArrayList;import java.util.List;/** * @ClassName Server * @Author gaoqisen * @Date 2019-11-26 * @Version 1.0 */public class Server &#123; /* * java.net.ServerSocket * 运行在服务端的ServerSocket的主要 * 作用是: * 1:向OS申请服务端口(客户端通过该端口 * 与服务端建立连接) * 2:监听服务端口,等待客户端连接,一旦一个 * 客户端连接后,就会创建一个Socket实例 * 与该客户端进行交互. */ private ServerSocket server; /* * 共享集合,用于存放所有客户端的输出流 * 以便广播消息 */ private List&lt;PrintWriter&gt; allOut; public Server() throws IOException&#123; /* * 初始化ServerSocket需要指定服务端口 * 若该端口已经被其他应用程序占用则会 * 抛出异常 */ server = new ServerSocket(8088); allOut = new ArrayList&lt;PrintWriter&gt;(); &#125; /** * 将给定的输出流存入共享集合 * @param out */ public synchronized void addOut(PrintWriter out)&#123; allOut.add(out); &#125; /** * 从共享集合中将给定输出流删除 * @param out */ public synchronized void removeOut(PrintWriter out)&#123; allOut.remove(out); &#125; /** * 将给定的消息发送至所有客户端 * @param message */ public synchronized void sendMessage(String message)&#123; for (int i = 0; i&lt; allOut.size(); i++) &#123; allOut.get(i).println(message); &#125; &#125; public void start()&#123; try &#123; while(true)&#123; /* * ServerSocket的方法 * Socket accept() * 该方法用来监听申请的服务端口, * 该方法是一个阻塞方法,直到一个 * 客户端通过该端口与服务端建立 * 连接,这里便会自动创建一个Socket * 并返回,通过该Socket可以与刚连接 * 的客户端进行交互. */ System.out.println("等待客户端连接..."); Socket socket = server.accept(); System.out.println("一个客户端连接了!"); //启动一个线程来处理该客户端的交互 ClientHandler handler = new ClientHandler(socket); Thread t = new Thread(handler); t.start(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * 该线程的任务是与指定的客户端进行交互 * @author adminitartor * */ class ClientHandler implements Runnable&#123; //该线程通过该Socket与指定客户端交互 private Socket socket; //客户端地址信息 private String host; public ClientHandler(Socket socket)&#123; this.socket = socket; //获取该客户端的地址信息 InetAddress address = socket.getInetAddress(); //获取其IP地址的字符串形式 host = address.getHostAddress(); &#125; @Override public void run()&#123; PrintWriter pw = null; try &#123; /* * 获取输出流,用于将服务端的消息通过该流 * 发送给客户端 */ OutputStream out = socket.getOutputStream(); OutputStreamWriter osw = new OutputStreamWriter(out,"UTF-8"); pw = new PrintWriter(osw,true); addOut(pw); /* * Socket提供的方法: * InputStream getInputStream() * 通过获取的输入流可以读取远端计算机 * 发送过来的数据 */ InputStream in = socket.getInputStream(); InputStreamReader isr = new InputStreamReader(in,"UTF-8"); BufferedReader br = new BufferedReader(isr); String message = null; /* * 在读取客户端发送过来的消息这里,由于客户端 * 所在操作系统不同,当客户端断开连接时,这里 * br.readLine的反应也不同: * linux的客户端断开时: * br.readLine方法会返回null. * * windows的客户端断开连接时: * br.readLine方法会直接抛出异常 * */ while((message = br.readLine())!=null)&#123; // System.out.println(host+"说:"+message); sendMessage(host+"说:"+message); &#125; &#125; catch (Exception e) &#123; &#125; finally&#123; try &#123; //处理客户端断开连接后的操作 System.out.println(host+"下线了"); removeOut(pw); //将Socket关闭 socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; try &#123; Server server = new Server(); server.start(); &#125; catch (Exception e) &#123; e.printStackTrace(); System.out.println("服务端启动失败!"); &#125; &#125;&#125; 客服端 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109package study.base;import java.io.*;import java.net.Socket;import java.net.UnknownHostException;import java.util.Scanner;/** * @ClassName Client * @Author gaoqisen * @Date 2019-11-26 * @Version 1.0 */public class Client &#123; /* * java.net.Socket * 封装了TCP协议 * 使用它可以与远程计算机连接并进行 * 数据交换,实现通讯的目的 */ private Socket socket; /** * 构造方法,用来初始化客户端 * @throws IOException * @throws UnknownHostException */ public Client() throws UnknownHostException, IOException&#123; /* * 初始化Socket * 初始化需要传入两个参数 * 参数1:远端计算机IP地址 * 参数2:远端计算机的服务端口 * * IP地址用来找到服务端所在的计算机 * 端口用来连接上该计算机上的服务端 * 应用程序 * * 实例化Socket的过程就是连接的过程 * 若远端计算机没有响应会抛出异常 */ System.out.println("正在连接服务端..."); socket = new Socket("localhost",8088); System.out.println("与服务端建立连接!"); &#125; /** * 客户端开始工作的方法 */ public void start()&#123; try &#123; //启动读取服务端消息的线程 ServerHandler handler = new ServerHandler(); Thread t = new Thread(handler); t.start(); Scanner scanner = new Scanner(System.in); /* * Socket的方法: * OutputStream getOutputStream() * 用于获取一个输出流,通过该输出流写出的字节 * 会发送至远端计算机.而远端计算机可以通过 * 输入流读取. */ OutputStream out = socket.getOutputStream(); OutputStreamWriter osw = new OutputStreamWriter(out,"UTF-8"); PrintWriter pw = new PrintWriter(osw,true); String message = null; while(true)&#123; message = scanner.nextLine(); pw.println(message); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; try &#123; Client client = new Client(); client.start(); &#125; catch (Exception e) &#123; e.printStackTrace(); System.out.println("客户端运行失败!"); &#125; &#125; /** * 该线程的任务是读取服务端发送过来的 * 每一条消息,并输出到控制台 * @author adminitartor * */ class ServerHandler implements Runnable&#123; @Override public void run()&#123; try &#123; InputStream in = socket.getInputStream(); InputStreamReader isr = new InputStreamReader(in,"UTF-8"); BufferedReader br = new BufferedReader(isr); String message = null; //读取服务端发送的每一条消息并输出 while((message=br.readLine())!=null)&#123; System.out.println(message); &#125; &#125; catch (Exception e) &#123; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java JavaSocket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IdeaDebug调试按钮]]></title>
    <url>%2Ftool%2Fidea.html</url>
    <content type="text"><![CDATA[快捷键12345678910// 多行选中Column Selection Mode// 修改所有变量名shift+F6// 方法参数提示Ctrl+L// 查看类注释Ctrl+Q// 抽取方法Fn+Ctrl+Alt+M DeBug各个按钮的意思 第一排(从左往右) Show Execution Point (Alt + F10)：如果你的光标在其它行或其它页面，点击这个按钮可跳转到当前代码执行的行。 Step Over (F8)：步过，一行一行地往下走，如果这一行上有方法不会进入方法。 Step Into (F7)：步入，如果当前行有方法，可以进入方法内部，一般用于进入自定义方法内，不会进入官方类库的方法，如第25行的put方法。 Force Step Into (Alt + Shift + F7)：强制步入，能进入任何方法，查看底层源码的时候可以用这个进入官方类库的方法。 Step Out (Shift + F8)：步出，从步入的方法内退出到方法调用处，此时方法已执行完毕，只是还没有完成赋值。 Drop Frame (默认无)：回退断点。 Run to Cursor (Alt + F9)：运行到光标处，你可以将光标定位到你需要查看的那一行，然后使用这个功能，代码会运行至光标行，而不需要打断点。 Evaluate Expression (Alt + F8)：计算表达式。 第二排（从上往下） Rerun ‘xxxx’：重新运行程序，会关闭服务后重新启动程序。 Resume Program (F9)：恢复程序，比如，你在第20行和25行有两个断点，当前运行至第20行，按F9，则运行到下一个断点(即第25行)，再按F9，则运行完整个流程，因为后面已经没有断点了。 Pause Program：暂停程序，启用Debug。目前没发现具体用法。 Stop ‘xxx’ (Ctrl + F2)：连续按两下，关闭程序。有时候你会发现关闭服务再启动时，报端口被占用，这是因为没完全关闭服务的原因，你就需要查杀所有JVM进程了。 View Breakpoints (Ctrl + Shift + F8)：查看所有断点，后面章节会涉及到。 Mute Breakpoints：哑的断点，选择这个后，所有断点变为灰色，断点失效，按F9则可以直接运行完程序。再次点击，断点变为红色，有效。如果只想使某一个断点失效，可以在断点上右键取消Enabled，如图2.4，则该行断点失效。 查看线程的dump 设置。显示方法返回值等 锁定与取消选项卡]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[了解token并用JWT实现]]></title>
    <url>%2Fjava%2FwebJsonToken.html</url>
    <content type="text"><![CDATA[Token定义token是服务器端生成的一串字符串，作为服务端访问服务端的一个令牌。第一次登录的是就为客服端生成一个token，后期用户登录的时候就传递这个token用于验证，无需带上用户的用户的帐号和密码。 流程 APP登录的时候发送加密的用户名和密码到服务器，服务器验证用户名和密码，如果成功，以某种方式比如随机生成32位的字符串作为token，存储到服务器中，并返回token到APP，以后APP请求时，凡是需要验证的地方都要带上该token，然后服务器端验证token，成功返回所需要的结果，失败返回错误信息，让他重新登录。其中服务器上token设置一个有效期，每次APP请求的时候都验证token和有效期。 客户端使用用户名跟密码请求登录 服务端收到请求，去验证用户名与密码 验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端 客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里或者 Local Storage 里 客户端每次向服务端请求资源的时候需要带着服务端签发的 Token 服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向客户端返回请求的数据 优势 无状态、可扩展: 在客户端存储的Tokens是无状态的，并且能够被扩展。基于这种无状态和不存储Session信息，负载均衡器能够将用户信息从一个服务传到其他服务器上。如果我们将已验证的用户的信息保存在Session中，则每次请求都需要用户向已验证的服务器发送验证信息(称为Session亲和性)，用户量大时，可能会造成 一些拥堵。然而tokens的无状态性完美解决了这个问题。 安全性: 请求中发送token而不再是发送cookie能够防止CSRF(跨站请求伪造)。即使在客户端使用cookie存储token，cookie也仅仅是一个存储机制而不是用于认证。不将信息存储在Session中，让我们少了对session操作。token是有时效的，一段时间之后用户需要重新验证。我们也不一定需要等到token自动失效，token有撤回的操作，通过token revocataion可以使一个特定的token或是一组有相同认证的token无效。 可扩展性: Tokens能够创建与其它程序共享权限的程序。个人理解就是自己可以提供一个类似第三方登录的功能，其他程序集成自己的登录，通过token授权 多平台跨域: CORS(跨域资源共享)，对应用程序和服务进行扩展的时候，需要介入各种各种的设备和应用程序。只要用户有一个通过了验证的token，数据和资源就能够在任何域上被请求到。 JWT（Json Web Token）原理 服务端认证之后生成一个json对象，返回给客服端如 12&#123;&quot;姓名&quot;,&quot;test&quot;，&quot;角色&quot;:&quot;学生&quot;&#125; // 返回一个json串pC5jRyXsdYWwpC5jRyXsdYWw== // 或者一串AES加密串保存用户姓名等 后面每次访问服务器的时候都将这段数据传给服务器，服务器只依靠这个就判断认定用户身份。为了防止用户篡改数据，服务器在生成这个对象的时候，会加上签名。 服务器不保存任何session信息，这样服务器就是无状态的了，后面添加负载也更容易 结构JWT返回的token分为3段，Header（头部），Payload（负载），Signature（签名）。分别用 . 隔开（Header.Payload.Signature）。如(点后面没有回车)： 123eyJhbGciOiJIUzI1NiJ9.eyJqdGkiOiJpbnNwdXIiLCJpYXQiOjE1NzMwMzAwNjQsInN1YiI6InFCMmNiNUFuMkg5WGovWEF5SVhucWc9PVxyXG4iLCJleHAiOjE1NzMxMTY0NjR9.eUIzHeBqYKtWM9owo36FzFaJByn0K1MP2n_rXSm4Xa4 JSON 对象使用 Base64URL 算法解密后 Header：描述 JWT 的元数据（JSON 对象使用 Base64URL 算法）。 1234&#123; &quot;alg&quot;: &quot;HS256&quot;, &quot;typ&quot;: &quot;JWT&quot;&#125; lg属性表示签名的算法（algorithm），默认是 HMAC SHA256（写成 HS256）；typ属性表示这个令牌（token）的类型（type），JWT 令牌统一写为JWT Payload: 用来存放实际需要传递的数据（JSON 对象也要使用 Base64URL 算法转成字符串）。JWT 规定了7个官方字段: 1234567iss (issuer)：签发人exp (expiration time)：过期时间sub (subject)：主题aud (audience)：受众nbf (Not Before)：生效时间iat (Issued At)：签发时间jti (JWT ID)：编号 除了官方字段，也可以在这个部分定义私有字段。但是JWT 默认是不加密的，任何人都可以读到，所以不要把秘密信息放在这个部分。 Signature: 是对前两部分的签名，防止数据篡改。 需要指定一个密钥（secret）。这个密钥只有服务器才知道，不能泄露给用户。然后，使用 Header 里面指定的签名算法（默认是 HMAC SHA256），按照下面的公式产生签名。 算出签名以后，把 Header、Payload、Signature 三个部分拼成一个字符串，每个部分之间用”点”（.）分隔，就可以返回给用户。 1234HMACSHA256(base64UrlEncode(header) + &quot;.&quot; +base64UrlEncode(payload),secret) Base64 有三个字符+、/和=，在 URL 里面有特殊含义，所以要被替换掉：=被省略、+替换成-，/替换成_ 。这就是 Base64URL 算法 特点 默认是不加密，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次。 不加密的情况下，不能将秘密数据写入 JWT 不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以降低服务器查询数据库的次数 由最大的缺点是由于服务器不保存 session 状态，因此无法在使用过程中废止某个 token，或者更改 token 的权限。也就是说，一旦 JWT 签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，JWT 的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证 为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输。 SpringBoot使用maven依赖12345&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.9.1&lt;/version&gt; &lt;/dependency&gt; 工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103import javax.crypto.SecretKey;import java.util.Date;import javax.crypto.spec.SecretKeySpec;import io.jsonwebtoken.*;import org.apache.commons.codec.binary.Base64;import org.slf4j.Logger;import org.slf4j.LoggerFactory;/** * @ClassName JwtUtil * @Author gaoqisen * @Date 2019-11-05 * @Version 1.0 */public class JwtUtil &#123; private static final Logger logger = LoggerFactory.getLogger(ApacheHttpClient.class); /** * 由字符串生成加密key * @return */ public SecretKey generalKey()&#123; //本地配置文件中加密的密文7786df7fc3a34e26a61c034d5ec8245d String stringKey = TokenConstant.JWT_SECRET; //本地的密码解码[B@152f6e2786df7fc3a34e26a61c034d5ec8245d byte[] encodedKey = Base64.decodeBase64(stringKey); // 根据给定的字节数组使用AES加密算法构造一个密钥，使用 encodedKey中的始于且包含 0 到前 leng 个字节这是当然是所有。 SecretKey key = new SecretKeySpec(encodedKey, 0, encodedKey.length, "AES"); return key; &#125; /** * 创建jwt * @param id * @param subject * @param ttlMillis * @return * @throws Exception */ public String createJWT(String id, String subject, long ttlMillis) throws Exception&#123; SignatureAlgorithm signatureAlgorithm = SignatureAlgorithm.HS256; long nowMillis = System.currentTimeMillis(); Date now = new Date(nowMillis); //创建payload的私有声明（根据特定的业务需要添加，如果要拿这个做验证，一般是需要和jwt的接收方提前沟通好验证方式的） //Map&lt;String,Object&gt; claims = new HashMap&lt;String,Object&gt;(); //claims.put("uid", "CVLm6KSSSkeNRg5pMqop2w"); //claims.put("user_name", "admin"); //claims.put("nick_name","DASDA121"); SecretKey key = generalKey(); JwtBuilder builder = Jwts.builder() //如果有私有声明，一定要先设置这个自己创建的私有的声明，这个是给builder的claim赋值，一旦写在标准的声明赋值之后，就是覆盖了那些标准的声明的 //.setClaims(claims) .setId(id) .setIssuedAt(now) .setSubject(subject) .signWith(signatureAlgorithm, key); if (ttlMillis &gt;= 0) &#123; long expMillis = nowMillis + ttlMillis; Date exp = new Date(expMillis); //设置过期时间 builder.setExpiration(exp); &#125; //就开始压缩为xxxxxxxxxxxxxx.xxxxxxxxxxxxxxx.xxxxxxxxxxxxx这样的jwt return builder.compact(); &#125; /** * 解密jwt * @param jwt * @return * @throws Exception */ public Claims parseJWT(String jwt) throws Exception&#123; SecretKey key = generalKey(); Claims claims = Jwts.parser() .setSigningKey(key) .parseClaimsJws(jwt).getBody(); return claims; &#125; /** * 校验jwt * @param jwt * @return * @throws */ public boolean validateJWT(String jwt) &#123; boolean flag = false; try &#123; parseJWT(jwt); flag = true; &#125; catch (ExpiredJwtException e) &#123; logger.error("token过期"); &#125; catch (SignatureException e) &#123; logger.error("签名校验失败"); &#125; catch (Exception e) &#123; logger.error("其它错误"); &#125; return flag; &#125;&#125; 常量123public static final String JWT_ID = "jwt"; public static final String JWT_SECRET = "26e4b9wqrfe444568f24232108460891"; public static final int JWT_TTL = 1*60*60*1000; // 60*60*1000; //过期时间（毫秒） 接口开发1234567891011121314151617181920212223242526272829303132333435363738394041 public JSONObject getToken(String msg) &#123; JSONObject json = new JSONObject(); JwtUtil util = new JwtUtil(); try &#123; String token = util.createJWT(TokenConstant.JWT_ID, msg TokenConstant.JWT_TTL); json.put("state", "ok"); json.put("token", token); &#125; catch (Exception e) &#123; json.put("state","error"); json.put("msg", "Token处理失败"); &#125; return json; &#125; public JSONObject checkToken(String token) &#123; JSONObject json = new JSONObject(); JwtUtil jwt = new JwtUtil(); boolean rs = jwt.validateJWT(token); json.put("state","ok"); json.put("token", rs); return json; &#125; public JSONObject getUserInfoByToken(String token) &#123; JSONObject json = new JSONObject(); JwtUtil jwt = new JwtUtil(); boolean rs = jwt.validateJWT(token); if (!rs) &#123; json.put("state", "error"); json.put("msg", "Token验证失败"); return json; &#125; try &#123; // 通过用户帐号获取用户信息 Claims claims = jwt.parseJWT(token); String id = claims.getSubject(); // 处理业务逻辑 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return json; &#125;&#125; 注: 网上说jwt只能抗2w并发， 如果并发过大会出现问题。（待验证）]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java token</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql －学习笔记]]></title>
    <url>%2Fdatabase%2FmysqlBase.html</url>
    <content type="text"><![CDATA[常用123456789101112-- 增加唯一索引alter table tablename add unique index uniq_name(filedName);-- 修改唯一索引alter table tablename drop key uniq_name;alter table tablename add unique index uniq_name(filedName);-- 在MYSQL里，不能先select一个表的记录，在按此条件进行更新和删除同一个表的记录，解决办法是，将select得到的结果，再通过中间表select一遍update tablename set status = 1 where id in (select id from (select id from tablename where name &lt;&gt; 1));-- 增加字段alter table tablename add column `fieldName` varcher(200) null comment &apos;字段名称&apos; after `id`; 一、优化方法1.1. sql优化1.1.1 索引优化 重复索引: MySQL需要单独维护重复的索引，并且优化器在优化查询的时候也需要逐个地进行考虑，这会影响性能,建议删除多余索引 联合索引符合最左原则: key index(a,b,c)相当于创建了三个索引a,ab,abc。不支持bc索引 那些情况下不会使用索引 索引不会包含有NULL值的列: 只要列中包含有NULL值都将不会被包含在索引中，复合索引中只要有一列含有NULL值，那么这一列对于此复合索引就是无效的。所以我们在数据库设计时不要让字段的默认值为NULL 条件中有or: 要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引 like查询是以%开头 存在索引列的数据类型隐形转换: 如列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引 where 子句里对索引列上有数学运算，用不上索引 where 子句里对有索引列使用函数 数据量极少: 如果mysql估计使用全表扫描要比使用索引快 Join的字段类型不相同: 如果你要把DECIMAL字段和一个INT字段Join在一起，MySQL就无法使用它们的索引。 不推荐使用索引 数据唯一性差（一个字段的取值只有几种时）的字段不要使用索引 频繁更新的字段不要使用索引 字段不在where语句出现时不要添加索引,如果where后含IS NULL /IS NOT NULL/ like ‘%输入符%’等条件，不建议使用索引 where 子句里对索引列使用不等于（&lt;&gt;），使用索引效果一般 1.1.2 慢查询优化通过记录慢查询日志，找到查询慢的sql进行优化(增加索引等) 123456-- 慢查询报表生成工具pt-query-digest slow-log &gt; text.log-- 索引维护工具pt-duplicate-key-checker -u root -p &apos;123456&apos;-- 查询不使用的索引pt-index-usage -uroot -p &apos;123456&apos; mysql-slow.log 1.1.3 语句优化 避免 SELECT *，(1)，读出越多的数据，那么查询就会变得越慢。(2)，加网络传输的负载 不使用ORDER BY RAND()，MySQL会去执行RAND()函数（很耗CPU时间），而且这是为了每一行记录去记行，然后再对其排序 使用ENUM而不是VARCHAR： ENUM保存的是TINYINT，但其外表上显示为字符串。这样一来，用这个字段来做一些选项列表变得相当的完美。如果你有一个字段，比如“性别”，“国家”，“民族”，“状态”或“部门”，你知道这些字段的取值是有限而且固定的，那么，你应该使用ENUM而不是VARCHAR 拆分大的DELETE或INSERT语句： DELETE和INSERT会进行锁表，如果生产环境操作的话，可能会造成服务无法使用的情况。建议使用limit 1000循环删除数据，删除的时候也sleep一下。 当只需要一条数据时使用LIMIT 1：这样MySQL数据库引擎会在找到一条数据后停止搜索，而不是继续往后查少下一条符合记录的数据 1.1.5 EXPLAINexplain不会考虑的情况: 触发器、存储过程的信息或用户自定义函数对查询的影响情况、各种Cache、显示MySQL在执行查询时所作的优化工作、部分统计信息是估算的，并非精确值、只能解释SELECT操作，其他操作要重写为SELECT后查看执行计划 12345678-- mysql执行计划mysql&gt; explain select * from servers;+----+-------------+---------+------+---------------+------+---------+------+------+-------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+---------+------+---------------+------+---------+------+------+-------+| 1 | SIMPLE | servers | ALL | NULL | NULL | NULL | NULL | 1 | NULL |+----+-------------+---------+------+---------------+------+---------+------+------+-------+1 row in set (0.03 sec) id: 执行编号，标识select所属的行。如果在语句中没子查询或关联查询，只有唯一的select，每行都将显示1。否则，内层的select语句一般会顺序编号，对应于其在原始语句中的位置 select_type: 显示本行是简单或复杂select。 | SIMPLE | 简单SELECT,不使用UNION或子查询等 || ——————– | ———————————————————- || PRIMARY | 查询中若包含任何复杂的子部分,最外层的select被标记为PRIMARY || UNION | UNION中的第二个或后面的SELECT语句 || DEPENDENT UNION | UNION中的第二个或后面的SELECT语句，取决于外面的查询 || UNION RESULT | UNION的结果 || SUBQUERY | 子查询中的第一个SELECT || DEPENDENT SUBQUERY | 子查询中的第一个SELECT，取决于外面的查询 || DERIVED | 派生表的SELECT, FROM子句的子查询 || UNCACHEABLE SUBQUERY | 一个子查询的结果不能被缓存，必须重新评估外链接的第一行 | table: 显示这一行的数据是关于哪张表的，有时不是真实的表名字,看到的是derivedx(x为数字，应该是第几步的意思) type: 数据访问/读取操作类型(从上到下，性能从差到好) | ALL | Full Table Scan， MySQL将遍历全表以找到匹配的行 || ————- | ———————————————————— || index | Full Index Scan，index与ALL区别为index类型只遍历索引树 || range | 只检索给定范围的行，使用一个索引来选择行 || ref | 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值 || eq_ref | 使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用primary key或者 unique key作为关联条件 || const、system | 当MySQL对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于where列表中，MySQL就能将该查询转换为一个常量,system是const类型的特例，当查询的表只有一行的情况下，使用system || NULL | MySQL在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成 | possible_keys: MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用 key: 显示mysql决定采用哪个索引来优化查询 key_len: 表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度（key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的） ref: 显示了之前的表在key列记录的索引中查找值所用的列或常量 rows: 为了找到所需的行而需要读取的行数，估算值，不精确。通过把所有rows列值相乘，可粗略估算整个查询会检查的行数 Extra: 包含MySQL解决查询的详细信息 Using where:列数据是从仅仅使用了索引中的信息而没有读取实际的行动的表返回的，这发生在对表的全部的请求列都是同一个索引的部分的时候，表示mysql服务器将在存储引擎检索行后再进行过滤 Using temporary：表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询 Using filesort：MySQL中无法利用索引完成的排序操作称为“文件排序” Using join buffer：改值强调了在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。 Impossible where：这个值强调了where语句会导致没有符合条件的行。 Select tables optimized away：这个值意味着仅通过使用索引，优化器可能仅从聚合函数结果中返回一行 1.2. 表结构优化 类型选择: 尽量设置小的类型, 数据库90%以上的时间都是在IO上，尽量少的IO读写就会提高数据库性能。时间类型尽量使用TIMESTAMP类型，只需要精确到某一天的数据类型，建议使用DATE(3个字节)类型 。数字类型尽量不要使用DOUBLE(长度问题和精度问题)。字符串类型尽量不要用TEXT类型，建议使用 CHAR 类型，不定长字段尽量使用 VARCHAR。反对在数据库中使用 LOB 类型数据，应该使用其他工具存储大数据。 能增加not null约束的一定要加上：NULL 类型比较特殊，SQL 难优化。虽然 MySQL NULL类型和 Oracle 的NULL 有差异，会进入索引中，但如果是一个组合索引，那么这个NULL 类型的字段会极大影响整个索引的效率。此外，NULL 在索引中的处理也是特殊的，也会占用额外的存放空间 日期类型或者存储ip字段优化：把IP地址存成UNSIGNED INT 1.3 服务器优化 mysql配置优化 存储引擎: InnoDB(支持事务，行锁,支持外键)，MyISAM(表级锁、不支持事务和全文索引) back_log: MySql的连接数据达到max_connections时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，将不不被授予连接资源。查看mysql 当前系统默认back_log值，命令：show variables like ‘back_log’; wait_timeout: 可以减少wait的连接数(wait_timeout=1800) show variables like ‘wait_timeout’; max_connections: 最大链接数，show variables like ‘max_connections’; thread_concurrency: 目前默认的8，可以修改为thread_concurrency=64，thread_concurrency应设为CPU核数的2倍，比如有1个双核的CPU，那thread_concurrency 的应该为4，2个双核的cpu thread_concurrency的值应为8。show variables like ‘thread_concurrency’; max_connect_errors: 这个参数负责阻止客户端尝试暴力破解密码，当某台主机错误连接次数达到该值时，该主机无法再尝试登陆。解决方法是重启mysql，或者把该值改大一点 query_cache_type: query_cache_type=1 开启缓存，显示为ON。大多数的MySQL服务器都开启了查询缓存。利用变量代替函数去执行sql，CURDATE(),NOW(),RAND()这些时间函数都不会开启查询缓存。 硬件优化 配置较大的内存。足够大的内存,是提高 MYSQL数据库性能的方法之一。内存的速度 比磁盘I/O快得多,可以通过增加系统的缓冲区容量,使数据在内存停留的时间更长,以减少磁盘I/O。 配置高速磁盘系统,以减少读盘的等待时间,提高响应速度 合理分布磁盘I/O,把磁盘IO分散在多个设备上,以减少资源竞争,提高并行操作能力 配置多处理器, MYSQL是多线程的数据库,多处理器可同时执行多个线程。 cpu并不是越多越好,mysql5.5是的服务器不要超过32核,偏向选择单核频率更快的cpu; 二、基本操作123456789101112131415161718192021222324252627282930313233-- 查看mysql锁表信息show status like &apos;%lock%&apos;;show OPEN TABLES where In_use &gt; 0;-- 显示哪些线程正在运行show processlist;-- kill线程kill 16557290;-- 获取锁表信息select * from information_schema.processlist where db = &apos;tablename&apos;;-- 批量kill线程语句生成select CONCAT(&apos;kill &apos;,ID,&apos;;&apos;) from information_schema.processlist where db = &apos;tablename&apos; and info like &apos;***%&apos;;-- mysql 启动、停止、重启（5.0版本）service mysqld startservice mysqld stopservice mysqld restart -- mysql 启动、停止、重启（5.5.7版本）service mysql startservice mysql stopservice mysql restart-- 脚本启动、停止、重启/etc/inint.d/mysqld start/etc/inint.d/mysqld stop/etc/inint.d/mysqld restart-- 链接mysql -uroot -p // 回车输入密码即可-- 查看表的当前自增IDselect auto_increment from information_schema.tables where table_schema=&apos;bsp&apos; and table_name=&apos;sys_menu&apos;;-- 修改表的当前自增IDalter table sys_menu AUTO_INCREMENT=100;-- 查看表信息SHOW TABLE STATUS;-- 慢查询日志分析统计工具mysqldumpslow 三、库操作1234567891011121314151617-- 查看当前数据库SELECT DATABASE();-- 显示当前时间、用户名、数据库版本SELECT now(), user(), version();-- 创建库CREATE DATABASE[ IF NOT EXISTS] databasesname 数据库选项 数据库选项： CHARACTER SET charset_name COLLATE collation_name-- 查看当前库信息 SHOW CREATE DATABASE databasesname-- 修改库的选项信息 ALTER DATABASE databasesname 选项信息-- 修改数据库的编码，可使用上一条语句查看是否修改成功alter database databasesname default character set gbk collate gbk_bin;-- 删除库,同时删除该数据库相关的目录及其目录内容DROP DATABASE[ IF EXISTS] databasesname 四、数据类型(列类型)4.1数值类型 整型 | 类型 | 字节 | 有符号位 | 无符号位 | | — | — | — | — | | tinyint | 1 | -128 ~ 127 | 0 ~ 255 | | smallint | 2 | -32768 ~ 32767| 0 ~ 65535 | | mediumint | 3 | -8388608 ~ 8388607| 0 ~ 1677215 | | int、integer | 4 | -2147483648 ~ 2147483647 | 0 ~ 4294967295 | | bigint | 8 | -922337203684775808-9223372036854775807 | 0 ~ 148446744073709551615 | | float | 4 | | | | double | 8 | | | 默认存在符号位，unsigned 属性修改 显示宽度，如果某个数不够定义字段时设置的位数，则前面以0补填，zerofill 属性修改 例：int(5) 插入一个数’123’，补填后为’00123’ 在满足要求的情况下，越小越好。 1表示bool值真，0表示bool值假。MySQL没有布尔类型，通过整型0和1表示。常用tinyint(1)表示布尔型。 浮点型 |类型 | 字节 | 范围| | — | — | — | |float(单精度)| 4字节|| | double(双精度) | 8字节|| 浮点型既支持符号位 unsigned 属性，也支持显示宽度 zerofill 属性。 不同于整型，前后均会补填0. 定义浮点型时，需指定总位数和小数位数。 float(M, D) double(M, D) M表示总位数，D表示小数位数。 M和D的大小会决定浮点数的范围。不同于整型的固定范围。 M既表示总位数（不包括小数点和正负号），也表示显示宽度（所有显示符号均包括）。 支持科学计数法表示。 浮点数表示近似值。 定点数 decimal – 可变长度 decimal(M, D) M也表示总位数，D表示小数位数。 保存一个精确的数值，不会发生数据的改变，不同于浮点数的四舍五入。 将浮点数转换为字符串来保存，每9位数字保存为4个字节。4.2字符串类型 char, varchar ———- char(M) 定长字符串，速度快，但浪费空间 varchar(M) 变长字符串，速度慢，但节省空间 M表示能存储的最大长度，此长度是字符数，非字节数。 不同的编码，所占用的空间不同。 char,最多255个字符，与编码无关。 varchar,最多65535字符，与编码有关。 一条有效记录最大不能超过65535个字节。 utf8 最大为21844个字符，gbk 最大为32766个字符，latin1 最大为65532个字符 varchar 是变长的，需要利用存储空间保存 varchar 的长度，如果数据小于255个字节，则采用一个字节来保存长度，反之需要两个字节来保存。 varchar 的最大有效长度由最大行大小和使用的字符集确定。 最大有效长度是65532字节，因为在varchar存字符串时，第一个字节是空的，不存在任何数据，然后还需两个字节来存放字符串的长度，所以有效长度是64432-1-2=65532字节。 例：若一个表定义为 CREATE TABLE tb(c1 int, c2 char(30), c3 varchar(N)) charset=utf8; 问N的最大值是多少？ 答：(65535-1-2-4-30*3)/3 blob, text ———- blob 二进制字符串（字节字符串） tinyblob, blob, mediumblob, longblob text 非二进制字符串（字符字符串） tinytext, text, mediumtext, longtext text 在定义时，不需要定义长度，也不会计算总长度。 text 类型在定义时，不可给default值 binary, varbinary ———- 类似于char和varchar，用于保存二进制字符串，也就是保存字节字符串而非字符字符串。 char, varchar, text 对应 binary, varbinary, blob.4.3日期时间类型 类型 字节数 名词 范围 datetime 8 年月日时分秒 1000-01-01 00:00:00 到 9999-12-31 23:59:59 date 3 年月日 1000-01-01 到 9999-12-31 timestamp 4 年月日时分秒 19700101000000 到 2038-01-19 03:14:07 time 3 时分秒 -838:59:59 到 838:59:59 year 1 年 1901 - 2155 datetime YYYY-MM-DD hh:mm:ss timestamp YY-MM-DD hh:mm:ss YYYYMMDDhhmmss YYMMDDhhmmss YYYYMMDDhhmmss YYMMDDhhmmss date YYYY-MM-DD YY-MM-DD YYYYMMDD YYMMDD YYYYMMDD YYMMDD time hh:mm:ss hhmmss hhmmss year YYYY YY YYYY YY4.4枚举和集合 枚举: enum(val1, val2, val3…) 在已知的值中进行单选。最大数量为65535. 枚举值在保存时，以2个字节的整型(smallint)保存。每个枚举值，按保存的位置顺序，从1开始逐一递增。 表现为字符串类型，存储却是整型。 NULL值的索引是NULL。 空字符串错误值的索引值是0。 集合: set(val1, val2, val3…) create table tab ( gender set(‘男’, ‘女’, ‘无’) ); insert into tab values (‘男, 女’); 最多可以有64个不同的成员。以bigint存储，共8个字节。采取位运算的形式。 当创建表时，SET成员值的尾部空格将自动被删除。 五、列属性(列约束) PRIMARY 主键 能唯一标识记录的字段，可以作为主键。 一个表只能有一个主键。 主键具有唯一性。 声明字段时，用 primary key 标识。 也可以在字段列表之后声明例：create table tab ( id int, stu varchar(10), primary key (id)); 主键字段的值不能为null。 主键可以由多个字段共同组成。此时需要在字段列表后声明的方法。 例：create table tab ( id int, stu varchar(10), age int, primary key (stu, age)); UNIQUE 唯一索引（唯一约束） 使得某字段的值也不能重复。 NULL 约束 null不是数据类型，是列的一个属性。 表示当前列是否可以为null，表示什么都没有。 null, 允许为空。默认。 not null, 不允许为空。 insert into tab values (null, ‘val’); //此时表示将第一个字段的值设为null, 取决于该字段是否允许为null DEFAULT 默认值属性 当前字段的默认值。 insert into tab values (default, ‘val’); – 此时表示强制使用默认值。 create table tab ( add_time timestamp default current_timestamp );//表示将当前时间的时间戳设为默认值。current_date, current_time AUTO_INCREMENT 自动增长约束 自动增长必须为索引（主键或unique） 只能存在一个字段为自动增长。 默认为1开始自动增长。可以通过表属性 auto_increment = x进行设置，或 alter table tbl auto_increment = x; COMMENT 注释 例：create table tab ( id int ) comment ‘注释内容’; FOREIGN KEY 外键约束 用于限制主表与从表数据完整性。 alter table t1 add constraint t1_t2_fk foreign key (t1_id) references t2(id); 将表t1的t1_id外键关联到表t2的id字段。 每个外键都有一个名字，可以通过 constraint 指定 存在外键的表，称之为从表（子表），外键指向的表，称之为主表（父表）。 作用：保持数据一致性，完整性，主要目的是控制存储在外键表（从表）中的数据。 MySQL中，可以对InnoDB引擎使用外键约束,语法： foreign key (外键字段） references 主表名 (关联字段) [主表记录删除时的动作] [主表记录更新时的动作] 此时需要检测一个从表的外键需要约束为主表的已存在的值。外键在没有关联的情况下，可以设置为null.前提是该外键列，没有not null。 可以不指定主表记录更改或更新时的动作，那么此时主表的操作被拒绝。 如果指定了 on update 或 on delete：在删除或更新时，有如下几个操作可以选择： cascade，级联操作。主表数据被更新（主键值更新），从表也被更新（外键值更新）。主表记录被删除，从表相关记录也被删除。 set null，设置为null。主表数据被更新（主键值更新），从表的外键被设置为null。主表记录被删除，从表相关记录外键被设置成null。但注意，要求该外键列，没有not null属性约束。 restrict，拒绝父表删除和更新。 外键只被InnoDB存储引擎所支持。其他引擎是不支持的。 六、建表规范12345678910111213-- Normal Format, NF - 每个表保存一个实体信息 - 每个具有一个ID字段作为主键 - ID主键 + 原子表-- 1NF, 第一范式 字段不能再分，就满足第一范式。-- 2NF, 第二范式 满足第一范式的前提下，不能出现部分依赖。 消除复合主键就可以避免部分依赖。增加单列关键字。-- 3NF, 第三范式 满足第二范式的前提下，不能出现传递依赖。 某个字段依赖于主键，而有其他字段依赖于该字段。这就是传递依赖。 将一个实体信息的数据放在一个表内实现。 七、SQL实战 有个部门表如下，写出不同部门之间平均工资高于2000的部门 1select type, avg(salary) sa from dept group by type having sa &gt; 2000; 编写一个 SQL 查询，满足条件：无论 person 是否有地址信息，都需要基于上述两表提供 person 的以下信息：FirstName, LastName, City, State 123456789101112131415161718192021# Person+-------------+---------+| 列名 | 类型 |+-------------+---------+| PersonId | int || FirstName | varchar || LastName | varchar |+-------------+---------+# PersonId 是上表主键# Address+-------------+---------+| 列名 | 类型 |+-------------+---------+| AddressId | int || PersonId | int || City | varchar || State | varchar |+-------------+---------+# AddressId 是上表主键# sqlselect Person.FirstName, Person.LastName, Address.City, Address.State from Person left join Address on Person.PersonId = Address.PersonId 八、锁8.1 悲观锁认为别的线程会修改值。在操作数据的时候，直接给数据加锁不让其他的线程修改，当前线程修改成功之后其他线程才可以修改。实现方式就是加锁(如: Java的synchronized)。 8.2 乐观锁认为别的线程不会修改值。在操作数据的时候不对数据上锁，执行操作的时候判断一下数据是否被修改，如果被修改就放弃操作。实现方式有两种，CAS和版本号机制。 CAS(Compare And Swap) 在修改的时候判断查出来的数据是否被修改过，如果没有则进行修改，如果被修改了可以进行自旋操作。这种情况有可能出现ABA问题(多线程的时候如果当前线程为A,线程B把num加1，线程C把num减1期间线程A查询出数据还未进行操作，当BC线程执行完成之后A线程在此执行的时候就会认为数据没有修改，但是实际上数据被修改过)，用版本号机制就不会出现这个问题。 1234# 查询产品数量和IDselect num,id from product;# subNum为查出来的num-1, id和num都为查出来的数据。update product set num = #&#123;subNum&#125; where id = #&#123;id&#125; and num = #&#123;num&#125; 当竞争不激烈 (出现并发冲突的概率小)时，乐观锁更有优势，因为悲观锁会锁住代码块或数据，其他线程无法同时访问，影响并发，而且加锁和释放锁都需要消耗额外的资源。 版本号机制 在字段中增加一个版本号用来判断当前数据是否被修改过 1234# 查询产品数量、ID和版本号select num,id,version from product;# 通过版本号判断数据是否被修改,subNum是通过计算过后的库存数量, id和version都为查出来的数据update product set num = #&#123;subNum&#125; where id = #&#123;id&#125; and version = #&#123;version&#125; 当竞争激烈(出现并发冲突的概率大)时，悲观锁更有优势，因为乐观锁在执行更新时频繁失败，需要不断重试，浪费CPU资源。 九、参考 索引: https://blog.csdn.net/kaka1121/article/details/53395587 explain: https://www.cnblogs.com/xuanzhi201111/p/4175635.html 锁: https://www.cnblogs.com/kismetv/p/10787228.html#t1]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ SpringBoot 实践]]></title>
    <url>%2Ftool%2Frocketmq.html</url>
    <content type="text"><![CDATA[官网：https://rocketmq.apache.org/ 消息队列简介 可以把消息队列比作是一个存放消息的容器，当我们需要使用消息的时候可以取出消息供自己使用。消息队列是分布式系统中重要的组件，使用消息队列主要是为了通过异步处理提高系统性能和削峰、降低系统耦合性。目前使用较多的消息队列有ActiveMQ，RabbitMQ，Kafka，RocketMQ 消息队列的优点： 通过异步处理提高系统性能（削峰、减少响应所需时间）; 降低系统耦合性。 消息队列缺点: 系统可用性降低: 要担心MQ队列挂掉和消息丢失 系统复杂性提高：需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题 一致性问题：消息的真正消费者没有正确消费消息，导致数据不一致。 名词解释： Topic: 主题（Topic）作为消息通信载体，类似于广播模式；发布者发布一条消息，该消息通过主题传递给所有的订阅者，在一条消息广播之后才订阅的用户则是收不到该条消息的。 生产者（消息发布者）：负责生产消息并发送消息到Topic 消费者（消息订阅者）: 负责从Topic接收消息并消费 消息：生产者向消息到Topic，消费者接受到的数据 消息属性： 生产者给消息定义的属性，包含Message Key 和 Tag Group: 给一类生产者和消费者分一个组，消息发布或订阅的逻辑一致 应用场景:削峰填谷、异步解耦、顺序收发、分布式事务一致性、大数据分析、分布式缓存同步 RocketMQ特色功能：消息查询、消息轨迹、集群消费、广播消费、重置消费位点、死信队列、全球消息路由、资源报表、监控报警 消息类型：普通消息、事务消息、延时消息、顺序消息 MAC安装下载链接https://www.apache.org/dyn/closer.cgi?path=rocketmq/4.1.0-incubating/rocketmq-all-4.1.0-incubating-source-release.zip 命令行安装12345cd rocketmq-all-4.1.0-incubatingmvn -Prelease-all -DskipTests clean install -U // maven依赖cd distribution/target/apache-rocketmqsh bin/mqnamesrv &amp; // 启动 Name Server服务sh bin/mqbroker -n localhost:9876 autoCreateTopicEnable=true &amp; // 启动 broker docker-compose安装12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455version: '3.5'services: rmqnamesrv: image: foxiswho/rocketmq:server container_name: rmqnamesrv ports: - 9876:9876 volumes: - ./data/logs:/opt/logs - ./data/store:/opt/store networks: rmq: aliases: - rmqnamesrv rmqbroker: image: foxiswho/rocketmq:broker container_name: rmqbroker ports: - 10909:10909 - 10911:10911 volumes: - ./data/logs:/opt/logs - ./data/store:/opt/store - ./data/brokerconf/broker.conf:/etc/rocketmq/broker.conf environment: NAMESRV_ADDR: "rmqnamesrv:9876" JAVA_OPTS: " -Duser.home=/opt" JAVA_OPT_EXT: "-server -Xms128m -Xmx128m -Xmn128m" command: mqbroker -c /etc/rocketmq/broker.conf depends_on: - rmqnamesrv networks: rmq: aliases: - rmqbroker rmqconsole: image: styletang/rocketmq-console-ng container_name: rmqconsole ports: - 8080:8080 environment: JAVA_OPTS: "-Drocketmq.namesrv.addr=rmqnamesrv:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false" depends_on: - rmqnamesrv networks: rmq: aliases: - rmqconsolenetworks: rmq: name: rmq driver: bridge docker-compose安装成功后，springboot链接的时候一直报错无法正常链接，网上说系统物理内存需要空闲20G，因为安装了rmqconsole可能导致内存不够，故单独安装了RrocketMQ。 SpringBoot简单集成配置文件1234server.port=8081apache.rocketmq.consumer.PushConsumer=PushConsumerapache.rocketmq.producer.producerGroup=Producerapache.rocketmq.namesrvAddr=localhost:9876 pom.xml依赖1234567891011121314151617&lt;!-- https://mvnrepository.com/artifact/org.apache.rocketmq/rocketmq-client --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt; &lt;version&gt;4.1.0-incubating&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.rocketmq/rocketmq-common --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-common&lt;/artifactId&gt; &lt;version&gt;4.1.0-incubating&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.13&lt;/version&gt; &lt;/dependency&gt; 生产者服务12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.example.roketmq.server;import org.apache.rocketmq.client.producer.DefaultMQProducer;import org.apache.rocketmq.client.producer.SendResult;import org.apache.rocketmq.common.message.Message;import org.apache.rocketmq.remoting.common.RemotingHelper;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Service;import javax.annotation.PostConstruct;import javax.annotation.PreDestroy;/** * @ClassName ProducerService * @Author gaoqisen * @Date 2019-10-31 * @Version 1.0 */@Servicepublic class ProducerService &#123; @Value("$&#123;apache.rocketmq.producer.producerGroup&#125;") private String producerGroup; @Value("$&#123;apache.rocketmq.namesrvAddr&#125;") private String namesrvAddr; private DefaultMQProducer producer; @PostConstruct public void initProducer() &#123; producer = new DefaultMQProducer(producerGroup); producer.setNamesrvAddr(namesrvAddr); producer.setRetryTimesWhenSendFailed(3); try &#123; producer.start(); System.out.println("[Producer 已启动]"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public String send(String topic, String tags, String msg) &#123; SendResult result = null; try &#123; Message message = new Message(topic, tags, msg.getBytes(RemotingHelper.DEFAULT_CHARSET)); result = producer.send(message); System.out.println("[生产者：] msgID(" + result.getMsgId() + ") " + result.getSendStatus()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return "&#123;\"MsgId\":\"" + result.getMsgId() + "\"&#125;"; &#125; @PreDestroy public void shutDownProducer() &#123; if (producer != null) &#123; producer.shutdown(); &#125; &#125;&#125; 消费者1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.example.roketmq.server;import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;import org.apache.rocketmq.common.consumer.ConsumeFromWhere;import org.apache.rocketmq.common.message.MessageExt;import org.apache.rocketmq.remoting.common.RemotingHelper;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Component;import javax.annotation.PostConstruct;/** * @ClassName ConsumerService * @Author gaoqisen * @Date 2019-10-31 * @Version 1.0 */@Componentpublic class ConsumerService &#123; @Value("$&#123;apache.rocketmq.consumer.PushConsumer&#125;") private String consumerGroup; @Value("$&#123;apache.rocketmq.namesrvAddr&#125;") private String namesrvAddr; @PostConstruct public void defaultMQPushConsumer() &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(consumerGroup); consumer.setNamesrvAddr(namesrvAddr); try &#123; consumer.subscribe("test1", "push"); // 如果是第一次启动，从队列头部开始消费 // 如果不是第一次启动，从上次消费的位置继续消费 consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.registerMessageListener((MessageListenerConcurrently) (list, context) -&gt; &#123; try &#123; for (MessageExt messageExt : list) &#123; String messageBody = new String(messageExt.getBody(), RemotingHelper.DEFAULT_CHARSET); System.out.println("[消费者] msgID(" + messageExt.getMsgId() + ") msgBody : " + messageBody); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); return ConsumeConcurrentlyStatus.RECONSUME_LATER; &#125; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;); consumer.start(); System.out.println("[Consumer 已启动]"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 测试Controller12345678910111213141516171819202122package com.example.roketmq.server;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @ClassName TestController * @Author gaoqisen * @Date 2019-10-31 * @Version 1.0 */@RestControllerpublic class TestController &#123; @Autowired private ProducerService producer; @RequestMapping("/push") public String pushMsg(String msg) &#123; return producer.send("test1", "push", msg); &#125;&#125; 如果报错No route info of this topic 更改启动方式为：sh bin/mqbroker -n localhost:9876 autoCreateTopicEnable=true &amp; jar包的版本要对应上，如rocketmq的版本为4.1.0-incubating，那么jar包的版本也应该为4.1.0-incubating（按照这种方法以解决）。]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Annotation学习]]></title>
    <url>%2Fjava%2Fannotation.html</url>
    <content type="text"><![CDATA[一、基本概述 Annontation是Java5开始引入的新特征。中文名称一般叫注解。它提供了一种安全的类似注释的机制，用来将任何的信息或元数据（metadata）与程序元素（类、方法、成员变量等）进行关联测试。 更通俗的意思是为程序的元素（类、方法、成员变量）加上更直观更明了的说明，这些说明信息是与程序的业务逻辑无关，并且是供指定的工具或框架使用的。 Annontation像一种修饰符一样，应用于包、类型、构造方法、方法、成员变量、参数及本地变量的声明语句中。 二、原理 Annotation其实是一种接口。通过Java的反射机制相关的API来访问Annotation信息。相关类（框架或工具中的类即使用注解的类）根据这些信息来决定如何使用该程序元素或改变它们的行为。 Annoation和程序代码的隔离性：Annotation是不会影响程序代码的执行，无论Annotation怎么变化，代码都始终如一地执行。 三、元注解3.1 @Target：注解的作用目标 ElementType.TYPE：允许被修饰的注解作用在类、接口和枚举上 ElementType.FIELD：允许作用在属性字段上 ElementType.METHOD：允许作用在方法上 ElementType.PARAMETER：允许作用在方法参数上 ElementType.CONSTRUCTOR：允许作用在构造器上 ElementType.LOCAL_VARIABLE：允许作用在本地局部变量上 ElementType.ANNOTATION_TYPE：允许作用在注解上 ElementType.PACKAGE：允许作用在包上 3.2 @Retention：注解的生命周期 RetentionPolicy.SOURCE：当前注解编译期可见，不会写入 class 文件 RetentionPolicy.CLASS：类加载阶段丢弃，会写入 class 文件 RetentionPolicy.RUNTIME：永久保存，可以反射获取 3.3 @Documented：注解是否应当被包含在 JavaDoc 文档中3.4 @Inherited：是否允许子类继承该注解四、实践一4.1 自定义Log注解12345678910111213141516import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;/** * 自定义日志注解 * @author gaoqisen * */@Documented@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface Log &#123; String value() default "";&#125; 4.2 用Aop实现注解逻辑123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107import java.lang.reflect.Method;import java.util.regex.Matcher;import java.util.regex.Pattern;import javax.servlet.http.HttpServletRequest;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.After;import org.aspectj.lang.annotation.AfterReturning;import org.aspectj.lang.annotation.AfterThrowing;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;import org.aspectj.lang.reflect.MethodSignature;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.core.LocalVariableTableParameterNameDiscoverer;import org.springframework.stereotype.Component;import org.springframework.web.context.request.RequestContextHolder;import org.springframework.web.context.request.ServletRequestAttributes;@Aspect@Componentpublic class LogAspect &#123; @Autowired private CommonService commonServcie; /** * 切入点 */ @Pointcut("@annotation(cn.annotation.Log)") public void pointcut() &#123; &#125; @Around("pointcut()") public Object around(ProceedingJoinPoint point) &#123; Object result = null; long beginTime = System.currentTimeMillis(); try &#123; // 执行方法 result = point.proceed(); &#125; catch (Throwable e) &#123; e.printStackTrace(); throw new AppException(e.getMessage()); &#125; // 执行时长(毫秒) long time = System.currentTimeMillis() - beginTime; // 保存日志 saveLog(point, time); return result; &#125; private void saveLog(ProceedingJoinPoint joinPoint, long time) &#123; MethodSignature signature = (MethodSignature) joinPoint.getSignature(); Method method = signature.getMethod(); SysLog sysLog = new SysLog(); Log logAnnotation = method.getAnnotation(Log.class); if (logAnnotation != null) &#123; // 注解上的描述 sysLog.setOperation(logAnnotation.value()); &#125; // 请求的方法名 String className = joinPoint.getTarget().getClass().getName(); String methodName = signature.getName(); sysLog.setMethods(className + "." + methodName + "方法"); // 请求的方法参数值 Object[] args = joinPoint.getArgs(); // 请求的方法参数名称 LocalVariableTableParameterNameDiscoverer u = new LocalVariableTableParameterNameDiscoverer(); String[] paramNames = u.getParameterNames(method); if (args != null &amp;&amp; paramNames != null) &#123; String params = ""; for (int i = 0; i &lt; args.length; i++) &#123; params += " " + paramNames[i] + ": " + args[i]; &#125; sysLog.setParms(params); &#125; // 获取request HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); Object obj = request.getSession().getAttribute("user"); // 设置IP地址 String ip = RequestUtil.getIpAddress(request); sysLog.setIp(ip); sysLog.setAddress(RequestUtil.getAddressByIp(ip)); // 模拟一个用户名 if(obj != null) &#123; User user = (User) obj; sysLog.setUser_name(user.getUsername()); sysLog.setUser_id(user.getId()); &#125; else &#123; sysLog.setUser_name("未知"); &#125; sysLog.setBaseData(); sysLog.setTime((int) time); // 保存系统日志 this.commonServcie.inster("sys_log", sysLog); &#125; private String replaceBlank(String s) &#123; String result= null; if (s == null) &#123; return result; &#125; else &#123; Pattern p = Pattern.compile("\\s*|\t|\r|\n"); Matcher m = p.matcher(s); result= m.replaceAll(""); return result; &#125; &#125;&#125; 五、实践二5.1 自定义validation注解校验12345678910111213141516171819@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)@Constraint(validatedBy = LengthInvalidatorImpl.class)@Documentedpublic @interface MaxLength &#123; // 字段支持的最大长度(字符数) int maxLength() default 5; // 校验失败后返回的错误信息 String message() default "超过最大长度"; // 分组 Class&lt;?&gt;[] groups() default &#123;&#125;; // 负载 Class&lt;? extends Payload&gt;[] payload() default &#123;&#125;;&#125; 5.2 实现类1234567891011121314151617181920212223242526272829303132333435/** * 最大长度校验实现类 */public class LengthInvalidatorImpl implements ConstraintValidator&lt;MaxLength, String&gt; &#123; private MaxLength maxLength; /** * 初始化数据 * @param constraintAnnotation 注解类 */ @Override public void initialize(MaxLength constraintAnnotation) &#123; maxLength = constraintAnnotation; &#125; /** * 校验是否有效 * * @param fieldValue 字段值 * @param context 限制校验上下文 * @return 是否有效 */ @Override public boolean isValid(String fieldValue, ConstraintValidatorContext context) &#123; if (fieldValue.length() &gt; maxLength.maxLength()) &#123; context.disableDefaultConstraintViolation(); context.buildConstraintViolationWithTemplate(maxLength.message()).addConstraintViolation(); // 校验失败返回false。返回true上游收集不到错误信息。 return false; &#125; return false; &#125;&#125; 5.3 手动校验工具1234567891011121314151617181920/** * validation校验工具 */public class ValidationUtils &#123; private static Validator validation = Validation.buildDefaultValidatorFactory().getValidator(); /** * 校验实体 * @param obj 需要校验的对象 */ public static void validationEntity(Object obj) &#123; Set&lt;ConstraintViolation&lt;Object&gt;&gt; constraintViolations = validation.validate(obj); for (ConstraintViolation&lt;Object&gt; constraintViolation : constraintViolations) &#123; String message = constraintViolation.getMessage(); throw new AppException(message); &#125; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程实验程序]]></title>
    <url>%2Fstudy%2Fjava.html</url>
    <content type="text"><![CDATA[实验一目标 创建两个Thread的子类Thread_ 1、Thread 2, Thread 1类用来计算阶乘的结果，Thread 2类用来读取Thread 1中的结果并显示在窗体中， 创建一个Thread frame 类来创建窗体，在窗体上添加标签、文本域、文本框、进度条和按钮，其中，文本域显示阶乘的计算过程，文本框显示计算结果，进度条根据文本域来显示进度; 为按钮添加点击事件，使得点击按钮后，运行线程; 创建测试类testThread,测试程序。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169import javax.swing.*;import java.awt.*;import java.awt.event.ActionEvent;import java.awt.event.ActionListener;// 创建Thread的子类Thread_ 1,用来计算阶乘的结果public class Thread_1 extends Thread&#123; //存储阶乘和进度 static String stringSum=""; //存储阶乘和的字符串 static String stringResult=""; //存储阶乘结果的字符串 static int i=0; //计算阶乘 double sum=0; double method(int n)&#123; //阶乘结果 double result=1; for(int i=1;i&lt;=n;i++)&#123; result*=i; &#125; return result; &#125; @Override public void run() &#123; while(i&lt;30)&#123; //计算阶乘和 i++; sum+=method(i); stringResult=String.valueOf(sum); //将阶乘和存储到字符串中 if(i!=1)&#123; //显示阶乘和的过程：1！+2！+...+30！ stringSum=stringSum+"+"+i+"!"; &#125;else&#123; stringSum=i+"!"; &#125; try&#123; //0.5-1秒读取一次线程 Thread.sleep((int)(Math.random()*500+500)); &#125;catch(InterruptedException ex)&#123; &#125; &#125; &#125;&#125;// 创建Thread的子类Thread_ 2,用来读取Thread 1中的结果并显示在窗体中class Thread_2 extends Thread&#123; ThreadFrame tf; Thread_2(ThreadFrame tf)&#123; //初始化 this.tf=tf; &#125; @Override public void run() &#123; while(true)&#123; tf.textArea.setText(Thread_1.stringSum); //将阶乘和的过程显示到文本域中 tf.textFile.setText(Thread_1.stringResult); //将阶乘和结果显示到文本框中 tf.jpb.setValue(Thread_1.i); //在面板上的进度条中显示计算进度 try&#123; Thread.sleep(100); //0.1秒读取一次线程 &#125;catch (Exception e) &#123; &#125; &#125; &#125;&#125;// 创建一个Thread frame 类来创建窗体，在窗体上添加标签、文本域、文本框、进度条和按钮，其中，文本域显示阶乘的计算过程，文本框显示计算结果，进度条根据文本域来显示进度class ThreadFrame implements ActionListener &#123; //创建面板 JFrame jframe; //创建窗体 Panel panel; //创建面板 Label label_title; //创建标签 Label label_1; Label label_2; Label label_3; TextField textFile; //创建文本框 TextArea textArea; //创建文本域 Button btn; //创建按钮 JProgressBar jpb; //创建进度条 ThreadFrame()&#123; //创建窗体 jframe=new JFrame("线程"); //设置窗体名称 jframe.setBounds(600, 100, 400, 400); //设置大小 jframe.setVisible(true); //设置课件 jframe.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); //结束进程 //创建面板 panel=new Panel(); panel.setBackground(Color.white); //设置背景颜色 panel.setLayout(null); //取消默认布局 jframe.add(panel); //创建标签 label_title=new Label("多线程实验"); label_1=new Label("计算线程："); label_2=new Label("计算进度："); label_3=new Label("计算读取："); label_title.setBounds(jframe.size().width/2-50, 10, 100, 50); label_1.setBounds(30, 100, 60, 20); label_2.setBounds(30, 160, 60, 20); label_3.setBounds(30, 220, 60, 20); label_title.setFont(new Font("宋体", 1, 16));//设置字体 panel.add(label_title); panel.add(label_1); panel.add(label_2); panel.add(label_3); //创建文本域 textArea=new TextArea(); textArea.setBounds(100, 80, 200, 60); textArea.setEditable(false);//不可编辑 panel.add(textArea); //创建单行文本框 textFile=new TextField("0"); textFile.setBounds(textArea.getX(), 220, textArea.size().width, 20); textFile.setEditable(false);//不可编辑 panel.add(textFile); //创建按钮 btn=new Button("开始计算"); btn.setBounds(jframe.size().width/2-35, 270, 70, 30); panel.add(btn); btn.addActionListener(this);//添加监听器 //创建进度条 jpb=new JProgressBar(); jpb.setBounds(textArea.getX(), textArea.getY()+textArea.size().height+10, textArea.size().width, 40); jpb.setMaximum(30);//设置最大值 panel.add(jpb); &#125; // 为按钮添加点击事件，使得点击按钮后，运行线程 @Override public void actionPerformed(ActionEvent e) &#123; //按钮点击事件 //调用计算线程 Thread_1 ct=new Thread_1(); Thread tc=new Thread(ct); //调用读取线程 Thread_2 rt=new Thread_2(this); Thread tr=new Thread(rt); //开始线程 tc.start(); tr.start(); &#125;&#125;// 创建测试类testThread,测试程序。class TestThread extends Thread&#123; public static void main(String[] args) &#123; ThreadFrame tf=new ThreadFrame(); &#125;&#125; 实验二目标 创建两个实现Runnable接口的类MyThread1、MyThread2,在里面重写run方法: 创建MyThread1的子类ComputeThread和MyThread2的子类ReadThread,其中，ComputeThread类用来计算阶乘的结果, ReadThread类用来读取Compute Thread中的结果并显示在窗体中 创建一个MyFrame类来创建窗体，在窗体上添加标签、文本域、文本框、进度条和按钮，其中，文本域显示阶乘的计算过程，文本框显示计算结果，进度条根据文本域来显示进度; 为按钮添加点击事件，使得点击按钮后，运行线程， 创建测试类TestThread,测试程序。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177import javax.swing.*;import java.awt.*;import java.awt.event.ActionEvent;import java.awt.event.ActionListener;// ComputeThread类用来计算阶乘的结果public class MyThread1 implements Runnable&#123; @Override public void run() &#123; &#125;&#125;class ComputeThread extends MyThread1&#123; //存储阶乘和进度 static String stringSum=""; //存储阶乘和的字符串 static String stringResult=""; //存储阶乘结果的字符串 static int i=0; //计算阶乘 double sum=0; double method(int n)&#123; //阶乘结果 double result=1; for(int i=1;i&lt;=n;i++)&#123; result*=i; &#125; return result; &#125; public void run() &#123; while(i&lt;30)&#123; //计算阶乘和 i++; sum+=method(i); stringResult=String.valueOf(sum); //将阶乘和存储到字符串中 if(i!=1)&#123; //显示阶乘和的过程：1！+2！+...+30！ stringSum=stringSum+"+"+i+"!"; &#125;else&#123; stringSum=i+"!"; &#125; try&#123; //0.5-1秒读取一次线程 Thread.sleep((int)(Math.random()*500+500)); &#125;catch(InterruptedException ex)&#123; &#125; &#125; &#125;&#125;class MyThread2 implements Runnable&#123; @Override public void run() &#123; &#125;&#125;class ReadThread extends MyThread2&#123; RunnableFrame tf; ReadThread(RunnableFrame tf)&#123; //初始化 this.tf=tf; &#125; public void run() &#123; while(true)&#123; tf.textArea.setText(ComputeThread.stringSum); //将阶乘和的过程显示到文本域中 tf.textFile.setText(ComputeThread.stringResult); //将阶乘和结果显示到文本框中 tf.jpb.setValue(ComputeThread.i); //在面板上的进度条中显示计算进度 try&#123; Thread.sleep(100); //0.1秒读取一次线程 &#125;catch (Exception e) &#123; &#125; &#125; &#125;&#125;// 创建一个Thread frame 类来创建窗体，在窗体上添加标签、文本域、文本框、进度条和按钮，其中，文本域显示阶乘的计算过程，文本框显示计算结果，进度条根据文本域来显示进度class RunnableFrame implements ActionListener &#123; //创建面板 JFrame jframe; //创建窗体 Panel panel; //创建面板 Label label_title; //创建标签 Label label_1; Label label_2; Label label_3; TextField textFile; //创建文本框 TextArea textArea; //创建文本域 Button btn; //创建按钮 JProgressBar jpb; //创建进度条 RunnableFrame()&#123; //创建窗体 jframe=new JFrame("线程"); //设置窗体名称 jframe.setBounds(600, 100, 400, 400); //设置大小 jframe.setVisible(true); //设置课件 jframe.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); //结束进程 //创建面板 panel=new Panel(); panel.setBackground(Color.white); //设置背景颜色 panel.setLayout(null); //取消默认布局 jframe.add(panel); //创建标签 label_title=new Label("多线程实验"); label_1=new Label("计算线程："); label_2=new Label("计算进度："); label_3=new Label("计算读取："); label_title.setBounds(jframe.size().width/2-50, 10, 100, 50); label_1.setBounds(30, 100, 60, 20); label_2.setBounds(30, 160, 60, 20); label_3.setBounds(30, 220, 60, 20); label_title.setFont(new Font("宋体", 1, 16));//设置字体 panel.add(label_title); panel.add(label_1); panel.add(label_2); panel.add(label_3); //创建文本域 textArea=new TextArea(); textArea.setBounds(100, 80, 200, 60); textArea.setEditable(false);//不可编辑 panel.add(textArea); //创建单行文本框 textFile=new TextField("0"); textFile.setBounds(textArea.getX(), 220, textArea.size().width, 20); textFile.setEditable(false);//不可编辑 panel.add(textFile); //创建按钮 btn=new Button("开始计算"); btn.setBounds(jframe.size().width/2-35, 270, 70, 30); panel.add(btn); btn.addActionListener(this);//添加监听器 //创建进度条 jpb=new JProgressBar(); jpb.setBounds(textArea.getX(), textArea.getY()+textArea.size().height+10, textArea.size().width, 40); jpb.setMaximum(30);//设置最大值 panel.add(jpb); &#125; // 为按钮添加点击事件，使得点击按钮后，运行线程 @Override public void actionPerformed(ActionEvent e) &#123; //按钮点击事件 //调用计算线程 ComputeThread ct=new ComputeThread(); Thread tc=new Thread(ct); //调用读取线程 ReadThread rt=new ReadThread(this); Thread tr=new Thread(rt); //开始线程 tc.start(); tr.start(); &#125;&#125;// 创建测试类testThread,测试程序。class TestRunnable&#123; public static void main(String[] args) &#123; RunnableFrame tf=new RunnableFrame(); &#125;&#125;]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[枚举学习]]></title>
    <url>%2Fjava%2Fenum.html</url>
    <content type="text"><![CDATA[原理 枚举本质上是通过普通的类来实现的，只是编译器为我们进行了处理。每个枚举类型都继承自java.lang.Enum， 并自动添加了values和valueOf方法。而每个枚举常量是一个静态常量字段，使用内部类实现，该内部类继承了枚举类。所有枚举常量都通过静态代码块来进行初始化，即在类加载期间就初始化。另外通过把clone、readObject、writeObject这三个方法定义为final的，同时实现是抛出相应的异常。这样保证了每个枚举类型及枚举常量都是不可变的。可以利用枚举的这两个特性来实现线程安全的单例。（来源：https://blog.csdn.net/u010142437/article/details/80498020） 作用 枚举可以代替常量，枚举提供了比常量更多的方法。 使用枚举，能让我们的代码可读性更强。 注意事项 枚举类名建议带上Enum后缀 枚举成员名称需要全部大写 单词间用下划线分割 阿里规约【强制】：所有的枚举类型字段必须要有注释，说明每个数据项的用途。 枚举类型对象之间的值比较，是可以使用==，直接来比较值，是否相等，不是必须使用equals方法 特性 它不能有public的构造函数，这样做可以保证客户代码没有办法新建一个enum的实例。 所有枚举值都是public , static , final的。注意这一点只是针对于枚举值，我们可以和在普通类里面定义 变量一样定义其它任何类型的非枚举变量，这些变量可以用任何你想用的修饰符。 Enum默认实现了java.lang.Comparable接口。 Enum覆载了了toString方法，因此我们如果调用Color.Blue.toString()默认返回字符串”Blue”. Enum提供了一个valueOf方法，这个方法和toString方法是相对应的。调用valueOf(“Blue”)将返回Color.Blue. 因此我们在自己重写toString方法的时候就要注意到这一点，一把来说应该相对应地重写valueOf方法。 Enum还提供了values方法，这个方法使你能够方便的遍历所有的枚举值。 Enum还有一个oridinal的方法，这个方法返回枚举值在枚举类种的顺序，这个顺序根据枚举值声明的顺序而定，这里Color.Red.ordinal()返回0。 常用方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.test.utils;/** * @ClassName EnumExample */public enum EnumExample &#123; // 红色 RED(1,&quot;红色&quot;), // 蓝色 BLUE(2, &quot;蓝色&quot;), // 黑色 BLACK(3, &quot;黑色&quot;); private int index; private String name; // 添加普通方法 public static String getName(int index)&#123; for(EnumExample e : EnumExample.values()) &#123; if(e.index == index) &#123; return e.name; &#125; &#125; return null; &#125; EnumExample(int i, String name) &#123; this.index = i; this.name = name; &#125; public int getIndex() &#123; return index; &#125; public void setIndex(int index) &#123; this.index = index; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public static void main(String[] args) &#123; System.out.println(EnumExample.getName(2)); // 蓝色 EnumExample enumExample = EnumExample.BLACK; System.out.println(enumExample.index + &quot;:&quot; + enumExample.name); // 3:黑色 for(EnumExample e : EnumExample.values()) &#123; // 遍历枚举 System.out.println(e.index + &quot;:&quot; + e.name); &#125; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>enum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软件工程]]></title>
    <url>%2Fstudy%2Fsoftware.html</url>
    <content type="text"><![CDATA[第一章 绪论软件危机随着计算机的广泛应用，软件生产率、软件质量远远满足不了社会发展的需求，成为社会、经济发展的制约因素，人们把这种现象称为“软件危机” 软件工程其目的是倡导以工程的原理、原则和方法进行软件开发，以期解决“软件危机”。 第二章 软件需求与软件需求规约需求与需求获取需求定义 一个需求是一个‘要予构造’的陈述，描述了一个待开发产品/系统应该具有的功能、性能和其他性质。 单一一个需求的5个基本性质：必要的、误歧义的、可测的、可跟踪的、可测量的。 需求分类 功能需求 非功能需求：性能需求、外部接口需求（用户接口、硬件接口、软件接口、通信接口、内存约束、运行、地点需求）、设计约束（法规政策、硬件限制、与其他应用的接口、并发操作、审计功能、控制功能、高级语言需求、握手协议应用的关键程度、安全和保密）、质量属性 需求发现技术自悟、交谈、观察、小组会、提炼 需求规约定义需求规约是一个软件／产品／系统所有需求称述的正式文档，它表达了一个软件产品／系统的概念模型。 满足的4个基本性质 重要性和稳定性程度。 可修改的 完整的 一致的 需求规约格式1234567891011121314151. 引言 1.1 目的 1.2 范围 1.3定义，缩略语 1.4参考文献 1.5 概述2. 总体描述 2.1 产品概述 2.2 产品功能 2.3 用户特性 2.4 约束 2.5 假设和依赖3. 特定需求附录索引 需求规约的表达 形式化的需求规约（自然语言） 半形式化的需求规约（一半自然语言，一半正式语言） 形式化规约（基于良好的数学概念的符号体系编织的） 需求规约的作用 是软件开发组织和用户之间一份事实上的技术合同书。 对于项目的其余大多数工作，需求规约是一个管理控制点。 对于产品／系统的设计，是一个正式的、受控的起始点 是创建产品验收测试计划和用户指南的基础。 需求规约回答交付给客户的产品／系统是什么（关注产品需求）。项目需求回答开发组要做的是什么（关注项目工作与管理）。 第三章 结构化方法结构化需求分析三大挑战 问题空间的理解 人与人之间的通信 需求的变化性 好的需求技术的基本特征 提供方便通信的机制 鼓励需求分析人员使用问题空间的术语思考问题，编写文档 提供定义系统边界的方法 提供支持抽象的基本机制 为需求分析人员提供多种可供选择的方案 提供特定的技术，适应需求的变化 基本术语数据源、数据潭、数据流、加工、数据存储 数据流图（DFD）为了建立系统功能模型，为此结构化分析方法给出了一种表达功能模型的工具 建模过程 建立系统环境图，确定系统语境（顶层数据流图） 自动向下，逐步求精（数据流的分派） 定义数据字典（顺序结构、选择结构、重复结构） 描述加工（结构化自然语言、判定表、判定树） 需求验证需求中发现的错误类型 类型 百分比 类型 百分比 不正确的事实 40 歧义性 5 遗漏 31 错放 2 不一致 13 其他 9 发现错误的方法 方法 发现错误的百分比 方法 发现错误的百分比 审查 65 集成 5 单元测试 10 其他 10 评估 10 结构化设计目标建立系统的模块结构，即系统实现所需要的软件模块—-系统中可标识的软件成分，以及这些模块之间的调用关系。 模块： 是指软件中具有特定标识的独立成分； 模块调用：指模块之间的一种使用关系 表达软件体系结构的工具 模块结构图：是一种描述软件宏观结构的图形化工具。 层次图：主要描绘软件的层次结构 HIPO图：层次图＋输入／处理／输出 总体设计步骤 变换型数据流图： 具有明显的输入部分和变换部分之间的界面、变换部分和输出部分之间节目的数据流图 事务型数据流图：数据达到一个加工T ,改加工T根据输入数据的值，在其后的若干动作序列（一个事物）中选出一个执行。 三个阶段 初始设计 精华设计 复审阶段 模块化及启发式规则模块化 是执行一个特殊任务的一个过程以及相关的数据结构 把一个待开发的软件分解成若干简单的具有高内聚低耦合的模块 耦合：指不同模块之间相互依赖程度的度量（内容耦合、标记耦合、控制耦合、公共耦合、数据耦合） 内聚：指一个模块内部各成分之间相互关联程度的度量（偶然内聚、逻辑内聚、时间内聚、过程内聚、通信内聚、顺序内聚、功能内聚） 启发式规则 改进软件结构，提高模块独立性。 力求模块规模适中 力求深度、宽度、扇出和扇入适中。 尽力使模块的作用域在其控制域之内。 尽力江都模块接口的复杂度 力求模块功能可以预测 详细设计具体描述模块结构图中的每一个模块，即给出实现模块功能的实施机制，包括一组例程和数据结构。目标是将总体设计阶段产生的系统高层结构映射为以这些术语所表达的底层结构，也是系统的最终结构。 三种基本结构控制：顺序、选择、循环。 详细设计工具 程序流程图（程序框图）： 历史最悠久、使用最广泛的软件设计工具。 盒图（N-S图）：支持自顶向下逐步求精的详细设计 PAD图：用二维树形结构图表示程序的控制流。 类程序设计语言PDL（伪码）：借用某种结构化程序设计语言的关键字作为语法框架，用于定义控制结构和数据结构。 概要设计规约的主要内容 系统环境 软件模块的结构 模块描述 文件结构和全局数据文件的逻辑结构 测试需求 详细设计规约增加了 ：1.各处理过程的算法。2.算法所涉及的全部数据结构的描述。 第四章 面向对象方法－－UML 8个术语：类与对象、接口、协作、用况、主动类、构件、制品、节点。]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>软件工程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven学习记录]]></title>
    <url>%2Fjava%2Fmaven.html</url>
    <content type="text"><![CDATA[mvn命令行新建spingboot项目 命令行创建 12345mvn archetype:generate -DinteractiveMode=false -DgroupId=com.gqs -DartifactId=springboot -Dversion=1.0.0-SNAPSHOT-DgroupId //包名-DartifactId //项目名-DarchetypeArtifactId //类型maven-archetype-quickstart,创建一个Java Project,maven-archetype-webapp,创建一个Web Project-DinteractiveMode //是否使用交互模式,如果为false,非交互式的命令后直接创建,否则会有控制台提示输入操作 idea导入项目 常用目录结构 1234567891011121314151617181920212223│── src│ └── main│ ├── java│ │ └── com│ │ └── gqs│ │ └── dir│ │ ├── config // 配置│ │ ├── constant // 常量│ │ ├── controller // 控制层│ │ ├── exception // 异常处理│ │ ├── mapper // 数据层│ │ ├── pojo // 实体类│ │ ├── service // 服务层│ │ └── utils // 工具类│ ├── resources│ │ ├── application.yml│ │ ├── image│ │ ├── lib // 第三方jar│ │ ├── mapper // mapper.xml文件│ │ ├── static // 静态文件│ │ └── templates // html文件│ └── test│── pom.xml pom.xml配置 12345678910111213141516171819202122232425262728293031323334 // 对于SpingBoot测试Junit至少是4.1-4.2以上的版本,所以把版本号删除默认的就行, 可以直接替换以下配置 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.abc.test&lt;/groupId&gt; &lt;artifactId&gt;test&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;test&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; main配置 12345678// 添加@SpringBootApplication注释和pringApplication.run(App.class); @SpringBootApplication public class App &#123; public static void main( String[] args )&#123; SpringApplication.run(App.class, args); System.out.println( &quot;Hello World!&quot; ); &#125; &#125; 创建controller/Test.java 123456789 // 必须要写在App启动类一个包下才能够扫描到@RestController // @RestController注解相当于@ResponseBody ＋ @Controller合在一起的作用。@RequestMapping(&quot;/app&quot;)public class Test &#123; @GetMapping(&quot;start&quot;) public String test() &#123; return &quot;ok&quot;; &#125;&#125; 在main文件夹下面创建配置文件的目录resources/application.yml 123// 更改端口号server: port: 8889 启动服务成功后访问链接http://localhost:8889/app/start， 返回OK表示成功 脚手架创建的项目也可以自己手动创建目录 maven常用命令123456789101112131415161718192021222324252627282930313233mvn release:prepare // 准备发布mvn release:prepare -Dusername=myuser -Dpassword=mypassword // 准备命令mvn release:preform // 发布到nexusmvn clean package -D maven.test.skip=true 打包命令mvn -v 显示版本 mvn help:describe -Dplugin=help 使用 help 插件的 describe 目标来输出 Maven Help 插件的信息。 mvn help:describe -Dplugin=help -Dfull 使用Help 插件输出完整的带有参数的目标列 mvn help:describe -Dplugin=compiler -Dmojo=compile -Dfull 获取单个目标的信息,设置 mojo 参数和 plugin 参数。此命令列出了Compiler 插件的compile 目标的所有信息 mvn help:describe -Dplugin=exec -Dfull 列出所有 Maven Exec 插件可用的目标 mvn help:effective-pom 看这个“有效的 (effective)”POM，它暴露了 Maven的默认设置 mvn archetype:create -DgroupId=org.sonatype.mavenbook.ch03 -DartifactId=simple -DpackageName=org.sonatype.mavenbook 创建Maven的普通java项目，在命令行使用Maven Archetype 插件 mvn exec:java -Dexec.mainClass=org.sonatype.mavenbook.weather.Main Exec 插件让我们能够在不往 classpath 载入适当的依赖的情况下，运行这个程序 mvn dependency:resolve 打印出已解决依赖的列表 mvn dependency:sources 下载源码mvn dependency:tree 打印整个依赖树 mvn install -X 想要查看完整的依赖踪迹，包含那些因为冲突或者其它原因而被拒绝引入的构件，打开 Maven 的调试标记运行 mvn install -Dmaven.test.skip=true 给任何目标添加maven.test.skip 属性就能跳过测试 mvn install assembly:assembly 构建装配Maven Assembly 插件是一个用来创建你应用程序特有分发包的插件 mvn jetty:run 调用 Jetty 插件的 Run 目标在 Jetty Servlet 容器中启动 web 应用 mvn compile 编译你的项目 mvn test-compile 编译测试代码mvn test 运行测试mvn package 打包，根据pom.xml打成war或jarmvn -Dtest package 打包但不测试mvn clean 清除产生的项目mvn idea:idea 生成idea项目mvn eclipse:eclipse 生成eclipse项目mvn clean install 删除再编译 mvn hibernate3:hbm2ddl 使用 Hibernate3 插件构造数据库 maven 打包warpom.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.abc.test&lt;/groupId&gt; &lt;artifactId&gt;test&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;test&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; main12345678910111213@ServletComponentScan@SpringBootApplicationpublic class App extends SpringBootServletInitializer &#123; public static void main(String[] args) &#123; System.out.println(&quot;Hello World!&quot;); SpringApplication.run(App.class, args); &#125; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return builder.sources(App.class); &#125;&#125; maven 打包运行jar12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.17.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.inspur.serverMonitoring&lt;/groupId&gt; &lt;artifactId&gt;ServerMonitoring&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;ServerMonitoring&lt;/name&gt; &lt;description&gt;a server monitoring application&lt;/description&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;properties&gt; &lt;java.version&gt;1.7&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;monitor-1.0&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources/lib&lt;/directory&gt; &lt;targetPath&gt;BOOT-INF/lib&lt;/targetPath&gt; &lt;includes&gt; &lt;include&gt;**/*.jar&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;targetPath&gt;BOOT-INF/classes&lt;/targetPath&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt; maven打包自己的工具jar123456789101112131415161718192021222324252627282930313233343536&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.test&lt;/groupId&gt; &lt;artifactId&gt;first&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;build&gt; &lt;finalName&gt;firstmaven1&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;appendAssemblyId&gt;true&lt;/appendAssemblyId&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;archive&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;assembly&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[curl命令学习]]></title>
    <url>%2Flinux%2Fcurl.html</url>
    <content type="text"><![CDATA[作用在Linux中curl是一个利用URL规则在命令行下工作的文件传输工具，可以说是一款很强大的http命令行工具。它支持文件的上传和下载，是综合传输工具，但按传统，习惯称url为下载工具。 常用参数12345678910111213141516-A/--user-agent &lt;string&gt; 设置用户代理发送给服务器-b/--cookie &lt;name=string/file&gt; cookie字符串或文件读取位置-c/--cookie-jar &lt;file&gt; 操作结束后把cookie写入到这个文件中-C/--continue-at &lt;offset&gt; 断点续转-D/--dump-header &lt;file&gt; 把header信息写入到该文件中-e/--referer 来源网址-f/--fail 连接失败时不显示http错误-o/--output 把输出写到该文件中-O/--remote-name 把输出写到该文件中，保留远程文件的文件名-r/--range &lt;range&gt; 检索来自HTTP/1.1或FTP服务器字节范围-s/--silent 静音模式。不输出任何东西-T/--upload-file &lt;file&gt; 上传文件-u/--user &lt;user[:password]&gt; 设置服务器的用户和密码-w/--write-out [format] 什么输出完成后-x/--proxy &lt;host[:port]&gt; 在给定的端口上使用HTTP代理-#/--progress-bar 进度条显示当前的传送状态 例子基本get、post请求123curl www.baidu.com // get请求curl -X POST --data &quot;name=123&amp;age=20&quot; www.google.com // post请求curl -X POST -D &quot;name=123&amp;age=20&quot; www.google.com // post请求 代理请求12curl --proxy 192.168.0.1:8080 www.google.com // 代理get请求，192.168.0.1:8080为代理IPcurl --data &quot;name=123&amp;age=20&quot; --proxy 192.168.0.1:8080 www.google.com // 代理post请求，192.168.0.1:8080为代理IP 带cookie请求1234curl -c cookies www.google.com // get请求取得cookie,保存到cookiescurl -b cookies -c cookies -d &apos;name=123&amp;age=20&apos; &apos;www.google.com&apos; // 带cookie的post请求curl -c cookies --proxy 192.168.0.1:8080 www.google.com // get代理请求取得cookie,保存到cookiescurl -b cookies -c cookies --proxy 192.168.0.1:8080 -d &apos;name=123&amp;age=20&apos; &apos;www.google.com&apos; // 带cookie的代理post请求 其他参数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192-a/--append 上传文件时，附加到目标文件--anyauth 可以使用“任何”身份验证方法--basic 使用HTTP基本验证-B/--use-ascii 使用ASCII文本传输-d/--data &lt;data&gt; HTTP POST方式传送数据--data-ascii &lt;data&gt; 以ascii的方式post数据--data-binary &lt;data&gt; 以二进制的方式post数据--negotiate 使用HTTP身份验证--digest 使用数字身份验证--disable-eprt 禁止使用EPRT或LPRT--disable-epsv 禁止使用EPSV--egd-file &lt;file&gt; 为随机数据(SSL)设置EGD socket路径--tcp-nodelay 使用TCP_NODELAY选项-E/--cert &lt;cert[:passwd]&gt; 客户端证书文件和密码 (SSL)--cert-type &lt;type&gt; 证书文件类型 (DER/PEM/ENG) (SSL)--key &lt;key&gt; 私钥文件名 (SSL)--key-type &lt;type&gt; 私钥文件类型 (DER/PEM/ENG) (SSL)--pass &lt;pass&gt; 私钥密码 (SSL)--engine &lt;eng&gt; 加密引擎使用 (SSL). &quot;--engine list&quot; for list--cacert &lt;file&gt; CA证书 (SSL)--capath &lt;directory&gt; CA目 (made using c_rehash) to verify peer against (SSL)--ciphers &lt;list&gt; SSL密码--compressed 要求返回是压缩的形势 (using deflate or gzip)--connect-timeout &lt;seconds&gt; 设置最大请求时间--create-dirs 建立本地目录的目录层次结构--crlf 上传是把LF转变成CRLF--ftp-create-dirs 如果远程目录不存在，创建远程目录--ftp-method [multicwd/nocwd/singlecwd] 控制CWD的使用--ftp-pasv 使用 PASV/EPSV 代替端口--ftp-skip-pasv-ip 使用PASV的时候,忽略该IP地址--ftp-ssl 尝试用 SSL/TLS 来进行ftp数据传输--ftp-ssl-reqd 要求用 SSL/TLS 来进行ftp数据传输-F/--form &lt;name=content&gt; 模拟http表单提交数据-form-string &lt;name=string&gt; 模拟http表单提交数据-g/--globoff 禁用网址序列和范围使用&#123;&#125;和[]-G/--get 以get的方式来发送数据-h/--help 帮助-H/--header &lt;line&gt; 自定义头信息传递给服务器--ignore-content-length 忽略的HTTP头信息的长度-i/--include 输出时包括protocol头信息-I/--head 只显示文档信息-j/--junk-session-cookies 读取文件时忽略session cookie--interface &lt;interface&gt; 使用指定网络接口/地址--krb4 &lt;level&gt; 使用指定安全级别的krb4-k/--insecure 允许不使用证书到SSL站点-K/--config 指定的配置文件读取-l/--list-only 列出ftp目录下的文件名称--limit-rate &lt;rate&gt; 设置传输速度--local-port&lt;NUM&gt; 强制使用本地端口号-m/--max-time &lt;seconds&gt; 设置最大传输时间--max-redirs &lt;num&gt; 设置最大读取的目录数--max-filesize &lt;bytes&gt; 设置最大下载的文件总量-M/--manual 显示全手动-n/--netrc 从netrc文件中读取用户名和密码--netrc-optional 使用 .netrc 或者 URL来覆盖-n--ntlm 使用 HTTP NTLM 身份验证-N/--no-buffer 禁用缓冲输出-p/--proxytunnel 使用HTTP代理--proxy-anyauth 选择任一代理身份验证方法--proxy-basic 在代理上使用基本身份验证--proxy-digest 在代理上使用数字身份验证--proxy-ntlm 在代理上使用ntlm身份验证-P/--ftp-port &lt;address&gt; 使用端口地址，而不是使用PASV-Q/--quote &lt;cmd&gt; 文件传输前，发送命令到服务器--range-file 读取（SSL）的随机文件-R/--remote-time 在本地生成文件时，保留远程文件时间--retry &lt;num&gt; 传输出现问题时，重试的次数--retry-delay &lt;seconds&gt; 传输出现问题时，设置重试间隔时间--retry-max-time &lt;seconds&gt; 传输出现问题时，设置最大重试时间-S/--show-error 显示错误--socks4 &lt;host[:port]&gt; 用socks4代理给定主机和端口--socks5 &lt;host[:port]&gt; 用socks5代理给定主机和端口-t/--telnet-option &lt;OPT=val&gt; Telnet选项设置--trace &lt;file&gt; 对指定文件进行debug--trace-ascii &lt;file&gt; Like --跟踪但没有hex输出--trace-time 跟踪/详细输出时，添加时间戳--url &lt;URL&gt; Spet URL to work with-U/--proxy-user &lt;user[:password]&gt; 设置代理用户名和密码-V/--version 显示版本信息-X/--request &lt;command&gt; 指定什么命令-y/--speed-time 放弃限速所要的时间。默认为30-Y/--speed-limit 停止传输速度的限制，速度时间&apos;秒-z/--time-cond 传送时间设置-0/--http1.0 使用HTTP 1.0-1/--tlsv1 使用TLSv1（SSL）-2/--sslv2 使用SSLv2的（SSL）-3/--sslv3 使用的SSLv3（SSL）--3p-quote like -Q for the source URL for 3rd party transfer--3p-url 使用url，进行第三方传送--3p-user 使用用户名和密码，进行第三方传送-4/--ipv4 使用IP4-6/--ipv6 使用IP6]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>curl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue学习记录]]></title>
    <url>%2Fweb%2FvueBase.html</url>
    <content type="text"><![CDATA[目标：了解Vue, 了解常用的Vue的一些工具，用vue cli搭建一个测试用例，在浏览器上面运行起来。 了解Vue百科定义Vue (读音 /vjuː/，类似于 view) 是一套用于构建用户界面的渐进式JavaScript框架。与其它大型框架不同的是，Vue 被设计为可以自底向上逐层应用。Vue 的核心库只关注视图层，方便与第三方库或既有项目整合。 同类的技术AngularJS: 诞生于2009年，由Misko Hevery 等人创建，后为Google所收购。是一款优秀的前端JS框架，已经被用于Google的多款产品当中。AngularJS有着诸多特性，最为核心的是：MVC（Model–view–controller）、模块化、自动化双向数据绑定、语义化标签、依赖注入等等。 React: 起源于 Facebook 的内部项目，因为该公司对市场上所有 JavaScript MVC 框架，都不满意，就决定自己写一套，用来架设 Instagram 的网站。做出来以后，发现这套东西很好用，就在2013年5月开源了。主要用于构建UI，很多人认为 React 是 MVC 中的 V（视图）。 AngularJS、React、Vue.js并称前端3大框架。 同类技术优缺点 优点 缺点 Vue.js 轻量级,学习成本低 生态不太成熟 angularJS 有优秀的组件系统 学习曲线是非常陡峭 React 丰富的生态系统 学习曲线陡峭 vue对比链接：https://cn.vuejs.org/v2/guide/comparison.html#AngularJS-Angular-1 vue vs React :合严格的 Flux 架构，适合超大规模多人协作的复杂项目。理论上 Vue 配合类似架构也可以胜任这样的用例，但缺少类似 Flux 这样的官方架构。小快灵的项目上，Vue 和 React 的选择更多是开发风格的偏好。对于需要对 DOM 进行很多自定义操作的项目，Vue 的灵活性优于 React。 vue vs Angular：Angular的学习曲线是非常陡峭的——作为一个框架，它的 API 面积比起 Vue 要大得多，你也因此需要理解更多的概念才能开始有效率地工作。当然，Angular 本身的复杂度是因为它的设计目标就是只针对大型的复杂应用；但不可否认的是，这也使得它对于经验不甚丰富的开发者相当的不友好。 渐进式JavaScript框架vue官网的第一句话就是渐进式JavaScript框架，我的理解就是循序渐进可以自底向上逐层应用开发的框架，可以单独一个页面用来做表单，也可以整个项目用来做框架，可以一步一步引入vue，模块化需要那个就引入那个。 Vue时间轴 2013: 在Google工作的尤雨溪，受到Angular的启发，从中提取自己所喜欢的部分，开发出了一款轻量框架，最初命名为Seed。 2013.12：这粒种子发芽了，更名为Vue，版本号是0.6.0。 2014.01.24：Vue正式对外发布，版本号是0.8.0。 2014.02.25：vue版本0.9.0发布（代号Animatrix动画版的骇客帝国），此后重要的版本都会有自己的代号。 2015.06.13：vue版本0.12.0发布（代号Dragon Ball龙珠），这一年Vue大爆发，Laravel 社区（一款流行的 PHP 框架的社区）首次使用 Vue，Vue在JS社区也打响了知名度。 2015.08.18：vue里程碑-新世纪福音战士发布。vue-router（2015-08-18）、vuex（2015-11-28）、vue-cli（2015-12-27）相继发布，标志着 Vue从一个视图层库发展为一个渐进式框架。 2016.9.3：尤雨溪正式宣布加盟阿里巴巴Weex团队，尤雨溪称他将以技术顾问的身份加入 Weex 团队来做 Vue 和 Weex 的 JavaScript runtime 整合，目标是让大家能用 Vue 的语法跨三端 2016.9.30: vue版本2.0.0 （Ghost in the Shell 攻壳机动队）发布，这是第二个重要的里程碑，它吸收了React的Virtual Dom方案，还支持服务端渲染。 2018.9.30： 发布了 Vue 3.0 的开发路线，会保持与 2.x 的兼容并表示将从头开始重写 3.0 2019.2.4：vue版本2.6.0 （Macross超时空要塞）发布了。新增了Scoped slots(作用域插槽)的新语法、 动态参数指令、响应对象等新特性。 一点小知识Vue学习之前需要了解: Node.js：运行在服务端的 JavaScript，是一个事件驱动I/O服务端JavaScript环境，基于Google的V8引擎，V8引擎执行Javascript的速度非常快，性能非常好。 npm、cnpm : npm是nodejs的包管理器，cnpm是淘宝 NPM 镜像，用来加速。 webpack: 基于node的一个现代 JavaScript 应用程序的静态模块打包器 ECMAScript 6: ECMAScript 6.0（以下简称ES6）是JavaScript语言的下一代标准，已经在2015年6月正式发布了。它的目标，是使得JavaScript语言可以用来编写复杂的大型应用程序，成为企业级开发语言。 html、css、JavaScript的基础 vue官网: 官方文档 看云Vue文档: 二手文档 VSCode：速度较快，对超大文件读写速度飞快(打开10M代码不到1s)，插件数量相对少，有一些增强功能比如调试器， 终端，原生支持语言语法高亮较少(C# JS TypeScript是第一位)，内置JS/TS调试器…可以基于不同项目(文件夹)设置偏好，写C#和JS/TS专用 Element-UI: 饿了么提供的UI框架。iView：一个团队 1234// 在main.js中全局引入element import ElementUI from &apos;element-ui&apos; import &apos;element-ui/lib/theme-chalk/index.css&apos; Vue.use(ElementUI) 维护靠个人的vux: 基于webpack+vue-loader+vux可以快速开发移动端页面，配合vux-loader方便你在WeUI的基础上定制需要的样式。滴滴的cube-ui vuepress: Vue 开发主题的极简静态网站生成器，另一个部分是为书写技术文档而优化的默认主题。它的诞生初衷是为了支持 Vue 及其子项目的文档需求。 Vue组成方式(MVVM模式以及两个核心点) MVVM模式 Model(数据层)-View(视图层)-ViewModel(视图和数据的链接层)，ViewModel层连接Model和View。View层和Model层并没有直接联系，而是通过ViewModel层进行交互。ViewModel层通过双向数据绑定将View层和Model层连接了起来，使得View层和Model层的同步工作完全是自动的。因此开发者只需关注业务逻辑，无需手动操作DOM，复杂的数据状态维护交给MVVM统一来管理 数据驱动 所谓数据驱动，是指视图是由数据驱动生成的，我们对视图的修改，不会直接操作 DOM，而是通过修改数据。它相比我们传统的前端开发，如使用 jQuery 等前端库直接修改 DOM，大大简化了代码量。特别是当交互复杂的时候，只关心数据的修改会让代码的逻辑变的非常清晰，因为 DOM 变成了数据的映射，我们所有的逻辑都是对数据的修改，而不用碰触 DOM，这样的代码非常利于维护。 组件化 所谓组件化，就是把页面拆分成多个组件 (component)，每个组件依赖的 CSS、JavaScript、模板、图片等资源放在一起开发和维护。组件是资源独立的，组件在系统内部可复用，组件和组件之间可以嵌套。 代码结构 Vue的生命周期图(当遇到页面初始化的时候需要处理一下逻辑的时候，在什么时候触发函数) 。详细的生命周期解释：https://segmentfault.com/a/1190000011381906 技术揭秘https://ustbhuangyi.github.io/vue-analysis/data-driven/ 实战安装方式 在官网下载Node.js 123456789101112node -v // 查看node版本npm -v // 查看npm版本npm install cnpm -g // 全局安装cnpmnpm install -g cnpm --registry=https://registry.npm.taobao.org // 指定地址安装cnpmcnpm install vue // 安装最新稳定版本的vuevue --version // 查看vue版本cnpm install --global vue-cli // cnpm 全局安装vue脚手架，npm install -g @vue/cli // npm 全局安装vue脚手架vue init webpack my-project // 创建一个基于 webpack 模板的新项目cd my-project // 到达项目根目录cnpm install // 安装依赖cnpm run dev // 启动项目，或者npm run dev vue脚手架安装时的选项 1234567891011❯ vue build 构建方式,两个选择（上下箭头选择，回车即为选定） Runtime + Compiler:recommended for most users (译：运行+编译：被推荐给大多数用户) Runtime-only:about 6KB lighter min+gzip,but templates (or any Vue-specific HTML) are ONLY allowed in .vue files-render functions are required elsewhere(译：只运行大约6KB比较轻量的压缩文件，但只允许模板（或任何VUE特定HTML）。VUE文件需要在其他地方呈现函数。(意思大概是选择该构建方式对文件大小有要求, 这里推荐使用1选项，适合大多数用户的) Standard (https://github.com/standard/standard) js的标准风格 Airbnb (https://github.com/airbnb/javascript) JavaScript最合理的方法，这个github地址说是JavaScript最合理的方法 none (configure it yourself) 自己配置 Setup unit tests? 是否安装单元测试 Setup e2e tests with Nightwatch(Y/n)?是否安装E2E测试框架NightWatch（E2E，也就是End To End，就是所谓的“用户真实场景”。） yes,use npm(使用npm) yes,use yarn(使用yarn) no,I will handle that myself(自己操作) 如果报以下的错误，就安装缺少依赖(cnpm install)，全部安装完成之后就可以通过链接访问了。 访问http://localhost:8080出现vue标识表示安装成功 vue路由 123456789101112 routes: [ &#123; // 路由路径，浏览器网址输入栏的路径 path: &apos;/&apos;, // 通过name属性，为一个页面中不同的router-view渲染不同的组件,如：将上面代码的Hello渲染在 name为Hello的router-view中，将text渲染在name为text的router-view中。不设置name的将为默认的渲染组件。&lt;router-view name=&quot;test&quot;&gt;12345645645&lt;/router-view&gt; name: &apos;HelloWorld&apos;, // 导入的组件import HelloWorld from &apos;@/components/HelloWorld&apos; component: HelloWorld &#125;,]// 页面跳转方式&lt;router-link to=&quot;/test&quot;&gt;测试1&lt;/router-link&gt; 配置文件 package.json 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152 &#123; &quot;name&quot;: &quot;ffdd-fast-vue&quot;, // 项目名称 &quot;version&quot;: &quot;1.2.2&quot;, // 版本 &quot;description&quot;: &quot;...&quot;, // 描述 &quot;author&quot;: &quot;&quot;, // 作者 &quot;private&quot;: true, // 是否私有 &quot;scripts&quot;: &#123; &quot;dev&quot;: &quot;webpack-dev-server --inline --progress --config build/webpack.dev.conf.js&quot;, // npm run dev 执行的语句 &quot;start&quot;: &quot;npm run dev&quot;, // 项目启动 &quot;unit&quot;: &quot;jest --config test/unit/jest.conf.js --coverage&quot;, // 单元测试 &quot;e2e&quot;: &quot;node test/e2e/runner.js&quot;, // 前端到后端整个过程的测试 &quot;test&quot;: &quot;npm run unit &amp;&amp; npm run e2e&quot;, // 测试 &quot;lint&quot;: &quot;eslint --ext .js,.vue src test/unit/specs test/e2e/specs&quot;, // 修改代码样式, 运行之后就不报ESLint的错误 &quot;build&quot;: &quot;gulp&quot; // 构建 &#125;, &quot;dependencies&quot;: &#123; // 生产环境所有的第三方依赖 &quot;axios&quot;: &quot;0.17.1&quot;, // 代替ajax &quot;babel-plugin-component&quot;: &quot;0.10.1&quot;, // 按需加载插件 &quot;babel-polyfill&quot;: &quot;6.26.0&quot;, // 按需加载进行性能优化插件 &quot;element-ui&quot;: &quot;2.8.2&quot;, // 饿了么提供UI框架 &quot;gulp&quot;: &quot;3.9.1&quot;, // 自动化构建工具 &quot;gulp-concat&quot;: &quot;2.6.1&quot;, // 文件合并插件 &quot;gulp-load-plugins&quot;: &quot;1.5.0&quot;, // 自动加载插件 &quot;gulp-replace&quot;: &quot;0.6.1&quot;, // 文件替换插件 &quot;gulp-shell&quot;: &quot;0.6.5&quot;, // 命令行插件 &quot;lodash&quot;: &quot;4.17.5&quot;, // JavaScript 实用工具库。 &quot;node-sass&quot;: &quot;4.9.0&quot;, // sass编译成css &quot;npm&quot;: &quot;^6.9.0&quot;, &quot;sass-loader&quot;: &quot;6.0.6&quot;, // 是webpack的一个loader, &quot;svg-sprite-loader&quot;: &quot;3.7.3&quot;, // 实现自己的Icon组件 &quot;vue&quot;: &quot;2.5.2&quot;, &quot;vue-cookie&quot;: &quot;1.1.4&quot;, // cookie插件 &quot;vue-router&quot;: &quot;3.0.1&quot;, // vue 路由 &quot;vuex&quot;: &quot;3.0.1&quot; // vue状态管理 &#125;, &quot;devDependencies&quot;: &#123; // 开发环境所有的第三方依赖 &quot;autoprefixer&quot;: &quot;7.1.2&quot;, // 自动补全css前缀 &quot;babel-core&quot;: &quot;6.22.1&quot;, // 把 js 代码分析成 ast ,方便各个插件分析语法进行相应的处理 &quot;babel-eslint&quot;: &quot;7.1.1&quot;, // 语法检查 &quot;babel-jest&quot;: &quot;21.0.2&quot;, // 单元测试 ... &#125;, &quot;engines&quot;: &#123; // 引擎 &quot;node&quot;: &quot;&gt;= 8.11.1&quot;, &quot;npm&quot;: &quot;&gt;= 5.6.0&quot; &#125;, &quot;browserslist&quot;: [ // 浏览器列表 &quot;&gt; 1%&quot;, // 全球超过1%人使用的浏览器 &quot;last 2 versions&quot;, // 所有浏览器兼容到最后两个版本根据CanIUse.com追踪的版本 &quot;not ie &lt;= 8&quot; // 方向排除部分版本 ]&#125; config/index.js 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&apos;use strict&apos; // 模版版本号: 1.3.1 // see http://vuejs-templates.github.io/webpack for documentation. const path = require(&apos;path&apos;) module.exports = &#123; dev: &#123; // npm run dev 执行参数 // 路径 assetsSubDirectory: &apos;static&apos;, // 静态文件路径 assetsPublicPath: &apos;/&apos;, // 代理列表 proxyTable : &#123; &apos;/proxyApi&apos;: &#123; target: &apos;http://localhost:8887/&apos;, // 代理地址 changeOrigin: true, // 变化源 pathRewrite: &#123; // 路径重写 &apos;^/proxyApi&apos;: &apos;/&apos; &#125; &#125; &#125;, // 各种开发服务器设置 host: &apos;localhost&apos;, // 可以被process.env.HOST覆盖 port: 8080, // 可以被process.env.PORT覆盖，如果端口正在使用，将换一个端口 autoOpenBrowser: false, // 自动打开浏览器 errorOverlay: true, // 异常覆盖 notifyOnErrors: true, // 异常通知 poll: false, // https://webpack.js.org/configuration/dev-server/#devserver-watchoptions- // 如果为true，则在捆绑期间将对您的代码进行处理，linting错误和警告将显示在控制台中 useEslint: true, // 如果为true, 错误和警告也将显示在错误覆盖中 showEslintErrorsInOverlay: false, /** * Source Maps */ // 开发环境工具 devtool: &apos;cheap-module-eval-source-map&apos;, // 缓存破坏 // https://vue-loader.vuejs.org/en/options.html#cachebusting cacheBusting: true, cssSourceMap: true &#125;, build: &#123; // npm run build 执行参数 // index.html文件路径指定 index: path.resolve(__dirname, &apos;../dist/index.html&apos;), // 构建后路径指定、资源文件夹名、公开路径 assetsRoot: path.resolve(__dirname, &apos;../dist&apos;), assetsSubDirectory: &apos;static&apos;, assetsPublicPath: &apos;/&apos;, /** * 生产环境的Source Maps */ productionSourceMap: true, // https://webpack.js.org/configuration/devtool/#production devtool: &apos;#source-map&apos;, //默认情况下Gzip关闭许多流行的静态主机，例如Surge或Netlify已经为您准备了所有静态资源。 //在设置为“true”之前，请确保：npm install --save-dev compression-webpack-plugin productionGzip: false, productionGzipExtensions: [&apos;js&apos;, &apos;css&apos;], //运行带有额外参数的build命令 //在构建完成后查看捆绑分析器报告：`npm run build --report` bundleAnalyzerReport: process.env.npm_config_report &#125; &#125;]]></content>
      <categories>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c++学习的一些记录]]></title>
    <url>%2Fstudy%2Fc%2B%2B.html</url>
    <content type="text"><![CDATA[实验程序12345678910111213141516171819202122232425262728293031323334#include&lt;stdio.h&gt;int main(void) &#123; // 求出1~100之间所有每位数的乘积小于没位数的和的数。例如：13满足1*3＜1+3。 &#123; int i,m,n; for(i = 10;i&lt;100;i++) &#123; m = i/10; n = i%10; if(m*n &lt; m +n) &#123; printf("%d\n", i); &#125; &#125; &#125; printf("+++++++++++++++++++"); // 求出1~100之间每位数的乘积大于每位数的和的数。例如数字26，数位上数字的乘积12大于数字之和8 &#123; int n,k=1,s=0,m; for(n=1;n&lt;=100;n++)&#123; k=1; s=0; // 1 m = n; while( m &gt; 0 )&#123; //2 k*=m%10; s+=m%10; // 3 m = m/10; &#125; if(k&gt;s) printf("%d\n",n); &#125; &#125; return 0;&#125; 函数和对象程序基本构成1234// first.cpp // 注释行#include &lt;iostream&gt; // 标准输入输出的预处理命令（将头文件iostream加入到程序中），以＃开头的都是预处理命令using namespace std; // 使用所有标识符的命名空间int main()&#123;&#125; // 是开始执行程序的入口，不管main方法在程序的那个位置，总是先执行，一个程序中，只能有一个主程序。 指针、引用、常量123456int *p = new int(10); // 动态分配了一个int类型的变量，并将它赋值给了指针pdelelte p; // 通过new分配的动态内存空间，必须通过delete运算符释放。int&amp; r = a; // 引用，就是创建一个别名，对引用的操作就是对代表的数据对象的操作。不能引用null，引用是必须立即初始化。const int * p; // *p是常量，不能进行左值操作int * const p = &amp;a; // p本身是常量，不能改变p的指向，内容可以改变const int * const p = &amp;a; // 指针p和p都不能作为左值。 析构函数 当对象消失时，应使用析构函数释放构造函数分配的内存。在对象的生存期结束时被自动调用。 12~Point(); // 析构函数用～区分// 一个类只能有一个析构函数且不能指明参数，不能返回任何类型，void也不行。 复制构造函数1Point(Point&amp;); // 复制构造函数 例子友元12345678910111213141516171819#include &lt;iostream&gt;using namespace std;class point&#123; private: float x; public: void f(float a)&#123;x=a;&#125; void f()&#123;x=0;&#125; friend float max(point&amp;, point&amp;);&#125;;float max (point&amp; a, point&amp; b)&#123; return a.x &gt; b.x ? a.x:b.x;&#125;int main()&#123; point m, n; m.f(2); cout &lt;&lt; max(m,n); // 异常max不是类的成员函数，是类的友元函数，不能用m.max(a,b)方式调用 return 0;&#125; 指针123456789101112131415161718192021222324#include &lt;iostream&gt; using namespace std; int main ()&#123; // 指针演示 int var1; char var2[10]; cout &lt;&lt; "var1 变量的地址： "; cout &lt;&lt; &amp;var1 &lt;&lt; endl; cout &lt;&lt; var1 &lt;&lt; endl; cout &lt;&lt; var2 &lt;&lt; endl; cout &lt;&lt; "var2 变量的地址： "; cout &lt;&lt; &amp;var2 &lt;&lt; endl; int *ch; cout &lt;&lt; ch &lt;&lt; endl; return 0;&#125; 形参交换123456789101112131415161718#include &lt;iostream&gt; using namespace std;// 交换只是交换了形参的值，是无法达到交换值的效果 void swap1(int a, int b)&#123; int tmp; tmp = a; a = b; b = tmp; &#125; int main()&#123; int a = 1; int b = 2; swap1(a, b); cout&lt;&lt;"a = "&lt;&lt;a&lt;&lt;endl; cout&lt;&lt;"b = "&lt;&lt;b&lt;&lt;endl; system("pause"); return 0;&#125; 地址传输12345678910111213141516171819#include &lt;iostream&gt;using namespace std;// swap2接受的参数是地址，我们传入地址，就可以直接操作实参的值了void swap2(int *a, int *b)&#123; int tmp; tmp = *a; *a = *b; *b = tmp;&#125;int main()&#123; int a = 1; int b = 2; swap2(&amp;a, &amp;b); cout&lt;&lt;"a = "&lt;&lt;a&lt;&lt;endl; cout&lt;&lt;"b = "&lt;&lt;b&lt;&lt;endl; system("pause"); return 0;&#125; 指针1234567891011121314151617181920212223#include &lt;iostream&gt; using namespace std;// int **value， 最接近value的是*，说明value是一个指针，在前一个是*，说明是一个指向指针的指针，这样是合法的，那么如何访问value代表的实际参数的值呢？很简单，用**value就可以了，记住*是一个操作符，如同&amp;一样，不过&amp;是取地址操作符，而*是取值操作符 void swap6(int **a, int **b)&#123; int tmp; tmp = **a; **a = **b; **b = tmp; &#125; int main()&#123; int a = 1; int b = 2; int *aPtr = &amp;a;//指向数据的指针 int *bPtr = &amp;b;//指向数据的指针 int **aaPtr = &amp;aPtr;//指向指针的地址的指针 int **bbPtr = &amp;bPtr;//指向指针的地址的指针 swap6(aaPtr, bbPtr); cout&lt;&lt;"a = "&lt;&lt;a&lt;&lt;endl; cout&lt;&lt;"b = "&lt;&lt;b&lt;&lt;endl; system("pause"); return 0;&#125; 引用12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt; using namespace std;// int*&amp; value这样一个声明，我们从最接近value的符号看起，是个&amp;，说明value是一个引用，它是一个什么引用呢？再看*，它是一个指针的引用，即指针的别名，我们用*value就可以访问到实参的值了。所以，其交换函数的内部逻辑跟int *是一样的 void swap5(int *&amp;a, int *&amp;b)&#123; int tem = *a; *a = *b; *b = tem; &#125; int main()&#123; int a = 1; int b = 2; int *aPtr = &amp;a; int *bPtr = &amp;b; int *&amp;arPtr = aPtr; int *&amp;brPtr = bPtr; swap5(arPtr, brPtr); cout&lt;&lt;"a = "&lt;&lt;a&lt;&lt;endl; cout&lt;&lt;"b = "&lt;&lt;b&lt;&lt;endl; system("pause"); return 0;&#125;#include &lt;iostream&gt;using namespace std;// 引用即别名，通过引用也是可以直接访问到实参和控制实参的void swap3(int&amp; a, int&amp; b)&#123; int tmp; tmp = a; a = b; b = tmp;&#125;int main()&#123; int a = 1; int b = 2; swap3(a, b); cout&lt;&lt;"a = "&lt;&lt;a&lt;&lt;endl; cout&lt;&lt;"b = "&lt;&lt;b&lt;&lt;endl; system("pause"); return 0;&#125; 析构函数用例1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;iostream&gt;using namespace std;class Point&#123; private: int x,y; // 定义一个函数时，必须先要声明 public: Point(); Point(int, int); ~Point();&#125;;// 定义不带参数的构造函数Point::Point():x(0),y(0)&#123; cout &lt;&lt; "默认" &lt;&lt; x &lt;&lt; "," &lt;&lt; y &lt;&lt; endl;&#125;;// 定义带两个参数的构造函数 :x(a),y(b)等同于x=a,y=bPoint::Point(int a, int b):x(a),y(b)&#123; cout &lt;&lt; "赋值" &lt;&lt; a &lt;&lt; "," &lt;&lt; b &lt;&lt; endl;&#125;;Point:: ~Point(void) &#123; cout &lt;&lt; "析构函数" &lt;&lt; endl;&#125;;int main() &#123; // 构造器产生对象 Point A; Point B(15, 16); // 数组对象 Point C[2]; Point D[2] = &#123; Point(5,7), Point(8, 12) &#125;; Point *ptr1 = new Point; Point *ptr = new Point(10,23); // 删除内存空间中的对象 delete ptr1; delete ptr; Point *po = new Point[2]; delete []po;&#125;; 构造器的初始化1234567891011121314151617181920212223242526272829303132333435363738#include&lt;iostream&gt;using namespace std;class object&#123; private: int val; public: object():val(0)&#123; cout &lt;&lt; "object的默认构造器" &lt;&lt; endl; &#125; object(int i) : val(i)&#123; cout &lt;&lt; "object的带参构造器" &lt;&lt; val &lt;&lt; endl; &#125; ~object() &#123; cout &lt;&lt; "objecd的析构函数" &lt;&lt; val &lt;&lt; endl; &#125;&#125;;class container&#123; private: object one; object two; int data; public: container(): data(0)&#123; cout &lt;&lt; "container的默认构造器" &lt;&lt; endl; &#125; container(int i, int j,int k); ~container() &#123; cout &lt;&lt; "container的析构函数" &lt;&lt; data &lt;&lt; endl; &#125;&#125;;container::container(int i, int j, int k):two(i), one(j) &#123; data = k; cout &lt;&lt; "container的带参构造器" &lt;&lt; data &lt;&lt; endl;&#125;int main() &#123; container obj, anObj(5,6,10); return 0;&#125; 虚函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;using namespace std;class A&#123; public: A()&#123; cout &lt;&lt; "A的构造函数" &lt;&lt; endl; &#125; virtual void func()&#123; cout &lt;&lt; "类A的虚函数" &lt;&lt; endl; &#125; ~A()&#123;&#125; virtual void fund()&#123; cout &lt;&lt; "类A的析构函数" &lt;&lt; endl; &#125;&#125;;class B : public A&#123; public: B()&#123; cout &lt;&lt; "B的构造函数" &lt;&lt; endl; func(); &#125; void fun() &#123; cout &lt;&lt; "类B的函数,开始了："; func(); &#125; ~B()&#123; fund(); &#125;&#125;;class C : public B&#123; public: C()&#123; cout &lt;&lt; "类C的函数,开始了："; &#125; void func() &#123; cout &lt;&lt; "类C的fun函数" &lt;&lt; endl; &#125; ~C()&#123; fund(); &#125; void fund()&#123; cout &lt;&lt; "类C的fund函数" &lt;&lt; endl; &#125;&#125;;int main() &#123; C c; c.fun();&#125;]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进阶学习]]></title>
    <url>%2Fstudy%2Fstudy.html</url>
    <content type="text"><![CDATA[网上找到的高效学习方法 GitHub链接 https://github.com/judasn/hexo-blog/blob/master/2016/02/My-Learning-Way.md MD模版 1234567891011121314151617181920# &lt;center&gt;技术名&lt;/center&gt;&gt; 官方文档## 技术来源### 解决什么问题### 以前的处理方式## 含义### 百科定义### 同类的技术### 同类技术优缺点### 组成方式## 实战### 安装方式### 配置文件 性能优化 微服务架构 高并发分布式技术 微服务架构 自动化工具 来源：https://www.jianshu.com/p/d1d5c7a7c80d?utm_campaign=haruki&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=weixin 进阶学习 java拓展]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>study</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[颓废的时候]]></title>
    <url>%2Flife%2Fphrase.html</url>
    <content type="text"><![CDATA[无所事事的度过了这么久的时间，过去的这么长的时间里。我总是在纠结、自卑、懊悔中度过的，一点也不阳光，一直特别的丧。可是回想了一下以前的自己，感觉自己一直都是这个状态，一直开心不起来。刷手机的时候总是会看到有人说不要活在过去，我们是活在现在的，现在一切美好的时光都值得自己去好好享受。可是我总是享受不来，命运如此吗？还是我没有放过我自己。 尽管我在怎么逃避，在怎么不想去面对，可终究是分手了的。从她说分手的那一刻，而不是我坚持到最后坚持不下去了才说“算了吧！我认输”的那一刻。 我是一个喜欢逃避的人，不想面对所有的事情，以为所有的事只要笑一笑就会过去的，可是这件事情我总是笑不起来，不知道中间那个环节出现了问题。 我是一个不善言辞的人，可能自己吃了卑微果实吧！还在随时给自己放技能。 每天都是口水话，同样的话，就像妈妈的唠叨一样，还没开口就知道下一句话说的是什么。一个不会变花样的人。 谈恋爱一直都是两个人的事情，一方不想继续了，另一方在纠缠下去只会让美好的事情变得不那么美好。可是道理谁都懂，我总是做不到。 生活总是要继续下去的。不知道自己什么时候才能做到坦然的面对生活。 人生总是坎坷的，得过且过。 不知道自己的爱好是什么，害怕空闲的时候，无所事事的时候，心里就是空荡荡的，不知道干什么特别的迷茫无助，不知道未来在哪里，不知道意义何在，不知道这种状态还要持续多久。这种感觉糟糕透了。 特别喜欢快速打字发出的键盘声音，弹指一挥间。 每天漫无目的地忙碌着，也不知道自己要干什么，总觉得少了点什么。没有很强的动力来源。 活在过去的人，没有未来。 不知道自己的未来在那里，已经这么久了，还是没有走出去。这几天经常迷茫，不知道自己在想些什么，经常失眠，感觉自己的人生到了一个末路的情景。生活总是这样的吗？不知道该怎么办？ 在这段感情中，我学到了什么呢？ 1、关心都是相互的，我关心你，你关心我，我对你好，你也对我好。2、很多事是勉强不了的，不管你有多舍不得。3、沮丧是没有任何意义的，只会徒增烦恼。 过去这么久了，我的脑海里面还是不能忘怀，不知道在想些什么。最近的工作压力也比较大，睡眠质量也不是很好，总会在深夜醒来，已经好久没有舒坦的睡大觉了。整个人也是特别的焦虑。希望自己能安静下来。 今年大半年已经过去了，感觉自己没有学到更多的东西，要好好的学习新东西了。 我有敢于承担责任的能力和毅力吗？我足够上进吗？我有能力在经济方面让这个小家的生活质量越来越好吗？如果以后有了一个新的生命，在没有说明书的情况下，能把这个小朋友照顾好，并对Ta的人生负责吗？我没想好答案，我还想在等一等。 一天一天的过去了，每天都感觉惶惶不可终日，不知道自己应该干些什么。下班了就感觉已经很累了，感觉学习的动力没有以前强烈了。学习的动力不知道要从哪里找到。再一次问自己，我有敢于承担责任的能力和毅力吗？我足够上进吗？我有能力在经济方面让这个小家的生活质量越来越好吗？如果以后有了一个新的生命，在没有说明书的情况下，能把这个小朋友照顾好，并对Ta的人生负责吗？我没想好答案，我还想在等一等。 今天又是新的一天过去了，没有学习到新的技术，一直在用之前学到的东西。是时候多学一点东西了。加油！最近很少有时间问自己 每天都是重复的生活，一成不变的样子，失眠的还是向之前一样，睡觉的时候担心失眠就回失眠，焦虑了。在代码上面投入了太多的精力，应该给自己找一些爱好。 已经很久没有写日记了，之前计划的是每天都写日记的。每天跟自己说说话，自己反省自己，但是不知道什么时候开始，就已经忘记了这个事情，每天也不知道自己是不是过的好，是不是有一个好的心情。已经浑浑噩噩的过了好久的时间，我也必须开朗起来。很久不说话的我，说话总是太过小心翼翼了，少了男子汉的刚性。为人处事方面也是小心翼翼，不敢表达自己的意见，说话紧张兮兮。但是自己有在想办法摆脱这种方式吗？没有！一直都是习惯了这种方式，只有在偶尔的情况下才会想起来。 好久都没有和自己说话了，之前获得的一句话’活在过去的人，没有未来’。我还是活在过去的吗？还没有从过去走出来吗？之前不是掌握了一项重要的技能吗？ 一项遗忘的技能，可以到现在为止也没有掌握。该忘记的始终没有忘记，不该忘记的事情却给忘记了。自己的事情总是随波逐流，定的目标总是没有完成。日复一日的过去. 最近感觉比较乱，没有学到东西，心里也是一直没有安静下来。好像有一点方向了，又好像没有方向了。又是因为感情的事情，感情的事情总是不那么顺利，之前一直都是在逃避不想面对，可是一直这样又能怎么样呢？无法改变什么，我又要改变什么呢？一直质疑自己，一直被别人牵着鼻子走。也一直就像配角一样活着，羡慕很多的人，他们洒脱。 自己做的对吗？什么样子才算对？自己跟自己对话，自己跟自己诉说。做什么事情都会怀疑自己，怀疑自己做的不够好，这是一种好的事情吗？只有一直怀疑自己，才会一直往前走么！最近浑浑噩噩的看了好多小说，一直这样下去学到的东西就太少了，要学会克制自己。给自己制定计划，每天什么时候应该干什么事情。]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2Flinux%2Fgit.html</url>
    <content type="text"><![CDATA[title: centos7安装git服务器date: 2018-09-20 22:50:11tags: gitcategories: linux linux安装git，并配置仓库1.安装git,查看版本号12yum install -y gitgit --version 2.创建git用户useradd git //创建用户 password git //更改密码 3.初始化git仓库，并改变仓库权限cd /home/git mkdir -p test.git //创建仓库 git init --bare test.git //初始化 chown -R git:git test.git //改变权限 4.克隆仓库到本地git clone git@119.10.15.56:/home/git/test.git 本地git与远程git交互1.本地初始化git，并上传git init //初始化 git add test.txt //增加文件到暂存区 git commit -m &apos;注释&apos; //提交文件到本地仓库 git remote rm origin //删除之前的remote git remote add origin git@119.106.185.58:/home/test.git //添加远程起源 git push origin master //通过origin原点添加master分支到远程git仓库 2.更新agit pull origin master //取回origin主机的master分支，与本地当前分支合并 3.常用上传git add -A //将所有的新文件添加到暂存区 git add test.txt //增加文件到暂存区 git commit -m &apos;注释&apos; //提交文件到本地仓库 git commit -a -m &apos;注释&apos; //将所有的文件提交到本地仓库 git push origin master //通过origin原点添加master分支到远程git仓库 常用git命令git status //查看git状态 git remote -v //查看所有原点 git stash // 暂存，遇到pull代码冲突的时候，可以先暂存代码之后，在进行pull git stash pop // 返回到之前暂存的版本并删除之前的暂存版本 git push origin master --force //强制上传，将本地代码覆盖掉远程代码 // 删除远程分支 git push origin --delete BranchName // 删除本地分支 git branch -d BranchName 分支12345678910111213141516171819git branch //看看分支 git checkout aaa //切换分支aaa git branch aaa //创建aaa分支 git checkout -b aaa //本地创建 aaa分支，同时切换到aaa分支。只有提交的时候才会在服务端上创建一个分支git pull origin master //更新指定分支git branch -vv // 查看分支跟踪的远程分支git branch -v // 分支信息git branch --no-merged // 查看尚未合并的工作git merge iss53 // 将iss53合并到当前分支// 创建自己的分支并切换到自己的分支git checkout -b Branch.gaoqisen.20200825// 更新dev分支代码到自己的分支git pull origin dev// 冲突解决git checkout bbbgit merge aaagit push origin bbb 更详细的解释​ 问题解决1234// 冲突问题Merging is not possible because you have unmerged filesgit add -ugit commit -m &apos;&apos;git pull origin dev git钩子自动执行更新1.在初始化git仓库里面找到hooks文件夹，并在里面创建钩子文件vim post-receive //用vim创建文件 chmod 755 post-receive // 更改执行权限 2.编辑自动执行脚本1234567891011121314#!/bin/sh## 你需要部署的项目路径。注意文件夹的权限问题PATH=/home/fileDir/ cd $PATH ## git的hooks里面默认有一些环境变量,导致无论在哪个语句之后执行git命令都会有默认环境路径,直接unset掉默认的环境变量就好unset $(git rev-parse --local-env-vars) ## 更新项目/usr/bin/git pull ## 切换到root用户身份执行自己的脚本sudo /home/sh/git_hook.sh ## 注意：该命令需要在/etc/sudoers 大概91行左右的root ... （添加是需要改变文件的写权限，否则无法添加）下面添加：git ALL=(ALL) NOPASSWD:/home/sh/git_hook.sh 3.服务器克隆本地git仓库代码1git clone /home/test.git 暂时需要使用到的命令就这些。以后遇到了在增加]]></content>
  </entry>
  <entry>
    <title><![CDATA[nginx]]></title>
    <url>%2Flinux%2Fnginx.html</url>
    <content type="text"><![CDATA[日志分析12345678910# 统计所有的PV数（页面浏览量）cat access.log | wc -l# 获取访问IP数cat access.log | awk '&#123;print $1&#125;' | sort -k1 -r | uniq | wc -l# 查看日志中访问次数最多的前10个IPcat access.log |cut -d ' ' -f 1 | sort |uniq -c | sort -nr | awk '&#123;print $0 &#125;' | head -n 10 sed -n '/2019:21:[0-9][0-9]:[0-9][0-9]/,/2019:22:[0-9][0-9]:[0-9][0-9]/p' access.log_2019-12-18 |cut -d ' ' -f 1 | sort |uniq -c | sort -nr | awk '&#123;print $0 &#125;' | head -n 10# 查看日志中访问次数超过1000次的前10个IPcat access.log |cut -d ' ' -f 1 | sort |uniq -c | sort -nr | awk '&#123;if($1&gt;1000) print $0 &#125;' | head -n 10# 查看日志中访问url的次数awk '&#123;print $7&#125;' access.log_2019-12-25|sort | uniq -c |sort -n -k 1 -r &gt; test.txt 常用命令12345678910111213141516# 重启nginx./nginx -s reload# 启动nginx./nginx# 关闭nginx./nginx -s stop# 查看nginx并发连接数# TIME_WAIT表示处理完毕，等待超时结束的请求数 Linux默认的TIME_WAIT时长一般是60秒 TIME_WAIT数量较大时会出现访问很慢的情况，如网办# CLOSE-WAIT： 等待从本地用户发来的连接中断请求# SYN_SENT：应用已经开始，打开一个连接# FIN_WAIT1：应用说它已经完成# FIN_WAIT2：另一边已同意释放# ESTABLISHED：表示正常数据传输状态 or 当前并发连接数# SYN_RECV：表示正在等待处理的请求数# LAST_ACK：等待所有分组死掉netstat -n | awk '/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;' nginx配置生成网站https://nginxconfig.io/ nginx.conf 配置详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120#nginx进程数worker_processes 8;# 0001表示启用第一个CPU内核，0010表示启用第二个CPU内核，依此类推；worker_processes最多开启8个，8个以上性能提升不会再提升了，而且稳定性变得更低，所以8个进程够用了。worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000;#一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（系统的值ulimit) 与nginx进程数相除，但是nginx分配请求并不均匀，所以建议与ulimit -n的值保持一致。worker_rlimit_nofile 655350;#制定日志路径，级别。这个设置可以放入全局块，http块，server块，级别以此为：debug|info|notice|warn|error|crit|alert|emergerror_log /home/log/nginx/nginx_error.log crit; #单个进程最大连接数events &#123; #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，如果跑在FreeBSD上面，就用kqueue模型。 use epoll; #单个worker进程允许客户端最大连接数，这个数值一般根据服务器性能和内存来制定，实际最大值就是worker进程数乘以work_connections实际我们填入一个65535，足够了，这些都算并发值 worker_connections 40960; #告诉nginx收到一个新连接通知后接受尽可能多的连接，默认是on，设置为on后，多个worker按串行方式来处理连接，也就是一个连接只有一个worker被唤醒，其他的处于休眠状态，设置为off后，多个worker按并行方式来处理连接，也就是一个连接会唤醒所有的worker，直到连接分配完毕，没有取得连接的继续休眠。当你的服务器连接数不多时，开启这个参数会让负载有一定的降低，但是当服务器的吞吐量很大时，为了效率，可以关闭这个参数。 multi_accept on; #最大连接数，默认为512 #worker_connections 1024;&#125;#http服务器配置http &#123; #文件扩展名与文件类型映射表 include mime.types; #默认文件类型，默认为text/plain default_type application/octet-stream; #允许sendfile方式传输文件，默认为off，可以在http块，server块，location块。 sendfile on; #长连接超时时间，单位是秒 keepalive_timeout 65; #防止网络阻塞 tcp_nopush on; #防止网络阻塞 tcp_nodelay on; #隐藏版本号 server_tokens off; #设定服务器名称（即server_name指令所设置）哈希表的框大小，值越大能设置的server_name可以越多。参数哈希框大小总是等于哈希表的大小，即处理器高速缓存区（32）的倍数，这将加速处理器中key的搜索速度，减少内存的存取数。 server_names_hash_bucket_size 128; server_names_hash_max_size 512; #客户端请求头部的缓冲区大小 client_header_buffer_size 2k; #设置客户端请求的Header头缓冲区大小，默认为4K。客户端请求行不能超过设置的第一个数，请求的Header头信息不能大于设置的第二个数，否则会报"Request URI too large"(414)或“Bad request”(400)错误。如果客户端的Cookie信息较大，则需增加缓冲区大小 large_client_header_buffers 4 4k; #设置nginx允许接收的客户端请求内容的最大值，及客户端请求Header头信息中设置的Content-Lenth大最大值。如果超出该指令设置的最大值，nginx将返回“Request Entity Too Large”的错误信息(HTTP的413错误码) client_max_body_size 500m; #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后***缓存。 open_file_cache max=655350 inactive=20s; #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。 open_file_cache_min_uses 1; #这个是指多长时间检查一次缓存的有效信息。 open_file_cache_valid 30s; #设置nginx读取客户端请求Header头信息的超时时间，如果超过该指令设置的时间，nginx将返回"Requet time out"错误信息（HTTP的408错误码） client_header_timeout 15s; #设定nginx读取客户端请求内容的超时时间，如果超过该指令设置的时间，nginx将返回"Request time out"错误信息(HTTP状态码408) client_body_timeout 15s; #设置发送给客户端的应答超时时间。指两次tcp握手，还没有转为established状态的时间。如果这个时间，客户端没有响应，Nginx则关闭连接 send_timeout 60s; #开启gzip压缩功能，对用户请求的页面进行压缩处理，以达到节省网络带宽，提高网站速度的作用。 gzip on; #允许压缩的页面最小字节数。建议值为大于1024字节，小于1K的压缩可能无效果 gzip_min_length 1k; #设置系统获取几个单位的缓存用于存储gzip压缩结果数据流。此设置为：按照原始数据大小以16K为单位的4倍大小申请内存空间。如果不设置的话，默认值是申请跟原始数据相同大小的内存空间去存储gzip压缩的结果。 gzip_buffers 4 16k; #识别http协议的版本,只有1.1版本的压缩，因为可能早期的浏览器或http客户端可能不支持gzip压缩 gzip_http_version 1.0; #设置压缩比，值为1-9，压缩比最大，处理速度会越慢 gzip_comp_level 2; #指定需要被压缩的文件媒体类型 gzip_types text/plain text/javascript application/x-javascript application/json application/javascript text/css application/xml; #gzip_vary的作用是在http响应中增加一行“Vary: Accept-Encoding”，目的是改变反向代理服务器的缓存策略，反向代理服务器会根据后端服务器是否带Vary头采用不同的缓存策略。 gzip_vary on; #log日志配置 log_format access '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; #用来设置日志格式 access_log /home/log/nginx/access.log access; #虚拟主机的配置 server &#123; #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name test; #rewrite ^ https://$http_host$request_uri? permanent; # proxy_redirect功能比较强大,其作用是对发送给客户端的URL进行修改 proxy_redirect off; # 问产生405 503的时候给用户的返回状态是200,设置一个@405，在里边做对应的处理 error_page 405 503 =200 @405; location @405&#123; root /opt/htdocs; &#125; location / &#123; #禁止某个ip或者一个ip段访问.如果指定unix:,那将禁止socket的访问.注意：unix在1.5.1中新加入的功能，如果你的版本比这个低，请不要使用这个方法。 deny 127.0.0.1; deny 127.0.0.2; # 客户端主动断掉连接之后，Nginx 会等待后端处理完(或者超时)，然后 记录 「后端的返回信息」 到日志。所以，如果后端 返回 200， 就记录 200 ；如果后端放回 5XX ，那么就记录 5XX 。 proxy_ignore_client_abort on; # 代理转发 proxy_pass http://inspur; # 定项目的根目录，适用与server和location。可以指定多个，如果locaiton没有指定，会往其外层的server或http中寻找继承。 root html; # 在前后端分离的基础上，通过Nginx配置，指定网站初始页 index index.html index.htm; # 允许重新定义或添加字段传递给代理服务器的请求头 proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host:$server_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 客服端最大上传文件大小 client_max_body_size 100m; &#125; &#125; #upstream负载均衡配置，配置路由到tomcat的服务地址以及权重 upstream test&#123; #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题 ip_hash; # weight设置权重，多个服务器ip进行负载均衡分发 server 192.168.0.1:80 weight=5; server 192.168.0.2:80 weight=10; &#125;&#125;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat-service.xml标签含义]]></title>
    <url>%2Fjava%2FtomcatService.html</url>
    <content type="text"><![CDATA[service.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!-- 属性说明port:指定一个端口，这个端口负责监听关闭Tomcat的请求shutdown:向以上端口发送的关闭服务器的命令字符串--&gt;&lt;Server port=&quot;8005&quot; shutdown=&quot;SHUTDOWN&quot;&gt; &lt;!-- Listener监听器 --&gt; &lt;Listener className=&quot;org.apache.catalina.startup.VersionLoggerListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine=&quot;on&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.JreMemoryLeakPreventionListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener&quot; /&gt; &lt;!-- 全局资源 --&gt; &lt;GlobalNamingResources&gt; &lt;!-- 可编辑的用户数据库，也可供其使用 UserDatabaseRealm 用于对用户进行身份验证 --&gt; &lt;Resource name=&quot;UserDatabase&quot; auth=&quot;Container&quot; type=&quot;org.apache.catalina.UserDatabase&quot; description=&quot;User database that can be updated and saved&quot; factory=&quot;org.apache.catalina.users.MemoryUserDatabaseFactory&quot; pathname=&quot;conf/tomcat-users.xml&quot; /&gt; &lt;/GlobalNamingResources&gt; &lt;!-- Tomcat服务，name=Catalina，用于 绑定 连接器与 Engine --&gt; &lt;Service name=&quot;Catalina&quot;&gt; &lt;!-- Connector 元素: 由 Connector 接口定义.&lt;Connector&gt; 元素代表与客户程序实际交互的组件,它负责接收客户请求,以及向客户返回响应结果. 属性说明: port:服务器连接器的端口号,该连接器将在指定端口侦听来自客户端的请求。 enableLookups:如果为 true，则可以通过调用 request.getRemoteHost() 进行 DNS 查询来得到远程客户端的实际主机名；若为 false 则不进行DNS查询，而是返回其ip地址。 redirectPort:服务器正在处理http请求时收到了一个SSL传输请求后重定向的端口号。 acceptCount:当所有可以使用的处理请求的线程都被用光时,可以放到处理队列中的请求数,超过这个数的请求将不予处理，而返回Connection refused错误。 connectionTimeout:等待超时的时间数（以毫秒为单位）。 maxThreads:设定在监听端口的线程的最大数目,这个值也决定了服务器可以同时响应客户请求的最大数目.默认值为200。 protocol:必须设定为AJP/1.3协议。 address:如果服务器有两个以上IP地址,该属性可以设定端口监听的IP地址,默认情况下,端口会监听服务器上所有IP地址。 minProcessors:服务器启动时创建的处理请求的线程数，每个请求由一个线程负责。 maxProcessors:最多可以创建的处理请求的线程数。 minSpareThreads:最小备用线程 。 maxSpareThreads:最大备用线程。 debug:日志等级。 disableUploadTimeout:禁用上传超时,主要用于大数据上传时。 --&gt; &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; &lt;!-- 负责和其他 HTTP 服务器建立连接。在把 Tomcat 与其他 HTTP 服务器集成时就需要用到这个连接器。 --&gt; &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; &lt;!-- 每个Service元素只能有一个Engine元素.元素处理在同一个&lt;Service&gt;中所有&lt;Connector&gt;元素接收到的客户请求 属性说明: name:对应$CATALINA_HOME/config/Catalina 中的 Catalina ; defaultHost: 对应Host元素中的name属性,也就是和$CATALINA_HOME/config/Catalina/localhost中的localhost，缺省的处理请求的虚拟主机名，它至少与其中的一个Host元素的name属性值是一样的 debug:日志等级 --&gt; &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt; &lt;!-- Realm：领域 UserDatabaseRealm将UserDatabase的数据注入到引擎中，便于引擎访问UserDatabase --&gt; &lt;Realm className=&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.UserDatabaseRealm&quot; resourceName=&quot;UserDatabase&quot;/&gt; &lt;/Realm&gt; &lt;!-- 由 Host 接口定义.一个 Engine 元素可以包含多个&lt;Host&gt;元素. 每个&lt;Host&gt;的元素定义了一个虚拟主机.它包含了一个或多个Web应用. 属性说明： name:在此例中一直被强调为$CATALINA_HOME/config/Catalina/localhost中的localhost虚拟主机名 debug:是日志的调试等级 appBase:默认的应用路径,也就是把应用放在一个目录下,并在autoDeploy为true的情况下,可自动部署应用此路径相对于$CATALINA_HOME/ (web applications的基本目录) unpackWARs:设置为true,在Web应用为*.war是,解压此WAR文件. 如果为true,则tomcat会自动将WAR文件解压;否则不解压,直接从WAR文件中运行应用程序. autoDeploy:默认为true,表示如果有新的WEB应用放入appBase 并且Tomcat在运行的情况下,自动载入应用 --&gt; &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;!-- 属性说明： path:访问的URI,如:http://localhost/是我的应用的根目录,访问此应用将用:http://localhost/demm进行操作,此元素必须， 表示此web application的URL的前缀，用来匹配一个Context。请求的URL形式为http://localhost:8080/path/* docBase:WEB应用的目录,此目录必须符合Java WEB应用的规范，web application的文件存放路径或者是WAR文件存放路径。 debug:日志等级 reloadable:是否在程序有改动时重新载入,设置成true会影响性能,但可自动载入修改后的文件， 如果为true，则Tomcat将支持热部署，会自动检测web application的/WEB-INF/lib和/WEB-INF/classes目录的变化， 自动装载新的JSP和Servlet，我们可以在不重起Tomcat的情况下改变web application --&gt; &lt;Context path=&quot;/demm&quot; docBase=&quot;E:\\projects\\demm\\WebRoot&quot; debug=&quot;0&quot; reloadable=&quot;true&quot;&gt;&lt;/Context&gt; &lt;!-- Valve：阀门也可以理解为一个过滤器，放在了host里面则服务于整个host，放在Context内则只服务于那一个Context 作用：打印请求日志，IP过滤，限流等 具体配置要基于具体的Valve 接口的子类。以下即为一个访问日志的Valve. --&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt;]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat service.xml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker命令]]></title>
    <url>%2Flinux%2Fdocker.html</url>
    <content type="text"><![CDATA[一、镜像更改数据源为国内阿里的镜像 123456789101112# vim /etc/docker/daemon.json&#123;# 增加下面的数据源"registry-mirrors": ["https://xv4nhf8h.mirror.aliyuncs.com"],"exec-opts": ["native.cgroupdriver=systemd"],"log-driver": "json-file","log-opts": &#123;"max-size": "100m"&#125;&#125;# 重启dockerservice docker restart 二、网络在同一个docker-compose里面创建多个服务。自动创建在一个网络里面，通过服务名即可访问 12345678// 创建一个桥接模式的网络docker network create mynetwork // 在docker-compose里面加入如下配置networks: default: external: name: mynetwork 三、客服端命令1234567sudo docker rm $(sudo docker ps -a -q) // 删除所有停止了的服务docker container prune // 删除所有停止了的服务(1.13版本后)docker network create webcenter // 网络docker network inspect webcenter // 查看网络有哪些容器docker network connect webcenter mysql // 将mysql容器添加到webcenter网络中docker build -it webcenter:1.0.1 -f ./dockerfile . // 指定docker文件构件docker tag webcenter:latest gqs/webcenter:1.0.1 // 更改镜像名称 123456789101112131415161718192021222324252627282930313233343536373839404142434445attach：依附到一个正在运行的容器中；build：从一个 Dockerfile 创建一个镜像；commit：从一个容器的修改中创建一个新的镜像；cp：在容器和本地宿主系统之间复制文件中；create：创建一个新容器，但并不运行它；diff：检查一个容器内文件系统的修改，包括修改和增加；events：从服务端获取实时的事件；exec：在运行的容器内执行命令；export：导出容器内容为一个 tar 包；history：显示一个镜像的历史信息；images：列出存在的镜像；import：导入一个文件（典型为 tar 包）路径或目录来创建一个本地镜像；info：显示一些相关的系统信息；inspect：显示一个容器的具体配置信息；kill：关闭一个运行中的容器 &amp;#40;包括进程和所有相关资源&amp;#41;；load：从一个 tar 包中加载一个镜像；login：注册或登录到一个 Docker 的仓库服务器；logout：从 Docker 的仓库服务器登出；logs：获取容器的 log 信息；network：管理 Docker 的网络，包括查看、创建、删除、挂载、卸载等；node：管理 swarm 集群中的节点，包括查看、更新、删除、提升/取消管理节点等；pause：暂停一个容器中的所有进程；port：查找一个 nat 到一个私有网口的公共口；ps：列出主机上的容器；pull：从一个Docker的仓库服务器下拉一个镜像或仓库；push：将一个镜像或者仓库推送到一个 Docker 的注册服务器；rename：重命名一个容器；restart：重启一个运行中的容器；rm：删除给定的若干个容器；rmi：删除给定的若干个镜像；run：创建一个新容器，并在其中运行给定命令；save：保存一个镜像为 tar 包文件；search：在 Docker index 中搜索一个镜像；service：管理 Docker 所启动的应用服务，包括创建、更新、删除等；start：启动一个容器；stats：输出（一个或多个）容器的资源使用统计信息；stop：终止一个运行中的容器；swarm：管理 Docker swarm 集群，包括创建、加入、退出、更新等；tag：为一个镜像打标签；top：查看一个容器中的正在运行的进程信息；unpause：将一个容器内所有的进程从暂停状态中恢复；update：更新指定的若干容器的配置信息；version：输出 Docker 的版本信息；volume：管理 Docker volume，包括查看、创建、删除等；wait：阻塞直到一个容器终止，然后输出它的退出符。 3.1 客服端命令选项123456789--config=&quot;&quot;：指定客户端配置文件，默认为 `/.docker`；-D=true|false：是否使用 debug 模式。默认不开启；-H, --host=[]：指定命令对应 Docker 守护进程的监听接口，可以为 unix 套接字（unix:///path/to/socket），文件句柄（fd://socketfd）或 tcp 套接字（tcp://[host[:port]]），默认为 unix:///var/run/docker.sock；-l, --log-level=&quot;debug|info|warn|error|fatal&quot;：指定日志输出级别；--tls=true|false：是否对 Docker 守护进程启用 TLS 安全机制，默认为否；--tlscacert= /.docker/ca.pem：TLS CA 签名的可信证书文件路径；--tlscert= /.docker/cert.pem：TLS 可信证书文件路径；--tlscert= /.docker/key.pem：TLS 密钥文件路径；--tlsverify=true|false：启用 TLS 校验，默认为否。 3.2 docker 命令选项1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950--api-cors-header=&quot;&quot;：CORS 头部域，默认不允许 CORS，要允许任意的跨域访问，可以指定为 “*”；--authorization-plugin=&quot;&quot;：载入认证的插件；-b=&quot;&quot;：将容器挂载到一个已存在的网桥上。指定为 &apos;none&apos; 时则禁用容器的网络，与 --bip 选项互斥；--bip=&quot;&quot;：让动态创建的 docker0 网桥采用给定的 CIDR 地址; 与 -b 选项互斥；--cgroup-parent=&quot;&quot;：指定 cgroup 的父组，默认 fs cgroup 驱动为 `/docker`，systemd cgroup 驱动为 `system.slice`；--cluster-store=&quot;&quot;：构成集群（如 Swarm）时，集群键值数据库服务地址；--cluster-advertise=&quot;&quot;：构成集群时，自身的被访问地址，可以为 `host:port` 或 `interface:port`；--cluster-store-opt=&quot;&quot;：构成集群时，键值数据库的配置选项；--config-file=&quot;/etc/docker/daemon.json&quot;：daemon 配置文件路径；--containerd=&quot;&quot;：containerd 文件的路径；-D, --debug=true|false：是否使用 Debug 模式。缺省为 false；--default-gateway=&quot;&quot;：容器的 IPv4 网关地址，必须在网桥的子网段内；--default-gateway-v6=&quot;&quot;：容器的 IPv6 网关地址；--default-ulimit=[]：默认的 ulimit 值；--disable-legacy-registry=true|false：是否允许访问旧版本的镜像仓库服务器；--dns=&quot;&quot;：指定容器使用的 DNS 服务器地址；--dns-opt=&quot;&quot;：DNS 选项；--dns-search=[]：DNS 搜索域；--exec-opt=[]：运行时的执行选项；--exec-root=&quot;&quot;：容器执行状态文件的根路径，默认为 `/var/run/docker`；--fixed-cidr=&quot;&quot;：限定分配 IPv4 地址范围；--fixed-cidr-v6=&quot;&quot;：限定分配 IPv6 地址范围；-G, --group=&quot;&quot;：分配给 unix 套接字的组，默认为 `docker`；-g, --graph=&quot;&quot;：Docker 运行时的根路径，默认为 `/var/lib/docker`；-H, --host=[]：指定命令对应 Docker daemon 的监听接口，可以为 unix 套接字（unix:///path/to/socket），文件句柄（fd://socketfd）或 tcp 套接字（tcp://[host[:port]]），默认为 unix:///var/run/docker.sock；--icc=true|false：是否启用容器间以及跟 daemon 所在主机的通信。默认为 true。--insecure-registry=[]：允许访问给定的非安全仓库服务；--ip=&quot;&quot;：绑定容器端口时候的默认 IP 地址。缺省为 0.0.0.0；--ip-forward=true|false：是否检查启动在 Docker 主机上的启用 IP 转发服务，默认开启。注意关闭该选项将不对系统转发能力进行任何检查修改；--ip-masq=true|false：是否进行地址伪装，用于容器访问外部网络，默认开启；--iptables=true|false：是否允许 Docker 添加 iptables 规则。缺省为 true；--ipv6=true|false：是否启用 IPv6 支持，默认关闭；-l, --log-level=&quot;debug|info|warn|error|fatal&quot;：指定日志输出级别；--label=&quot;[]&quot;：添加指定的键值对标注；--log-driver=&quot;json-file|syslog|journald|gelf|fluentd|awslogs|splunk|etwlogs|gcplogs|none&quot;：指定日志后端驱动，默认为 json-file；--log-opt=[]：日志后端的选项；--mtu=VALUE：指定容器网络的 mtu；-p=&quot;&quot;：指定 daemon 的 PID 文件路径。缺省为 `/var/run/docker.pid`；--raw-logs：输出原始，未加色彩的日志信息；--registry-mirror=&lt;scheme&gt;://&lt;host&gt;：指定 `docker pull` 时使用的注册服务器镜像地址；-s, --storage-driver=&quot;&quot;：指定使用给定的存储后端；--selinux-enabled=true|false：是否启用 SELinux 支持。缺省值为 false。SELinux 目前尚不支持 overlay 存储驱动；--storage-opt=[]：驱动后端选项；--tls=true|false：是否对 Docker daemon 启用 TLS 安全机制，默认为否；--tlscacert= /.docker/ca.pem：TLS CA 签名的可信证书文件路径；--tlscert= /.docker/cert.pem：TLS 可信证书文件路径；--tlscert= /.docker/key.pem：TLS 密钥文件路径；--tlsverify=true|false：启用 TLS 校验，默认为否；--userland-proxy=true|false：是否使用用户态代理来实现容器间和出容器的回环通信，默认为 true；--userns-remap=default|uid:gid|user:group|user|uid：指定容器的用户命名空间，默认是创建新的 UID 和 GID 映射到容器内进程。 四、Dockerfile4.1 命令1docker build -t java:image . // 构建脚本 4.2 脚本12345678910111213FROM // 镜像来源COPY hom* /mydir/ // 复制hom开头的文件到mydir文件夹下面ADD file.gz /mydir // 增强复制功能，自动解压缩CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] // 分为shell命令和执行命令，容器启动命令，启动nginxENTRYPOINT // 入口点ENV // 设置环境变量ARG // 构建参数,设置的构建环境的环境变量VOLUME // 挂载匿名卷，用于数据持久化EXPOSE // 暴露端口WORKDIR // 指定工作目录USER // 指定当前用户HEALTHCHECK // 健康检查ONBUILD // 以当前镜像为基础镜像，去构建下一级镜像的时候才会被执行 五、docker-compose5.1 命令12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152build //构建（重新构建）项目中的服务容器 --force-rm //删除构建过程中的临时容器 --no-cache //构建镜像过程中不使用 cache（这将加长构建过程）。 --pull //始终尝试通过 pull 来获取更新版本的镜像。config //验证 Compose 文件格式是否正确，若正确则显示配置，若格式错误显示错误原因down //停止 up 命令所启动的容器，并移除网络exec //进入指定的容器help // 帮助images // 列出 Compose 文件中包含的镜像kill //格式为 docker-compose kill [options] [SERVICE...]。通过发送 SIGKILL 信号来强制停止服务容器。支持通过 -s 参数来指定发送的信号，例如通过如下指令发送 SIGINT 信号。logs // 查看服务容器的输出。默认情况下，docker-compose 将对不同的服务输出使用不同的颜色来区分。可以通过 --no-color 来关闭颜色pause // 暂停一个服务容器。port // 打印某个容器端口所映射的公共端口。 --protocol=proto //指定端口协议，tcp（默认值）或者 udp。 --index=index //如果同一服务存在多个容器，指定命令对象容器的序号（默认为 1）。ps //列出项目中目前的所有容器 -q 只打印容器的 ID 信息pull //拉取服务依赖的镜像 --ignore-pull-failures //忽略拉取镜像过程中的错误。push // 推送服务依赖的镜像到 Docker 镜像仓库restart // 重启项目中的服务 -t, --timeout TIMEOUT 指定重启前停止容器的超时（默认为 10 秒） rm // 删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器。 -f, --force 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。 -v 删除容器所挂载的数据卷。 run // 在指定服务上执行一个命令。docker-compose run ubuntu ping docker.com， 将会启动一个 ubuntu 服务容器，并执行 ping docker.com 命令 -d 后台运行容器。 --name NAME //为容器指定一个名字。 --entrypoint CMD //覆盖默认的容器启动指令。 -e KEY=VAL //设置环境变量值，可多次使用选项来设置多个环境变量。 -u, --user=&quot;&quot; //指定运行容器的用户名或者 uid。 --no-deps //不自动启动关联的服务容器。 --rm //运行命令后自动删除容器，d 模式下将忽略。 -p, --publish=[] //映射容器端口到本地主机。 --service-ports //配置服务端口并映射到本地主机。 -T //不分配伪 tty，意味着依赖 tty 的指令将无法运行。scale //设置指定服务运行的容器个数 docker-compose scale web=3 db=2 将启动 3 个容器运行 web 服务，2 个容器运行 db 服务 -t, --timeout TIMEOUT // 停止容器时候的超时（默认为 10 秒）start // 启动已经存在的服务容器up // 该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。默认情况，docker-compose up 启动的容器都在前台，控制台将会同时打印所有容器的输出信息，可以很方便进行调试。如果服务容器已经存在，docker-compose up 将会尝试停止容器，然后重新创建（保持使用 volumes-from 挂载的卷），以保证新启动的服务匹配 docker-compose.yml 文件的最新内容。如果用户不希望容器被停止并重新创建，可以使用 docker-compose up --no-recreate。这样将只会启动处于停止状态的容器，而忽略已经运行的服务。如果用户只想重新部署某个服务，可以使用 docker-compose up --no-deps -d &lt;SERVICE_NAME&gt; 来重新创建服务并后台停止旧服务，启动新服务，并不会影响到其所依赖的服务。 -d //在后台运行服务容器。 --no-color //不使用颜色来区分不同的服务的控制台输出。 --no-deps //不启动服务所链接的容器。 --force-recreate //强制重新创建容器，不能与 --no-recreate 同时使用。 --no-recreate //如果容器已经存在了，则不重新创建，不能与 --force-recreate 同时使用。 --no-build //不自动构建缺失的服务镜像。 -t, --timeout TIMEOUT //停止容器时候的超时（默认为 10 秒）。version // 打印版本信息。 stop // 停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器unpause // 恢复处于暂停状态中的服务。top // 查看各个服务容器内运行的进程。 5.2 脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100build // 指定 Dockerfile 所在文件夹的路径（可以是绝对路径，或者相对 docker-compose.yml 文件的路径）。 Compose 将会利用它自动构建这个镜像，然后使用这个镜像 context: dir //指定 Dockerfile 所在文件夹的路径 dockerfile: name // 指定 Dockerfile 文件名 arg: // 指令指定构建镜像时的变量 buildno: 1 // 变量buildno为1 cache_from：//指定构建镜像的缓存cap_add: // 指定容器的内核能力（capacity）分配 - ALL // 让容器拥有所有能力可以指定为cap_drop: // 去掉能力 - NET_ADMIN // 去掉NET_ADMIN command: echo &quot;hello world&quot; //覆盖容器启动后默认执行的命令 configs // 仅用于 Swarm modecgroup_parent // 指定父 cgroup 组，意味着将继承该组的资源限制.创建了一个 cgroup 组名称为 cgroups_1container_name: docker-web-container // 指定容器名称。默认将会使用 项目名称_服务名称_序号 这样的格式。deploy // 仅用于 Swarm modedevices: // 指定设备映射关系。 - &quot;/dev/ttyUSB1:/dev/ttyUSB0&quot; // 例子depends_on: // 解决容器的依赖、启动先后的问题。以下例子中会先启动 redis db 再启动 web - db // 先启动 redis - redis // 在启动 db，最后启动webdns: // 自定义 DNS 服务器。可以是一个值，也可以是一个列表 - 8.8.8.8 - 8.8.8.8 dns_search: // 配置 DNS 搜索域。可以是一个值，也可以是一个列表。 - domain1.example.com - domain2.example.comtmpfs: //挂载一个 tmpfs 文件系统到容器 - /run env_file: // 从文件中获取环境变量，可以为单独的文件路径或列表。如果通过 docker-compose -f FILE 方式来指定 Compose 模板文件，则 env_file 中变量的路径会基于模板文件路径。如果有变量名称与 environment 指令冲突，则按照惯例，以后者为准。 - ./common.envenvironment: // 设置环境变量。可以使用数组或字典两种格式。 RACK_ENV: development // 只给定名称的变量会自动获取运行 Compose 主机上对应变量的值，可以用来防止泄露不必要的数据 SESSION_SECRET: expose: // 暴露端口，但不映射到宿主机，只被连接的服务访问。 - &quot;3000&quot;external_links: // 不建议使用该指令.链接到 docker-compose.yml 外部的容器，甚至并非 Compose 管理的外部容器 extra_hosts: //类似 Docker 中的 --add-host 参数，指定额外的 host 名称映射信息 - &quot;googledns:8.8.8.8&quot; // 在/etc/hosts增加googledns:8.8.8.8文本healthcheck: // 通过命令检查容器是否健康运行。 test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost&quot;] interval: 1m30s timeout: 10s retries: 3image: ubuntu // 指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像labels: // 为容器添加 Docker 元数据（metadata）信息。例如可以为容器添加辅助说明信息。 com.startupteam.description: &quot;webapp for a startup team&quot; com.startupteam.department: &quot;devops department&quot; com.startupteam.release: &quot;rc3 for v1.0&quot;logging: // 配置日志选项 driver: syslog // 目前支持三种日志驱动类型&quot;json-file&quot;, &quot;syslog&quot;, &quot;none&quot; options: syslog-address: &quot;tcp://192.168.0.42:123&quot; max-size: &quot;200k&quot; max-file: &quot;10&quot; network_mode: &quot;bridge&quot; // 设置网络模式。使用和 docker run 的 --network 参数一样的值network_mode: &quot;host&quot;network_mode: &quot;none&quot;network_mode: &quot;service:[service name]&quot;network_mode: &quot;container:[container name/id]&quot; ports: // 暴露端口信息。使用宿主端口：容器端口 &amp;#40;HOST:CONTAINER&amp;#41; 格式，或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。 - &quot;3000&quot; // 当使用 HOST:CONTAINER 格式来映射端口时，如果你使用的容器端口小于 60 并且没放到引号里，可能会得到错误结果，因为 YAML 会自动解析 xx:yy 这种数字格式为 60 进制。为避免出现这种问题，建议数字串都采用引号包括起来的字符串格式。 - &quot;8000:8000&quot; - &quot;49100:22&quot; - &quot;127.0.0.1:8001:8001&quot; secrets: // 存储敏感数据，例如 mysql 服务密码 my_secret: file: ./my_secret.txt my_other_secret: external: truesecurity_opt: // 指定容器模板标签（label）机制的默认属性（用户、角色、类型、级别等）。例如配置标签的用户名和角色名。 - label:user:USER - label:role:ROLE stop_signal: SIGUSR1 // 设置另一个信号来停止容器。在默认情况下使用的是 SIGTERM 停止容器。sysctls: //配置容器内核参数 net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0sysctls: - net.core.somaxconn=1024 - net.ipv4.tcp_syncookies=0ulimits: // 指定容器的 ulimits 限制值。 nproc: 65535 //指定最大进程数为 65535，指定文件句柄数为 20000（软限制，应用可以随时修改，不能超过硬限制） 和 40000（系统硬限制，只能 root 用户提高）。 nofile: soft: 20000 hard: 40000 volumes: // 数据卷所挂载路径设置。可以设置宿主机路径 （HOST:CONTAINER） 或加上访问模式 - /var/lib/mysql - cache/:/tmp/cache - ~/configs:/etc/configs/:ro entrypoint: /code/entrypoint.sh // 指定服务容器启动后执行的入口文件user: nginx // 指定容器中运行应用的用户名。working_dir: /code // 指定容器中工作目录。domainname: your_website.com // 指定容器中搜索域名hostname: test // 指定容器中主机名mac_address: 08-00-27-00-0C-0A // 指定容器中mac 地址privileged: true // 允许容器中运行一些特权命令。restart: always // 指定容器退出后的重启策略为始终重启。该命令对保持服务始终运行十分有效，在生产环境中推荐配置为 always 或者 unless-stopped。read_only: true // 以只读模式挂载容器的 root 文件系统，意味着不能对容器内容进行修改。stdin_open: true // 打开标准输入，可以接受外部输入。tty: true // 模拟一个伪终端。$&amp;#123;MONGO_VERSION&amp;#125; // Compose 模板文件支持动态读取主机的系统环境变量和当前目录下的 .env 文件中的变量。 MONGO_VERSION=3.6]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Dockerfile docker-compose docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac常用命令]]></title>
    <url>%2Fother%2Fmac_command.html</url>
    <content type="text"><![CDATA[常用12345678910111213141516lsof -i:8886 // 查看端口号opne . // 打开终端下的目录touch aaa // 在当前目录下创建一个aaa名字的文件diskutil list // 查看磁盘分区表// 在当前文件夹以及当前文件夹的子文件夹中找到所有的.DS_Store文件，并将找到的文件通过管道传给xargs来处理。find . -name .DS_Store -print0 | xargs -0 git rm -f --ignore-unmatch// 批量删除同名文件sudo find &quot;需要删除的目录&quot; -name &quot;.DS_Store&quot; -depth -exec rm &#123;&#125; \;// 查看路由表netstat -rn// 增加路由sudo route -n add -host 192.168.1.0 192.168.1.0// 删除路由sudo route -v delete -net 172.0.53.1 -gateway 172.0.53.1// 下载brew/bin/zsh -c &quot;$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/Homebrew.sh)&quot; git1234// 清除git信息sudo git config --system --unset credential.helper// 重新生成git的id_rsa.pub, 之后一直enter，设置密码即可ssh-keygen -t rsa -b 4096 -C &apos;yourmail@qq.com&apos; iterm21234567891011121314151617181920212223command + t //新建标签command + w //关闭标签command + 数字 / command + 左右方向键 //切换标签command + enter //切换全屏command + f //查找command + d //垂直分屏command + shift + d //水平分屏command + ; //查看历史命令command + shift + h //查看剪贴板历史ctrl + u //清除当前行ctrl + l / command + r //清屏ctrl + a //到行首ctrl + e //到行尾ctrl + f/b //前进后退 (相当于左右方向键)ctrl + p //上一条命令ctrl + r //搜索命令历史ctrl + d //删除当前光标的字符ctrl + h //删除光标之前的字符ctrl + w //删除光标之前的单词ctrl + k //删除到文本末尾ctrl + t //交换光标处文本Command + / //查看当前终端中光标的位置command+f + tab // 选中即复制 tree12345678910111213141516171819202122-a 显示所有文件和目录。-A 使用ASNI绘图字符显示树状图而非以ASCII字符组合。-C 在文件和目录清单加上色彩，便于区分各种类型。-d 显示目录名称而非内容。-D 列出文件或目录的更改时间。-f 在每个文件或目录之前，显示完整的相对路径名称。-F 在执行文件，目录，Socket，符号连接，管道名称名称，各自加上&quot;*&quot;,&quot;/&quot;,&quot;=&quot;,&quot;@&quot;,&quot;|&quot;号。-g 列出文件或目录的所属群组名称，没有对应的名称时，则显示群组识别码。-i 不以阶梯状列出文件或目录名称。-I 不显示符合范本样式的文件或目录名称。-l 如遇到性质为符号连接的目录，直接列出该连接所指向的原始目录。-n 不在文件和目录清单加上色彩。-N 直接列出文件和目录名称，包括控制字符。-p 列出权限标示。-P 只显示符合范本样式的文件或目录名称。-q 用&quot;?&quot;号取代控制字符，列出文件和目录名称。-s 列出文件或目录大小。-t 用文件和目录的更改时间排序。-u 列出文件或目录的拥有者名称，没有对应的名称时，则显示用户识别码。-x 将范围局限在现行的文件系统中，若指定目录下的某些子目录，其存放于另一个文件系统上，则将该子目录予以排除在寻找范围外。tree -L 1 // 显示一层目录结构]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[私有仓库创建]]></title>
    <url>%2Flinux%2Fgtilab.html</url>
    <content type="text"><![CDATA[Gitlab私有代码存储仓库创建123456789101112131415161718192021version: &apos;3&apos;services: web: image: &apos;twang2218/gitlab-ce-zh:10.5&apos; restart: always hostname: &apos;192.168.75.145&apos; environment: TZ: &apos;Asia/Shanghai&apos; GITLAB_OMNIBUS_CONFIG: | external_url &apos;http://192.168.75.145:8080&apos; gitlab_rails[&apos;gitlab_shell_ssh_port&apos;] = 2222 unicorn[&apos;port&apos;] = 8888 nginx[&apos;listen_port&apos;] = 8080 ports: - &apos;8080:8080&apos; - &apos;8443:443&apos; - &apos;2222:22&apos; volumes: - /usr/local/docker/gitlab/config:/etc/gitlab - /usr/local/docker/gitlab/data:/var/opt/gitlab - /usr/local/docker/gitlab/logs:/var/log/gitlab 访问1http://ip:8080 Maven私有仓库创建12345678910version: &apos;3.1&apos;services: nexus: restart: always image: sonatype/nexus3 container_name: nexus ports: - 8081:8081 volumes: - /usr/local/docker/nexus/data:/nexus-data 访问1http://ip:port/ 用户名：admin 密码：admin123 Docker私有镜像仓库创建1234567891011121314151617181920212223version: &apos;3.1&apos;services: registry: image: registry restart: always container_name: registry ports: - 5000:5000 volumes: - /usr/local/docker/registry/data:/var/lib/registry# Registry WebUI 工具 version: &apos;3.1&apos;services: frontend: image: konradkleine/docker-registry-frontend:v2 ports: - 8080:80 volumes: - ./certs/frontend.crt:/etc/apache2/server.crt:ro - ./certs/frontend.key:/etc/apache2/server.key:ro environment: - ENV_DOCKER_REGISTRY_HOST=192.168.75.133 - ENV_DOCKER_REGISTRY_PORT=5000 访问12345678910// 访问http://ip:5000/v2/，http://ip:5000// 在/etc/docker/daemon.json中新增&#123; &quot;registry-mirrors&quot;: [ &quot;https://registry.docker-cn.com&quot; ], &quot;insecure-registries&quot;: [ &quot;ip:5000&quot; ]&#125; 访问 重启12sudo systemctl daemon-reloadsudo systemctl restart docker]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在线工具收藏]]></title>
    <url>%2Fother%2Fonline_utils.html</url>
    <content type="text"><![CDATA[在线工具 爱信息图床 图片素材 熊猫图片压缩 图片压缩 json在线 jquery插件 Java 1.6 JDK IP查询 图片合并 ascii字体 应用评测 思维导图 代码对比 在线视频转换 在线资源 字体图标 CDN加速 maven资源 网站UI jar下载 css动画 在线海报 天气API PDF转换 ascii生成推荐 网址缩短 在线画图 程序下载 asciiworld 在线文档 正则手册 jqGrid文档 docker gitbooks freemarker文档 jquery文档 docker文档 git文档 spring Cloud 中文 dubbo文档 开源镜像 北京理工大学 阿里巴巴 开源社 docker 在线书籍 大话设计模式 鸟哥的私房菜 Elasticsearch权威指南 并发程序设计 zooKeeper 学习网站 自强学堂 mrbird 各种手册 java指南 菜鸟教程 vue视频 java进阶 其他 医疗手册 google论坛 zoomeye 源代码 google趋势 百度流量研究院]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>utils</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux常用命令]]></title>
    <url>%2Flinux%2Fcommand.html</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122du -h // 查看当前文件夹的占用大小df -h // 查看当前文件下所有的文件的大小free -h // 查看磁盘使用情况 swap(交换空间：防止服务器出现内存溢出时无法操作系统。云服务器没有交换空间)netstat -al // 显示网络状态信息netstat -ltunp // 查看当前启动的服务ps -A // 显示所有的进程ps -ef|grep tomcat // 查看tomcat的端口passwd // 重置密码reboot // 重启（root用户才有权限）sudo // 临时获取root权限tar -czvf file.tar.gz . // 压缩当前文件夹tar -xzvf file.tar.gz // 解压缩文件apt-get // ubuntu软件包管理 在/etc/apt/source.list可以更改数据源 apt-get update让数据源生效lsb_release -a // 查看系统版本// 查看文件， 不会加载整个文件 `/`向下搜索，`?`向上搜索文件 n重复前一个搜索less// 分页显示test.log日志里面包含debug的日志cat -n test.log |grep &quot;debug&quot; |less// 分页查看压缩包里面的文件zcat -n app* |grep &quot;debug&quot; |less// 查找当前目录下面文本中的内容grep -rn &quot;京ICP备12049100号&quot; * 常用工具1htop 查看内存工具 系统信息123456789101112131415161718192021arch 显示机器的处理器架构(1) uname -m 显示机器的处理器架构(2) uname -r 显示正在使用的内核版本 dmidecode -q 显示硬件系统部件 - (SMBIOS / DMI) hdparm -i /dev/hda 罗列一个磁盘的架构特性 hdparm -tT /dev/sda 在磁盘上执行测试性读取操作 cat /proc/cpuinfo 显示CPU info的信息 cat /proc/interrupts 显示中断 cat /proc/meminfo 校验内存使用 cat /proc/swaps 显示哪些swap被使用 cat /proc/version 显示内核的版本 cat /proc/net/dev 显示网络适配器及统计 cat /proc/mounts 显示已加载的文件系统 lspci -tv 罗列 PCI 设备 lsusb -tv 显示 USB 设备 date 显示系统日期 cal 2007 显示2007年的日历表 date 041217002007.00 设置日期和时间 - 月日时分年.秒 clock -w 将时间修改保存到 BIOS yum install gcc gcc-c++ 安装gcc和g++（centos下） 关机 (系统的关机、重启以及登出 )12345678shutdown -h now 关闭系统(1) init 0 关闭系统(2) telinit 0 关闭系统(3) shutdown -h hours:minutes &amp; 按预定时间关闭系统 shutdown -c 取消按预定时间关闭系统 shutdown -r now 重启(1) reboot 重启(2) logout 注销 文件和目录123456789101112131415161718192021222324252627282930313233cd /home 进入 &apos;/ home&apos; 目录&apos; cd .. 返回上一级目录 cd ../.. 返回上两级目录 cd 进入个人的主目录 cd ~user1 进入个人的主目录 cd - 返回上次所在的目录 pwd 显示工作路径 ls 查看目录中的文件 ls -F 查看目录中的文件 ls -l 显示文件和目录的详细资料 ls -a 显示隐藏文件 ls *[0-9]* 显示包含数字的文件名和目录名 tree 显示文件和目录由根目录开始的树形结构(1) lstree 显示文件和目录由根目录开始的树形结构(2) mkdir dir1 创建一个叫做 &apos;dir1&apos; 的目录&apos; mkdir dir1 dir2 同时创建两个目录 mkdir -p /tmp/dir1/dir2 创建一个目录树 rm -f file1 删除一个叫做 &apos;file1&apos; 的文件&apos; rmdir dir1 删除一个叫做 &apos;dir1&apos; 的目录&apos; rm -rf dir1 删除一个叫做 &apos;dir1&apos; 的目录并同时删除其内容 rm -rf dir1 dir2 同时删除两个目录及它们的内容 mv dir1 new_dir 重命名/移动 一个目录 cp file1 file2 复制一个文件 cp dir/* . 复制一个目录下的所有文件到当前工作目录 cp -a /tmp/dir1 . 复制一个目录到当前工作目录 cp -a dir1 dir2 复制一个目录 ln -s file1 lnk1 创建一个指向文件或目录的软链接 ln file1 lnk1 创建一个指向文件或目录的物理链接 touch -t 0712250000 file1 修改一个文件或目录的时间戳 - (YYMMDDhhmm) file file1 outputs the mime type of the file as text iconv -l 列出已知的编码 iconv -f fromEncoding -t toEncoding inputFile &gt; outputFile creates a new from the given input file by assuming it is encoded in fromEncoding and converting it to toEncoding. find . -maxdepth 1 -name *.jpg -print -exec convert &quot;&#123;&#125;&quot; -resize 80x60 &quot;thumbs/&#123;&#125;&quot; \; batch resize files in the current directory and send them to a thumbnails directory (requires convert from Imagemagick) 文件搜索12345678910find / -name file1 从 &apos;/&apos; 开始进入根文件系统搜索文件和目录 find / -user user1 搜索属于用户 &apos;user1&apos; 的文件和目录 find /home/user1 -name \*.bin 在目录 &apos;/ home/user1&apos; 中搜索带有&apos;.bin&apos; 结尾的文件 find /usr/bin -type f -atime +100 搜索在过去100天内未被使用过的执行文件 find /usr/bin -type f -mtime -10 搜索在10天内被创建或者修改过的文件 find / -name \*.rpm -exec chmod 755 &apos;&#123;&#125;&apos; \; 搜索以 &apos;.rpm&apos; 结尾的文件并定义其权限 find / -xdev -name \*.rpm 搜索以 &apos;.rpm&apos; 结尾的文件，忽略光驱、捷盘等可移动设备 locate \*.ps 寻找以 &apos;.ps&apos; 结尾的文件 - 先运行 &apos;updatedb&apos; 命令 whereis halt 显示一个二进制文件、源码或man的位置 which halt 显示一个二进制文件或可执行文件的完整路径 挂载一个文件系统123456789101112mount /dev/hda2 /mnt/hda2 挂载一个叫做hda2的盘 - 确定目录 &apos;/ mnt/hda2&apos; 已经存在 umount /dev/hda2 卸载一个叫做hda2的盘 - 先从挂载点 &apos;/ mnt/hda2&apos; 退出 fuser -km /mnt/hda2 当设备繁忙时强制卸载 umount -n /mnt/hda2 运行卸载操作而不写入 /etc/mtab 文件- 当文件为只读或当磁盘写满时非常有用 mount /dev/fd0 /mnt/floppy 挂载一个软盘 mount /dev/cdrom /mnt/cdrom 挂载一个cdrom或dvdrom mount /dev/hdc /mnt/cdrecorder 挂载一个cdrw或dvdrom mount /dev/hdb /mnt/cdrecorder 挂载一个cdrw或dvdrom mount -o loop file.iso /mnt/cdrom 挂载一个文件或ISO镜像文件 mount -t vfat /dev/hda5 /mnt/hda5 挂载一个Windows FAT32文件系统 mount /dev/sda1 /mnt/usbdisk 挂载一个usb 捷盘或闪存设备 mount -t smbfs -o username=user,password=pass //WinClient/share /mnt/share 挂载一个windows网络共享 磁盘空间123456df -h 显示已经挂载的分区列表 ls -lSr |more 以尺寸大小排列文件和目录 du -sh dir1 估算目录 &apos;dir1&apos; 已经使用的磁盘空间&apos; du -sk * | sort -rn 以容量大小为依据依次显示文件和目录的大小 rpm -q -a --qf &apos;%10&#123;SIZE&#125;t%&#123;NAME&#125;n&apos; | sort -k1,1n 以大小为依据依次显示已安装的rpm包所使用的空间 (fedora, redhat类系统) dpkg-query -W -f=&apos;$&#123;Installed-Size;10&#125;t$&#123;Package&#125;n&apos; | sort -k1,1n 以大小为依据显示已安装的deb包所使用的空间 (ubuntu, debian类系统) 用户和群组12345678910111213groupadd group_name 创建一个新用户组 groupdel group_name 删除一个用户组 groupmod -n new_group_name old_group_name 重命名一个用户组 useradd -c &quot;Name Surname &quot; -g admin -d /home/user1 -s /bin/bash user1 创建一个属于 &quot;admin&quot; 用户组的用户 useradd user1 创建一个新用户 userdel -r user1 删除一个用户 ( &apos;-r&apos; 排除主目录) usermod -c &quot;User FTP&quot; -g system -d /ftp/user1 -s /bin/nologin user1 修改用户属性 passwd 修改口令 passwd user1 修改一个用户的口令 (只允许root执行) chage -E 2005-12-31 user1 设置用户口令的失效期限 pwck 检查 &apos;/etc/passwd&apos; 的文件格式和语法修正以及存在的用户 grpck 检查 &apos;/etc/passwd&apos; 的文件格式和语法修正以及存在的群组 newgrp group_name 登陆进一个新的群组以改变新创建文件的预设群组 文件的权限12345678910111213141516 - 使用 &quot;+&quot; 设置权限，使用 &quot;-&quot; 用于取消 ls -lh 显示权限 ls /tmp | pr -T5 -W$COLUMNS 将终端划分成5栏显示 chmod ugo+rwx directory1 设置目录的所有人(u)、群组(g)以及其他人(o)以读（r ）、写(w)和执行(x)的权限 chmod go-rwx directory1 删除群组(g)与其他人(o)对目录的读写执行权限 chown user1 file1 改变一个文件的所有人属性 chown -R user1 directory1 改变一个目录的所有人属性并同时改变改目录下所有文件的属性 chgrp group1 file1 改变文件的群组 chown user1:group1 file1 改变一个文件的所有人和群组属性 find / -perm -u+s 罗列一个系统中所有使用了SUID控制的文件 chmod u+s /bin/file1 设置一个二进制文件的 SUID 位 - 运行该文件的用户也被赋予和所有者同样的权限 chmod u-s /bin/file1 禁用一个二进制文件的 SUID位 chmod g+s /home/public 设置一个目录的SGID 位 - 类似SUID ，不过这是针对目录的 chmod g-s /home/public 禁用一个目录的 SGID 位 chmod o+t /home/public 设置一个文件的 STIKY 位 - 只允许合法所有人删除文件 chmod o-t /home/public 禁用一个目录的 STIKY 位 文件的特殊属性123456789- 使用 &quot;+&quot; 设置权限，使用 &quot;-&quot; 用于取消 chattr +a file1 只允许以追加方式读写文件 chattr +c file1 允许这个文件能被内核自动压缩/解压 chattr +d file1 在进行文件系统备份时，dump程序将忽略这个文件 chattr +i file1 设置成不可变的文件，不能被删除、修改、重命名或者链接 chattr +s file1 允许一个文件被安全地删除 chattr +S file1 一旦应用程序对这个文件执行了写操作，使系统立刻把修改的结果写到磁盘 chattr +u file1 若文件被删除，系统会允许你在以后恢复这个被删除的文件 lsattr 显示特殊的属性 打包和压缩文件1234567891011121314151617181920212223压缩当前的文件夹 zip -r ./xahot.zip ./* -r表示递归bunzip2 file1.bz2 解压一个叫做 &apos;file1.bz2&apos;的文件 bzip2 file1 压缩一个叫做 &apos;file1&apos; 的文件 gunzip file1.gz 解压一个叫做 &apos;file1.gz&apos;的文件 gzip file1 压缩一个叫做 &apos;file1&apos;的文件 gzip -9 file1 最大程度压缩 rar a file1.rar test_file 创建一个叫做 &apos;file1.rar&apos; 的包 rar a file1.rar file1 file2 dir1 同时压缩 &apos;file1&apos;, &apos;file2&apos; 以及目录 &apos;dir1&apos; rar x file1.rar 解压rar包 unrar x file1.rar 解压rar包 tar -cvf archive.tar file1 创建一个非压缩的 tarball tar -cvf archive.tar file1 file2 dir1 创建一个包含了 &apos;file1&apos;, &apos;file2&apos; 以及 &apos;dir1&apos;的档案文件 tar -tf archive.tar 显示一个包中的内容 tar -xvf archive.tar 释放一个包 tar -xvf archive.tar -C /tmp 将压缩包释放到 /tmp目录下 tar -cvfj archive.tar.bz2 dir1 创建一个bzip2格式的压缩包 tar -xvfj archive.tar.bz2 解压一个bzip2格式的压缩包 tar -cvfz archive.tar.gz dir1 创建一个gzip格式的压缩包 tar -xvf archive.tar.gz 解压一个gzip格式的压缩包 zip file1.zip file1 创建一个zip格式的压缩包 zip -r file1.zip file1 file2 dir1 将几个文件和目录同时压缩成一个zip格式的压缩包 unzip file1.zip 解压一个zip格式压缩包 rpm12345678910111213141516171819202122232425262728RPM 包 - （Fedora, Redhat及类似系统） rpm -ivh package.rpm 安装一个rpm包 rpm -ivh --nodeeps package.rpm 安装一个rpm包而忽略依赖关系警告 rpm -U package.rpm 更新一个rpm包但不改变其配置文件 rpm -F package.rpm 更新一个确定已经安装的rpm包 rpm -e package_name.rpm 删除一个rpm包 rpm -qa 显示系统中所有已经安装的rpm包 rpm -qa | grep httpd 显示所有名称中包含 &quot;httpd&quot; 字样的rpm包 rpm -qi package_name 获取一个已安装包的特殊信息 rpm -qg &quot;System Environment/Daemons&quot; 显示一个组件的rpm包 rpm -ql package_name 显示一个已经安装的rpm包提供的文件列表 rpm -qc package_name 显示一个已经安装的rpm包提供的配置文件列表 rpm -q package_name --whatrequires 显示与一个rpm包存在依赖关系的列表 rpm -q package_name --whatprovides 显示一个rpm包所占的体积 rpm -q package_name --scripts 显示在安装/删除期间所执行的脚本l rpm -q package_name --changelog 显示一个rpm包的修改历史 rpm -qf /etc/httpd/conf/httpd.conf 确认所给的文件由哪个rpm包所提供 rpm -qp package.rpm -l 显示由一个尚未安装的rpm包提供的文件列表 rpm --import /media/cdrom/RPM-GPG-KEY 导入公钥数字证书 rpm --checksig package.rpm 确认一个rpm包的完整性 rpm -qa gpg-pubkey 确认已安装的所有rpm包的完整性 rpm -V package_name 检查文件尺寸、 许可、类型、所有者、群组、MD5检查以及最后修改时间 rpm -Va 检查系统中所有已安装的rpm包- 小心使用 rpm -Vp package.rpm 确认一个rpm包还未安装 rpm2cpio package.rpm | cpio --extract --make-directories *bin* 从一个rpm包运行可执行文件 rpm -ivh /usr/src/redhat/RPMS/`arch`/package.rpm 从一个rpm源码安装一个构建好的包 rpmbuild --rebuild package_name.src.rpm 从一个rpm源码构建一个 rpm 包 YUM123456789101112YUM 软件包升级器 - （Fedora, RedHat及类似系统） yum install package_name 下载并安装一个rpm包 yum localinstall package_name.rpm 将安装一个rpm包，使用你自己的软件仓库为你解决所有依赖关系 yum update package_name.rpm 更新当前系统中所有安装的rpm包 yum update package_name 更新一个rpm包 yum remove package_name 删除一个rpm包 yum list 列出当前系统中安装的所有包 yum search package_name 在rpm仓库中搜寻软件包 yum clean packages 清理rpm缓存删除下载的包 yum clean headers 删除所有头文件 yum clean all 删除所有缓存的包和头文件 dpkg12345678910DEB 包 (Debian, Ubuntu 以及类似系统) dpkg -i package.deb 安装/更新一个 deb 包 dpkg -r package_name 从系统删除一个 deb 包 dpkg -l 显示系统中所有已经安装的 deb 包 dpkg -l | grep httpd 显示所有名称中包含 &quot;httpd&quot; 字样的deb包 dpkg -s package_name 获得已经安装在系统中一个特殊包的信息 dpkg -L package_name 显示系统中已经安装的一个deb包所提供的文件列表 dpkg --contents package.deb 显示尚未安装的一个包所提供的文件列表 dpkg -S /bin/ping 确认所给的文件由哪个deb包提供 apt-get12345678910APT 软件工具 (Debian, Ubuntu 以及类似系统) apt-get install package_name 安装/更新一个 deb 包 apt-cdrom install package_name 从光盘安装/更新一个 deb 包 apt-get update 升级列表中的软件包 apt-get upgrade 升级所有已安装的软件 apt-get remove package_name 从系统删除一个deb包 apt-get check 确认依赖的软件仓库正确 apt-get clean 从下载的软件包中清理缓存 apt-cache search searched-package 返回包含所要搜索字符串的软件包名称 查看文件内容1234567cat file1 从第一个字节开始正向查看文件的内容 tac file1 从最后一行开始反向查看一个文件的内容 more file1 查看一个长文件的内容 less file1 类似于 &apos;more&apos; 命令，但是它允许在文件中和正向操作一样的反向操作 head -2 file1 查看一个文件的前两行 tail -2 file1 查看一个文件的最后两行 tail -f /var/log/messages 实时查看被添加到一个文件中的内容 文本处理12345678910111213141516171819202122232425262728293031cat file1 file2 ... | command &lt;&gt; file1_in.txt_or_file1_out.txt general syntax for text manipulation using PIPE, STDIN and STDOUT cat file1 | command( sed, grep, awk, grep, etc...) &gt; result.txt 合并一个文件的详细说明文本，并将简介写入一个新文件中 cat file1 | command( sed, grep, awk, grep, etc...) &gt;&gt; result.txt 合并一个文件的详细说明文本，并将简介写入一个已有的文件中 grep Aug /var/log/messages 在文件 &apos;/var/log/messages&apos;中查找关键词&quot;Aug&quot; grep ^Aug /var/log/messages 在文件 &apos;/var/log/messages&apos;中查找以&quot;Aug&quot;开始的词汇 grep [0-9] /var/log/messages 选择 &apos;/var/log/messages&apos; 文件中所有包含数字的行 grep Aug -R /var/log/* 在目录 &apos;/var/log&apos; 及随后的目录中搜索字符串&quot;Aug&quot; sed &apos;s/stringa1/stringa2/g&apos; example.txt 将example.txt文件中的 &quot;string1&quot; 替换成 &quot;string2&quot; sed &apos;/^$/d&apos; example.txt 从example.txt文件中删除所有空白行 sed &apos;/ *#/d; /^$/d&apos; example.txt 从example.txt文件中删除所有注释和空白行 echo &apos;esempio&apos; | tr &apos;[:lower:]&apos; &apos;[:upper:]&apos; 合并上下单元格内容 sed -e &apos;1d&apos; result.txt 从文件example.txt 中排除第一行 sed -n &apos;/stringa1/p&apos; 查看只包含词汇 &quot;string1&quot;的行 sed -e &apos;s/ *$//&apos; example.txt 删除每一行最后的空白字符 sed -e &apos;s/stringa1//g&apos; example.txt 从文档中只删除词汇 &quot;string1&quot; 并保留剩余全部 sed -n &apos;1,5p;5q&apos; example.txt 查看从第一行到第5行内容 sed -n &apos;5p;5q&apos; example.txt 查看第5行 sed -e &apos;s/00*/0/g&apos; example.txt 用单个零替换多个零 cat -n file1 标示文件的行数 cat example.txt | awk &apos;NR%2==1&apos; 删除example.txt文件中的所有偶数行 echo a b c | awk &apos;&#123;print $1&#125;&apos; 查看一行第一栏 echo a b c | awk &apos;&#123;print $1,$3&#125;&apos; 查看一行的第一和第三栏 paste file1 file2 合并两个文件或两栏的内容 paste -d &apos;+&apos; file1 file2 合并两个文件或两栏的内容，中间用&quot;+&quot;区分 sort file1 file2 排序两个文件的内容 sort file1 file2 | uniq 取出两个文件的并集(重复的行只保留一份) sort file1 file2 | uniq -u 删除交集，留下其他的行 sort file1 file2 | uniq -d 取出两个文件的交集(只留下同时存在于两个文件中的文件) comm -1 file1 file2 比较两个文件的内容只删除 &apos;file1&apos; 所包含的内容 comm -2 file1 file2 比较两个文件的内容只删除 &apos;file2&apos; 所包含的内容 comm -3 file1 file2 比较两个文件的内容只删除两个文件共有的部分 字符设置和文件格式转换1234dos2unix filedos.txt fileunix.txt 将一个文本文件的格式从MSDOS转换成UNIX unix2dos fileunix.txt filedos.txt 将一个文本文件的格式从UNIX转换成MSDOS recode ..HTML &lt; page.txt &gt; page.html 将一个文本文件转换成html recode -l | more 显示所有允许的转换格式 文件系统分析123456789badblocks -v /dev/hda1 检查磁盘hda1上的坏磁块 fsck /dev/hda1 修复/检查hda1磁盘上linux文件系统的完整性 fsck.ext2 /dev/hda1 修复/检查hda1磁盘上ext2文件系统的完整性 e2fsck /dev/hda1 修复/检查hda1磁盘上ext2文件系统的完整性 e2fsck -j /dev/hda1 修复/检查hda1磁盘上ext3文件系统的完整性 fsck.ext3 /dev/hda1 修复/检查hda1磁盘上ext3文件系统的完整性 fsck.vfat /dev/hda1 修复/检查hda1磁盘上fat文件系统的完整性 fsck.msdos /dev/hda1 修复/检查hda1磁盘上dos文件系统的完整性 dosfsck /dev/hda1 修复/检查hda1磁盘上dos文件系统的完整性 初始化一个文件系统123456mkfs /dev/hda1 在hda1分区创建一个文件系统 mke2fs /dev/hda1 在hda1分区创建一个linux ext2的文件系统 mke2fs -j /dev/hda1 在hda1分区创建一个linux ext3(日志型)的文件系统 mkfs -t vfat 32 -F /dev/hda1 创建一个 FAT32 文件系统 fdformat -n /dev/fd0 格式化一个软盘 mkswap /dev/hda3 创建一个swap文件系统 SWAP文件系统123mkswap /dev/hda3 创建一个swap文件系统 swapon /dev/hda3 启用一个新的swap文件系统 swapon /dev/hda2 /dev/hdb3 启用两个swap分区 备份1234567891011121314151617dump -0aj -f /tmp/home0.bak /home 制作一个 &apos;/home&apos; 目录的完整备份 dump -1aj -f /tmp/home0.bak /home 制作一个 &apos;/home&apos; 目录的交互式备份 restore -if /tmp/home0.bak 还原一个交互式备份 rsync -rogpav --delete /home /tmp 同步两边的目录 rsync -rogpav -e ssh --delete /home ip_address:/tmp 通过SSH通道rsync rsync -az -e ssh --delete ip_addr:/home/public /home/local 通过ssh和压缩将一个远程目录同步到本地目录 rsync -az -e ssh --delete /home/local ip_addr:/home/public 通过ssh和压缩将本地目录同步到远程目录 dd bs=1M if=/dev/hda | gzip | ssh user@ip_addr &apos;dd of=hda.gz&apos; 通过ssh在远程主机上执行一次备份本地磁盘的操作 dd if=/dev/sda of=/tmp/file1 备份磁盘内容到一个文件 tar -Puf backup.tar /home/user 执行一次对 &apos;/home/user&apos; 目录的交互式备份操作 ( cd /tmp/local/ &amp;&amp; tar c . ) | ssh -C user@ip_addr &apos;cd /home/share/ &amp;&amp; tar x -p&apos; 通过ssh在远程目录中复制一个目录内容 ( tar c /home ) | ssh -C user@ip_addr &apos;cd /home/backup-home &amp;&amp; tar x -p&apos; 通过ssh在远程目录中复制一个本地目录 tar cf - . | (cd /tmp/backup ; tar xf - ) 本地将一个目录复制到另一个地方，保留原有权限及链接 find /home/user1 -name &apos;*.txt&apos; | xargs cp -av --target-directory=/home/backup/ --parents 从一个目录查找并复制所有以 &apos;.txt&apos; 结尾的文件到另一个目录 find /var/log -name &apos;*.log&apos; | tar cv --files-from=- | bzip2 &gt; log.tar.bz2 查找所有以 &apos;.log&apos; 结尾的文件并做成一个bzip包 dd if=/dev/hda of=/dev/fd0 bs=512 count=1 做一个将 MBR (Master Boot Record)内容复制到软盘的动作 dd if=/dev/fd0 of=/dev/hda bs=512 count=1 从已经保存到软盘的备份中恢复MBR内容 光盘123456789101112 cdrecord -v gracetime=2 dev=/dev/cdrom -eject blank=fast -force 清空一个可复写的光盘内容 mkisofs /dev/cdrom &gt; cd.iso 在磁盘上创建一个光盘的iso镜像文件 mkisofs /dev/cdrom | gzip &gt; cd_iso.gz 在磁盘上创建一个压缩了的光盘iso镜像文件 mkisofs -J -allow-leading-dots -R -V &quot;Label CD&quot; -iso-level 4 -o ./cd.iso data_cd 创建一个目录的iso镜像文件 cdrecord -v dev=/dev/cdrom cd.iso 刻录一个ISO镜像文件 gzip -dc cd_iso.gz | cdrecord dev=/dev/cdrom - 刻录一个压缩了的ISO镜像文件 mount -o loop cd.iso /mnt/iso 挂载一个ISO镜像文件 cd-paranoia -B 从一个CD光盘转录音轨到 wav 文件中 cd-paranoia -- &quot;-3&quot; 从一个CD光盘转录音轨到 wav 文件中（参数-3） cdrecord --scanbus 扫描总线以识别scsi通道 dd if=/dev/hdc | md5sum 校验一个设备的md5sum编码，例如一张 CD 网络123456789101112131415161718192021222324252627- （以太网和WIFI无线） ifconfig eth0 显示一个以太网卡的配置 ifup eth0 启用一个 &apos;eth0&apos; 网络设备 ifdown eth0 禁用一个 &apos;eth0&apos; 网络设备 ifconfig eth0 192.168.1.1 netmask 255.255.255.0 控制IP地址 ifconfig eth0 promisc 设置 &apos;eth0&apos; 成混杂模式以嗅探数据包 (sniffing) dhclient eth0 以dhcp模式启用 &apos;eth0&apos; route -n show routing table route add -net 0/0 gw IP_Gateway configura default gateway route add -net 192.168.0.0 netmask 255.255.0.0 gw 192.168.1.1 configure static route to reach network &apos;192.168.0.0/16&apos; route del 0/0 gw IP_gateway remove static route echo &quot;1&quot; &gt; /proc/sys/net/ipv4/ip_forward activate ip routing hostname show hostname of system host www.example.com lookup hostname to resolve name to ip address and viceversa(1) nslookup www.example.com lookup hostname to resolve name to ip address and viceversa(2) ip link show show link status of all interfaces mii-tool eth0 show link status of &apos;eth0&apos; ethtool eth0 show statistics of network card &apos;eth0&apos; netstat -tup show all active network connections and their PID netstat -tupl show all network services listening on the system and their PID tcpdump tcp port 80 show all HTTP traffic iwlist scan show wireless networks iwconfig eth1 show configuration of a wireless network card hostname show hostname host www.example.com lookup hostname to resolve name to ip address and viceversa nslookup www.example.com lookup hostname to resolve name to ip address and viceversa whois www.example.com lookup on Whois database Microsoft Windows networks (SAMBA)12345nbtscan ip_addr netbios name resolution nmblookup -A ip_addr netbios name resolution smbclient -L ip_addr/hostname show remote shares of a windows host smbget -Rr smb://ip_addr/share like wget can download files from a host windows via smb mount -t smbfs -o username=user,password=pass //WinClient/share /mnt/share mount a windows network share 命令详细解释ls1234567891011121314151617181920212223242526 ls (list 显示当前目录下文件和目录 ls -l 详细显示 ll ) ls [-aAdfFhilRS] 目录名称 ls [--color=&#123;none,auto,always&#125;] 目录名称 ls [--full-time] 目录名称 参数： -a ：全部的档案，连同隐藏档( 开头为 . 的档案) 一起列出来～ -A ：全部的档案，连同隐藏档，但不包括 . 与 .. 这两个目录，一起列出来～ -d ：仅列出目录本身，而不是列出目录内的档案数据 -f ：直接列出结果，而不进行排序 (ls 预设会以档名排序！) -F ：根据档案、目录等信息，给予附加数据结构，例如： *：代表可执行档； /：代表目录； =：代表 socket 档案； |：代表 FIFO 档案； -h ：将档案容量以人类较易读的方式(例如 GB, KB 等等)列出来； -i ：列出 inode 位置，而非列出档案属性； -l ：长数据串行出，包含档案的属性等等数据； -n ：列出 UID 与 GID 而非使用者与群组的名称 (UID与GID会在账号管理提到！) -r ：将排序结果反向输出，例如：原本档名由小到大，反向则为由大到小； -R ：连同子目录内容一起列出来； -S ：以档案容量大小排序！ -t ：依时间排序 --color=never ：不要依据档案特性给予颜色显示； --color=always ：显示颜色 --color=auto ：让系统自行依据设定来判断是否给予颜色 --full-time ：以完整时间模式 (包含年、月、日、时、分) 输出 --time=&#123;atime,ctime&#125; ：输出 access 时间或 改变权限属性时间 (ctime) 而非内容变更时间 (modification time) cat/tac1234567891011121314151617181920212223cat 由第一行开始显示档案内容 cat [-AEnTv] 参数： -A ：相当于 -vET 的整合参数，可列出一些特殊字符～ -E ：将结尾的断行字符 $ 显示出来； -n ：打印出行号； -T ：将 [tab] 按键以 ^I 显示出来； -v ：列出一些看不出来的特殊字符 tac 从最后一行开始显示，可以看出 tac 是 cat 的倒着写！nl 显示的时候，顺道输出行号！ nl [-bnw] 档案 参数： -b ：指定行号指定的方式，主要有两种： -b a ：表示不论是否为空行，也同样列出行号； -b t ：如果有空行，空的那一行不要列出行号； -n ：列出行号表示的方法，主要有三种： -n ln ：行号在屏幕的最左方显示； -n rn ：行号在自己字段的最右方显示，且不加 0 ； -n rz ：行号在自己字段的最右方显示，且加 0 ； -w ：行号字段的占用的位数。 more/head12345678910111213141516171819202122more 一页一页的显示档案内容 空格键 (space)：代表向下翻一页； Enter ：代表向下翻『一行』； /字符串 ：代表在这个显示的内容当中，向下搜寻『字符串』； :f ：立刻显示出文件名以及目前显示的行数； q ：代表立刻离开 more ，不再显示该档案内容。 less 与 more 类似，但是比 more 更好的是，他可以往前翻页！空格键 ：向下翻动一页； [pagedown]：向下翻动一页； [pageup] ：向上翻动一页； /字符串 ：向下搜寻『字符串』的功能； ?字符串 ：向上搜寻『字符串』的功能； n ：重复前一个搜寻 (与 / 或 ? 有关！) N ：反向的重复前一个搜寻 (与 / 或 ? 有关！) q ：离开 less 这个程序； head 只看头几行 head [-n number] 档案 参数： -n ：后面接数字，代表显示几行的意思 tail12345678910111213tail 只看尾巴几行 tail -200f logfile2 ( 显示日志最后 200 行 )od 以二进制的方式读取档案内容！ od [-t TYPE] 档案 参数： -t ：后面可以接各种『类型 (TYPE)』的输出，例如： a ：利用预设的字符来输出； c ：使用 ASCII 字符来输出 d[size] ：利用十进制(decimal)来输出数据，每个整数占用 size bytes ； f[size] ：利用浮点数值(floating)来输出数据，每个数占用 size bytes ； o[size] ：利用八进位(octal)来输出数据，每个整数占用 size bytes ； x[size] ：利用十六进制(hexadecimal)来输出数据，每个整数占用 size bytes ； chmod/chown/chgrp1234567chmod ( chmod +R filename增加文件读写执行权限,+R 可读,+W 可写,+X 可执行 ( chmod 777 filename 增加文件读写执行权限的另一种方式, 7=&gt; 对应8进制的 111 可读可写可执行) chown ( chown -R haowen .将当前目录下所有文件和目录权限赋给 haowen ,-R 包括子目录)chgrp -R mysql . (把当前文件夹变更到mysql群组,mysql是已经有的群组)变更文件或目录的所属群组。 find12find ./ -name index.jsp 查找当前目录下名称为index.jsp的文件find ( find ./ -name file1 -print ,从当前目录向下查找名为 file1 的文件) mkdir12345678910mkdir ( mkdir dir1 ,新建目录 dir1 ) mkdir [-mp] 目录名称 参数： -m ：设定档案的权限喔！直接设定，不需要看预设权限 (umask) 的脸色～ -p ：帮助你直接将所需要的目录递归建立起来！ rmdir [-p] 目录名称 参数： -p ：连同上层『空的』目录也一起删除 pwd12pwd Print Working Directory ( pwd ,显示当前路径 ) pwd -P 显示出确实的路径,而非使用连接(link)路径 cd12cd ( cd /usr/local/ 进入目录 /usr/local/ , cd ../ 返回到上一级目录 ./ 当前目录 ../父目录 - 代表前一个工作目录 ~代表[目前使用者身份]所在的家目录 ~account代表account这个使用者的家目录)针对 cd 的使用方法，如果仅输入 cd 时，代表的就是『 cd ~ 』 mv12345678910 mv ( mv file1 /home/haowen/ ,将文件移动到目录 /home/haowen/下 ,相当于 window 剪切 ) ( mv file1 filenew1 ,将文件名改为 filenew1 ) mv [-fiu] source destination mv [options] source1 source2 source3 .... directory 参数： -f ：force 强制的意思，强制直接移动而不询问； -i ：若目标档案 (destination) 已经存在时，就会询问是否覆盖！ -u ：若目标档案已经存在，且 source 比较新，才会更新 (update) cp12345678910111213141516 cp ( cp file1 /home/haowen/ ,将文件复制copy到目录 /home/haowen/下 cp -r dir1 /home/haowen/ cp file1 ./file2 复制文件并改名) cp [-adfilprsu] 来源档(source) 目的檔(destination) cp [options] source1 source2 source3 .... directory 参数： -a ：相当于 -pdr 的意思； -d ：若来源文件为连结文件的属性(link file)，则复制连结文件属性而非档案本身； -f ：为强制 (force) 的意思，若有重复或其它疑问时，不会询问使用者，而强制复制； -i ：若目的檔(destination)已经存在时，在覆盖时会先询问是否真的动作！ -l ：进行硬式连结 (hard link) 的连结档建立，而非复制档案本身； -p ：连同档案的属性一起复制过去，而非使用预设属性； -r ：递归持续复制，用于目录的复制行为； -s ：复制成为符号连结文件 (symbolic link)，亦即『快捷方式』档案； -u ：若 destination 比 source 旧才更新 destination ！ rm12345678 rm ( rm file1 ,rm -r dir1,rm -rf dir2 删除文件或目录, f不提示输入y rm [-fir] 档案或目录 参数： -f ：就是 force 的意思，强制移除； -i ：互动模式，在删除前会询问使用者是否动作 -r ：递归删除啊！最常用在目录的删除了 touch12345678910touch 建立一个空的档案,将某个档案日期修订为目前 (mtime 与 atime) touch [-acdmt] 档案 参数： -a ：仅修订 access time； -c ：仅修改时间，而不建立档案；-d ：后面可以接日期，也可以使用 --date=&quot;日期或时间&quot; -m ：仅修改 mtime ； -t ：后面可以接时间，格式为[YYMMDDhhmm] file12 file 如果你想要知道某个档案的基本数据，例如是属于 ASCII 或者是 data 档案，或者是 binary ， 且其中有没有使用到动态函式库 (share library) 等等的信息，就可以利用 file 这个指令来检阅喔！ which123456which (寻找『执行档』) 这个指令是根据『PATH』这个环境变量所规范的路径，去搜寻『执行档』的档名 which [-a] command 参数： -a ：将所有可以找到的指令均列出，而不止第一个被找到的指令名称 whereis1234567891011121314151617181920whereis (从数据库寻找特定档案) whereis [-bmsu] 档案或目录名 参数： -b :只找 binary 的档案 -m :只找在说明文件 manual 路径下的档案 -s :只找 source 来源档案 -u :没有说明档的档案！ 功能说明：计算字数。语 法：wc [-clw][--help][--version][文件名]补充说明：利用wc指令我们可以计算文件的Byte数、字数、或是列数，若不指定任何文件名称，或是所给予的文件名为&quot;-&quot;，则wc指令会从标准输入设备读取数据。假设不给予其参数，wc指令会一并显示列数、字数和Byte数参 数：-c 只显示Byte数，亦即字符数；-l 只显示列数；-w 只显示字数；-m 同样显示字符数--help 在线帮助；--version 显示此软件的版本信息。 locate12locate 从数据库列出某个档案的完整档名 grep123grep ( grep &quot;mobile=13712345678&quot; logfile1 ,在logfile1中 搜索查找内容 &quot;mobile=13712345678&quot; ) ping／ifconfig12ping ( ping 61.129.78.9 ,ping www.163.com ,测试网络连接是否正常 )ifconfig ( ifconfig ,查看本机 IP地址，子网掩码等 ) ps／kill1234ps ( ps aux 查看系统中已经启动的进程, ps aux | grep programe1 , 查看程序1是否正在运行kill ( kill -9 2325 ,杀死进程号为 2325的进程, killall programe1 ,杀死programe1进程 ) init／reboot1234reboot ( 重启系统 )init 0 ( 关机 ,仅 root 用户有权操作 )init 6 ( 重启系统 ,仅 root 用户有权操作 ) gzip／gunzip／tar123456gzip ( gzip file1 ,压缩文件 file1 )gunzip ( gunzip file1.gz 解压缩文件 file1.gz )tar -zcvf ( tar -zcvf dir1.tar.gz ./dir1 ,将当前目录下 dir1目录所有内容 压缩打包,包名dir1.tar.gz )tar -zxvf ( tar -zxvf dir1.tar.gz ,解开压缩包 ) echo／vi123456789101112131415 echo &quot;hello!&quot; &gt;&gt; file1 ( 将 &quot;hello&quot; 添加到文件 file1后面, 当 file1 不存在就创建 file1 vi file2 ( vi 编即器新建文件 file2) ...输入内容 welcome.. ( 按 i 进入 insert 状态 即插入模式 ,按 Esc 退出插入模式 在非插入模式下按 dd 删除光标当前行,按 x 删除当前字, 按 j,n,l移动光标 ) :wq ( 保存退出 ) :q! (不保存退出) 增加环境变量 echo $PATH PATH=&quot;$PATH&quot;:/root env／set12env 显示系统的一些环境变量 set 显示系统的所有变量 chmod12345678910111213141516171819chmod:Linux/Unix 的档案调用权限分为三级 : 档案拥有者、群组、其他。利用 chmod 可以藉以控制档案如何被他人所调用。 + 表示增加权限、- 表示取消权限、= 表示唯一设定权限。 r 表示可读取，w 表示可写入，x 表示可执行，1. 将档案 file1.txt 设为所有人皆可读取 : chmod ugo+r file1.txt 或 chmod 444 file1.txt2. 将文件 file2 设为属主可读写执行,Group,other ,只能读 chmod 744 file2 ( 7=&gt; &quot;111&quot; ,4=&gt;&quot;100&quot; 二进制 ) 3. 将文件 file3 设为属主可读写执行,Group,other ,无权限操作不能读写执行) chmod 700 file3 ( 7=&gt; &quot;111&quot; ,0=&gt;&quot;000&quot; ) 其中a,b,c各为一个数字，分别表示User、Group、及Other的权限。 r=4，w=2，x=1 若要rwx属性则4+2+1=7； 若要rw-属性则4+2=6； 若要r-x属性则4+1=5 tar12345678910tar:tar 调用gzip gzip是GNU组织开发的一个压缩程序，.gz结尾的文件就是gzip压缩的结果。 与gzip相对的解压程序是gunzip。tar中使用-z这个参数来调用gzip。 # tar -czf all.tar.gz *.jpg 这条命令是将所有.jpg的文件打成一个tar包，并且将其用gzip压缩，生成一个 gzip压缩过的包，包名为all.tar.gz # tar -xzf all.tar.gz 这条命令是将上面产生的包解开。 date／cal／bc123456 date 显示日期的指令： cal 显示日历的指令： bc 简单好用的计算器： info／who／finger／man12345678info 在线求助 : who 要看目前有谁在在线: finger 显示关于系统用户的信息man 命令:查看该命令的基础用法 netstat／ntsysv／shutdown12345netstat -a 看网络的联机状态: ntsysv 设置服务随系统启动时同时启动 shutdown ,shutdown -h now 惯用的关机指令： dmesg／df／du／free／top／hostname123456789dmesg : 例如 dmesg | more 显示系统的诊断信息,操作系统版本号,物理内及其它信息df : 例如 df -h 显示硬盘空间du : 查看目录中各级子目录使用的硬盘空间free: 查看系统内存,虚拟内存(交换空间)的大小占用情况top: 动态实时查看系统内存,CPU,进程hostname 查看主机名:hostname 新主机名 修改主机名(临时的,重启就没了): type12345678910111213141516type 查询某个指令是来自于外部指令(指的是其它非 bash 套件所提供的指令) 或是内建在 bash 当中的指令 type [-tpa] name 参数： ：不加任何参数时，则 type 会显示出那个 name 是外部指令还是 bash 内建的指令！ -t ：当加入 -t 参数时，type 会将 name 以底下这些字眼显示出他的意义： file ：表示为外部指令； alias ：表示该指令为命令别名所设定的名称； builtin ：表示该指令为 bash 内建的指令功能； -p ：如果后面接的 name 为指令时，会显示完整文件名(外部指令)或显示为内建指令； -a ：会将由 PATH 变量定义的路径中，将所有含有 name 的指令都列出来，包含 alias myname=pqb 变量的设定PATH=&quot;$PATH&quot;:/home/dmtsai/bin 变量的累加echo $myname 变量的查看unset myname 变量的取消 Shutdown123456789101112131415关闭系统使用Shutdown命令，确保用户和系统的资料完整。只有root用户才能使用这个命令。一般的用户是不允许执行这个命令的。我们先看看showdown语法：shutdown [options] when [message]options: -r 表示重启，-h表示系统服务停滞(halt)后，立刻关机，-f表示快速重启when： 为shutdown指定时间。hh:mm：绝对时间，hh指小时，mm指分钟；如08:30，+m:m分钟后执行，now=+0，也就是立刻执行message：表示系统的广播信息，一般提示各个用户系统关机或重启，要求用户保存资料后退出。我们来看看几个例子：shutdown -h now 立刻关机shutdown -h 21:30 今天21：30关机shutdown -h +10 十分钟后关机shutdown -r now 立刻重启shutdown -r +10 ‘the system will reboot’ 10分钟后重启，管理员提示用户系统要重启了，便于用户保存工作中的资料。只有root用户才能使用这个命令。 fdisk／mount／eject12345678910111213141516171819fdisk -l命令使用“vfat”文件系统类型表示所有的fat文件系统类型，包括fat16和fat32，ntfs还是使用ntfs表示。u盘的挂载方法mount -t vfat /dev/sdb1 /mnt/mount -t ntfs /dev/sdb1 /mnt/umount命令用于卸载已经挂载的文件系统，基本格式如：umount dir device对于光盘文件系统的卸载可以使用，以下两条命令中的任意一条umount /dev/cdromumount /media/cdromu盘的卸载umount /dev/sdb1eject命令eject 弹出光盘命令eject -t 光盘驱动器自动回收 ln1234567891011121314151617181920指令名称:ln 使用权限:所有使用者 使用方式:ln [options] source dist,其中 option 的格式为: [-bdfinsvF] [-S backup-suffix] [-V &#123;numbered,existing,simple&#125;] [--help] [--version] [--] 说明:Linux/Unix 档案系统中,有所谓的连结(link),我们可以将其视为档案的别名,而连结又可分为两种:硬连结(hard link)与软连结(symbolic link),硬连结的意思是一个档案可以有多个名称,而软连结的方式则是产生一个特殊的档案,该档案的内容是指向另一个档案的位置。硬连结是存在同一个档案系统中,而软连结却可以跨越不同的档案系统。 ln source dist 是产生一个连结(dist)到 source,至于使用硬连结或软链结则由参数决定。 不论是硬连结或软链结都不会将原本的档案复制一份,只会占用非常少量的磁碟空间。 -f:链结时先将与 dist 同档名的档案删除-d:允许系统管理者硬链结自己的目录-i:在删除与 dist 同档名的档案时先进行询问-n:在进行软连结时,将 dist 视为一般的档案-s:进行软链结(symbolic link)-v:在连结之前显示其档名-b:将在链结时会被覆写或删除的档案进行备份-S SUFFIX:将备份的档案都加上 SUFFIX 的字尾-V METHOD:指定备份的方式--help:显示辅助说明--version:显示版本 范例: 将档案 yy 产生一个 symbolic link:zz ln -s yy zz 将档案 yy 产生一个 hard link:zz ln yy xx at123456789101112131415161718192021222324 使用权限:所有使用者 使用方式:at -V [-q queue] [-f file] [-mldbv] TIME 说明:at 可以让使用者指定在 TIME 这个特定时刻执行某个程式或指令,TIME 的格式是 HH:MM其中的 HH 为小时,MM 为分钟,甚至你也可以指定 am, pm, midnight, noon, teatime(就是下午 4 点锺)等口语词。 如果想要指定超过一天内的时间,则可以用 MMDDYY 或者 MM/DD/YY 的格式,其中 MM 是分钟,DD 是第几日,YY 是指年份。另外,使用者甚至也可以使用像是 now + 时间间隔来弹性指定时间,其中的时间间隔可以是 minutes, hours, days, weeks 另外,使用者也可指定 today 或 tomorrow 来表示今天或明天。当指定了时间并按下 enter 之后,at 会进入交谈模式并要求输入指令或程式,当你输入完后按下 ctrl+D 即可完成所有动作,至于执行的结果将会寄回你的帐号中。 把计: -V:印出版本编号 -q:使用指定的伫列(Queue)来储存,at 的资料是存放在所谓的 queue 中,使用者可以同时使用多个 queue,而 queue 的编号为 a, b, c... z 以及 A, B, ... Z 共 52 个 -m:即使程式/指令执行完成后没有输出结果, 也要寄封信给使用者 -f file:读入预先写好的命令档。使用者不一定要使用交谈模式来输入,可以先将所有的指定先写入档案后再一次读入 -l:列出所有的指定 (使用者也可以直接使用 atq 而不用 at -l) -d:删除指定 (使用者也可以直接使用 atrm 而不用 at -d) -v:列出所有已经完成但尚未删除的指定 例子: 三天后的下午 5 点锺执行 /bin/ls: at 5pm + 3 days /bin/ls 三个星期后的下午 5 点锺执行 /bin/ls: at 5pm + 2 weeks /bin/ls 明天的 17:20 执行 /bin/date: at 17:20 tomorrow /bin/date 1999 年的最后一天的最后一分钟印出 the end of world ! at 23:59 12/31/1999 echo the end of world ! cal12345678910111213141516171819202122 使用权限：所有使用者 使用方式：cal [-mjy] [month [year]] 说明： 显示日历。若只有一个参数,则代表年份(1-9999),显示该年的年历。年份必须全部写出：``cal 89\ 将不会是显示 1989 年的年历。使用两个参数,则表示月份及年份。若没有参数则显示这个月的月历。 1752 年 9 月第 3 日起改用西洋新历,因这时大部份的国家都采用新历,有 10 天被去除,所以该月份的月历有些不同。在此之前为西洋旧历。 匡兜: -m:以星期一为每周的第一天方式显示。 -j:以凯撒历显示,即以一月一日起的天数显示。 -y:显示今年年历。 范例： cal:显示本月的月历。 [root@mylinux /root]# date Tue Aug 15 08:00:18 CST 2000 [root@mylinux /root]# cal ... cal 2001:显示公元 2001 年年历。 [root@mylinux /root]# cal 2001 ...cal 5 2001:显示公元 2001 年 5 月月历。 [root@mylinux /root]# cal 5 2001 crontab1234567891011121314151617181920212223242526272829303132333435 使用权限:所有使用者 使用方式: crontab [ -u user ] filecrontab [ -u user ] &#123; -l | -r | -e &#125; 说明: crontab 是用来让使用者在固定时间或固定间隔执行程式之用,换句话说,也就是类似使用者的时程表。-u user 是指设定指定 user 的时程表,这个前提是你必须要有其权限(比如说是 root)才能够指定他人的时程表。如果不使用 -u user 的话,就是表示设定自己的时程表。 参数: -e:执行文字编辑器来设定时程表,内定的文字编辑器是 VI,如果你想用别的文字编辑器,则请先设定 VISUAL 环境变数来指定使用那个文字编辑器(比如说 setenv VISUAL joe) -r:删除目前的时程表 -l:列出目前的时程表 时程表的格式如下: f1 f2 f3 f4 f5 program 其中 f1 是表示分钟,f2 表示小时,f3 表示一个月份中的第几日,f4 表示月份,f5 表示一个星期中的第几天。program 表示要执行的程式。 当 f1 为 * 时表示每分钟都要执行 program,f2 为 * 时表示每小时都要执行程式,其余类推 当 f1 为 a-b 时表示从第 a 分钟到第 b 分钟这段时间内要执行,f2 为 a-b 时表示从第 a 到第 b 小时都要执行,其余类推 当 f1 为 */n 时表示每 n 分钟个时间间隔执行一次,f2 为 */n 表示每 n 小时个时间间隔执行一次,其余类推 当 f1 为 a, b, c,... 时表示第 a, b, c,... 分钟要执行,f2 为 a, b, c,... 时表示第 a, b, c...个小时要执行,其余类推 使用者也可以将所有的设定先存放在档案 file 中,用 crontab file 的方式来设定时程表。 例子: 每月每天每小时的第 0 分钟执行一次 /bin/ls: 0 7 * * * /bin/ls 在 12 月内, 每天的早上 6 点到 12 点中,每隔 20 分钟执行一次 /usr/bin/backup: 0 6-12/3 * 12 * /usr/bin/backup 周一到周五每天下午 5:00 寄一封信给 alex@domain.name: 0 17 * * 1-5 mail -s &quot;hi&quot; alex@domain.name &lt; /tmp/maildata 每月每天的午夜 0 点 20 分, 2 点 20 分, 4 点 20 分....执行 echo &quot;haha&quot; 20 0-23/2 * * * echo &quot;haha&quot; 注意: 当程式在你所指定的时间执行后,系统会寄一封信给你,显示该程式执行的内容,若是你不希望收到这样的信,请在每一行空一格之后加上 &gt; /dev/null 2&gt;&amp;1 即可。 sleep12345678910111213141516171819 使用权限:所有使用者 使用方式:sleep [--help] [--version] number[smhd] 说明:sleep 可以用来将目前动作延迟一段时间 参数说明: --help:显示辅助讯息 --version:显示版本编号 number:时间长度,后面可接 s,m,h 或 d 其中 s 为秒,m 为 分钟,h 为小时,d 为日数 例子: 显示目前时间后延迟 1 分钟,之后再次显示时间: date;sleep 1m;date 名称： finger 使用权限： 所有使用者 使用方式： finger [options] user[@address] 说明：finger 可以让使用者查询一些其他使用者的资料。范例：下列指令可以查询本机管理员的资料： finger root last1234567891011 使用权限：所有使用者 使用方式：shell&gt;&gt; last [options] 说明：显示系统开机以来获是从每月初登入者的讯息 把计: -R 省略 hostname 的栏位 -num 展示前 num 个 username 展示 username 的登入讯息 tty 限制登入讯息包含终端机代号 范例： shell&gt;&gt; last -R -2 write1234567891011121314151617 使用权限:所有使用者 使用方式: write user [ttyname] 说明:传讯息给其他使用者 把计: user:预备传讯息的使用者帐号 ttyname:如果使用者同时有两个以上的 tty 连线,可以自行选择合适的 tty 传讯息 例子.1: 传讯息给 Rollaend,此时 Rollaend 只有一个连线: write Rollaend 接下来就是将讯息打上去,结束请按 ctrl+c 例子.2 :传讯息给 Rollaend,Rollaend 的连线有 pts/2,pts/3: write Rollaend pts/2 接下来就是将讯息打上去,结束请按 ctrl+c 注意:若对方设定 mesg n,则此时讯席将无法传给对方 expr123456789101112131415161718192021 使用权限：所有使用者 ### 字串长度 shell&gt;&gt; expr length &quot;this is a test&quot; 14 ### 数字商数 shell&gt;&gt; expr 14 % 9 5 ### 从位置处抓取字串 shell&gt;&gt; expr substr &quot;this is a test&quot; 3 5 is is ### 数字串 only the first character shell&gt;&gt; expr index &quot;testforthegame&quot; e 2 ### 字串真实重现 shell&gt;&gt; expr quote thisisatestformela thisisatestformela clear12 用途：清除萤幕用。 使用方法：在 console 上输入 clear。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud学习]]></title>
    <url>%2Fcloud%2Fspring_cloud.html</url>
    <content type="text"><![CDATA[模式B2B2C(如：耐克入住淘宝卖鞋子给用户) C2C(如: 耐克的官网直接卖鞋子给用户) 微服务需要满足的三个指标 高可用（服务一直可以用，n个9，6个9 99.9999%也就是一年以内允许宕机的时间为31.536秒）、 高性能（响应速度，3s以内） 高并发（系统的承载能力，用户同时访问的系统） 垂直扩展：升级配置，有性能瓶颈 水平扩张：添加服务器进行负载均衡（轮询、权重、hash一致） 微服务需要解决的四个问题 服务与服务之间如何访问 服务与服务之间如何通信 服务挂了怎么办 服务如何治理 CAP定理C: 一致性（强一致性）: 要么都成功，要么都失败，事务的原子性。（弱一致：顺序一致、最终一致） A: 可用性：高可用、高性能，服务一致可以使用，正常的响应时间 P: 分区容错性：如果其中一个服务出现了故障，仍然可以提供服务 如mysql服务进行了分区之后有多个服务，如果一台出现了故障，则转移到其它的备用服务进行数据处理。但是这样的话就无法保证数据的强一致性，即要么是强一致系统，要么是分区容错的系统。 故CAP定理三个要素最多只能同时实现两点，不可能三者兼顾。然而分布式系统已经保重了分区容错性，因此只有两种系统: CP系统：强一致系统，金融系统 AP系统: 高可用系统，互联网系统 BASE理论因为无法达到强一致性，故可以采用适当的方法达到最终一致性。 基本可用（保证核心可以用）、软状态（等待同步的过程）、最终一致性（最终达到一致） 微服务的拆分为了解耦 领域驱动设计 spring Cloud 是一种编程模型，微服务开发的一种标准，一系列的接口。 spring Cloud Netflix, spring Cloud Alibaba都是springCloud模型的的一种具体实现。 一、版本对应 Spring Boot Spring Cloud Spring Cloud Alibaba 2.1.x Greenwich 0.9.x 2.0.x Finchley 0.2.x 1.5.x Edgware 0.1.x 1.5.x Dalston 0.1.x 二、SpringCloud vs SpringCloudAlibaba 基于SpringBoot 2.x Finchley SpringCloudAlibaba 版本 Finchley 2.x 服务注册与发现 Eureka Nacos 路由网关 Gateway(zuul-Dalston版本) Gateway 配置中心 config Nacos 熔断机制(限流、 降级、重试) Hystix Sentinel 消息总线 Bus Bus 链路追踪 Sleuth Sleuth 聚合监控 Turbine Turbine 服务消费 Feign/Ribbon Nacos 负载均衡 Feign/Ribbon Dubbo 三、启动顺序dependences(依赖管理) &gt; config(配置中心) &gt; eureka(服务注册与发现) &gt; zipkin(链路追踪) &gt; 分布式配置中心 &gt; 服务注册中心 &gt; 服务提供者 &gt; 服务消费者 &gt; API网关 四、服务注册中心(Eureka)1234567891011121314151617181920// pom.xml 配置&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; // yml 配置spring: application: name: hello-spring-cloud-eurekaserver: port: 8761eureka: instance: hostname: localhost client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ 五、分布式配置中心12345678910111213141516171819202122232425262728293031323334// 服务端pom.xml配置&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;// 客户端pom.xml配置&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt;// 配置服务端yml配置spring: application: name: hello-spring-cloud-config cloud: config: label: master server: git: uri: https://github.com/topsale/spring-cloud-config search-paths: respo username: password:// 客户端yml配置spring: application: name: hello-spring-cloud-config-client cloud: config: uri: http://localhost:8888 name: config-client label: master profile: dev 六、服务提供者12345678910// ribbon服务提供者&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt;// yml配置eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 七、服务消费者123456789101112131415// ribbon服务消费&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;&lt;/dependency&gt;//Feign服务消费&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt;// yml配置eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 八、API网关123456789101112131415// zuul配置&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;// yum 配置zuul: routes: api-a: path: /api/a/** serviceId: hello-spring-cloud-web-admin-ribbon api-b: path: /api/b/** serviceId: hello-spring-cloud-web-admin-feign 九、熔断器防止服务雪崩12345678910// pom 配置&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt;// yum配置feign: hystrix: enabled: true// application里面添加@EnableHystrix注解，调用方法上面增加@HystrixCommand(fallbackMethod = &quot;hiError&quot;)注解 十、熔断器仪表盘监控1234567891011121314151617181920// pom.xml配置&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt;// application中添加@EnableHystrixDashboard注解//创建 hystrix.stream 的 Servlet 配置@Configurationpublic class HystrixDashboardConfiguration &#123; @Bean public ServletRegistrationBean getServlet() &#123; HystrixMetricsStreamServlet streamServlet = new HystrixMetricsStreamServlet(); ServletRegistrationBean registrationBean = new ServletRegistrationBean(streamServlet); registrationBean.setLoadOnStartup(1); registrationBean.addUrlMappings(&quot;/hystrix.stream&quot;); registrationBean.setName(&quot;HystrixMetricsStreamServlet&quot;); return registrationBean; &#125;&#125; 十一、服务链路追踪1234567891011121314151617181920// pom.xml 配置&lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-autoconfigure-ui&lt;/artifactId&gt;&lt;/dependency&gt;// aplication添加@EnableZipkinServer注解// yml配置management: metrics: web: server: auto-time-requests: false 十二、Spring Boot Admin12345678910111213141516171819202122232425262728293031323334// 服务端pom.xml依赖&lt;dependency&gt; &lt;groupId&gt;org.jolokia&lt;/groupId&gt; &lt;artifactId&gt;jolokia-core&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt;&lt;/dependency&gt;// 客户端pom.xml依赖&lt;dependency&gt; &lt;groupId&gt;org.jolokia&lt;/groupId&gt; &lt;artifactId&gt;jolokia-core&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt;&lt;/dependency&gt;// application添加@EnableAdminServer依赖// 服务端yml配置management: endpoint: health: show-details: always endpoints: web: exposure: include: health,info// 客户端yml配置spring: boot: admin: client: url: http://localhost:8084 十三、其他 Spring Cloud Bus：事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与Spring Cloud Config联合实现热部署。 Spring Cloud Netflix：针对多种Netflix组件提供的开发工具包，其中包括Eureka、Hystrix、Zuul、Archaius等。 Netflix Eureka：云端负载均衡，一个基于REST 的服务，用于定位服务，以实现云端的负载均衡和中间层服务器的故障转移。 Netflix Hystrix：容错管理工具，旨在通过控制服务和第三方库的节点,从而对延迟和故障提供更强大的容错能力。 Netflix Zuul：边缘服务工具，是提供动态路由，监控，弹性，安全等的边缘服务。 Netflix Archaius：配置管理API，包含一系列配置管理API，提供动态类型化属性、线程安全配置操作、轮询框架、回调机制等功能。 Spring Cloud for Cloud Foundry：通过Oauth2协议绑定服务到CloudFoundry，CloudFoundry是VMware推出的开源PaaS云平台。 Spring Cloud Sleuth：日志收集工具包，封装了Dapper,Zipkin和HTrace操作。 Spring Cloud Data Flow：大数据操作工具，通过命令行方式操作数据流。 Spring Cloud Security：安全工具包，为你的应用程序添加安全控制，主要是指OAuth2。 Spring Cloud Consul：封装了Consul操作，consul是一个服务发现与配置工具，与Docker容器可以无缝集成。 Spring Cloud Zookeeper：操作Zookeeper的工具包，用于使用zookeeper方式的服务注册和发现。 Spring Cloud Stream：数据流操作开发包，封装了与Redis,Rabbit、Kafka等发送接收消息。 Spring Cloud CLI：基于 SpringBoot CLI，可以让你以命令行方式快速建立云组件。]]></content>
      <categories>
        <category>cloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vi 快捷键记录]]></title>
    <url>%2Flinux%2Fvim.html</url>
    <content type="text"><![CDATA[vim键盘图12# 查看当前文件夹下面的文件数量ls -l |grep &quot;^-&quot;|wc -l vi小抄 vi 常用 进入vi vi filename 打开或新建文件，并将光标置于第一行首 vi +n filename 打开文件，并将光标置于第n行首 vi + filename 打开文件，并将光标置于最后一行首 vi +/pattern filename 打开文件，并将光标置于第一个与pattern匹配的串处 vi -r filename 在上次正用vi编辑时发生系统崩溃，恢复filename vi filename….filename 打开多个文件，依次进行编辑 退出vi w /tmp1 另存为/tmp1 20,59w /tmp1 仅将20-59行之间的内存另存为/tmp1 !command 执行shell命令command wq 保存退出 n1,n2 w !command 将文件中n1行至n2行的内容作为command的输入并执行之，若不指定n1，n2，则表示将整个文件内容作为command的输入 r !command 将命令command的输出结果放到当前行 w !sudo tee % 保存没权限时，可获取权限再保存 光标移动 k、j、h、l 上、下、左、右 space 光标右移一个字符 Backspace 光标左移一个字符 Enter 光标下移一行 w(W)、b(B) 光标右、左移一个字至字首 e(E) 光标右移一个字至字尾 (、) 光标移至句首、尾 {、} 光标移至段落开头、结尾 nG 光标移至第n行首 n+、n- 光标下、上移n行 n$ 光标移至第n行尾 H 光标移至屏幕顶行 M 光标移至屏幕中间行 L 光标移至屏幕最后行 0 （注意是数字零）光标移至当前行首 $ 光标移至当前行尾 搜索（查找） /abc 从光标开始处向文件尾搜索abc ?abc 从光标开始处向文件首搜索abc /\/abc 从光标开始处向文件尾搜索/abc，其中/是转义 n 在同一方向重复上一次搜索命令 N 在反方向上重复上一次搜索命令 替换 s/vivian/sky/ 替换当前行第一个 vivian 为 sky s/vivian/sky/g 替换当前行所有 vivian 为 sky n,$s/vivian/sky/ 替换第 n 行开始到最后一行中每一行的第一个 vivian 为 sky n,$s/vivian/sky/g 替换第 n 行开始到最后一行中每一行所有 vivian 为sky %s/vivian/sky/g （等同于 g/vivian/s//sky/） 替换每一行的每一个 vivian 为 sky s#vivian/#sky/# 替换当前行第一个 vivian/ 为 sky/（可以使用 #或+作为分隔符，此时中间出现的 / 不会作为分隔符） s/p1/p2/g 将当前行中所有p1均用p2替代 n1,n2s/p1/p2/g 将第n1至n2行中所有p1均用p2替代 g/p1/s//p2/g 将文件中所有p1均用p2替换 %s/^/123 把123添加到每行的行首 %s/$/123 把123添加到每行的行尾 g/^\s*$/d 去除所有空白行 %s/\n//g 删除换行符 屏幕翻滚 Ctrl+u 向文件首翻半屏 Ctrl+d 向文件尾翻半屏 Ctrl+f 向文件尾翻一屏 Ctrl＋b 向文件首翻一屏 nz 将第n行滚至屏幕顶部，不指定n时将当前行滚至屏幕顶部插入 i、a 在光标前 、后 I、A 在当前行首、尾 o 在当前行之下新开一行 O 在当前行之上新开一行 r 替换当前字符 s 从当前光标位置处开始，以输入的文本替代指定数目的字符 S 删除指定数目的行，并以所输入文本代替之 R 替换当前字符及其后的字符，直至按ESC键 ncw或 nCW 修改指定数目的字 nCC 修改指定数目的行 删除 ndw 或 ndW 删除光标处开始及其后的n-1个字 do 、d$ 删至行首、行尾 x 或 X 删除一个字符，x删除光标后的，而X删除光标前的 ndd 删除当前行及其后n-1行 Ctrl+u 删除输入方式下所输入的文本 n1,n2 d 将n1行到n2行之间的内容删除 %d 删除全部内容 1,$d 删除全部内容 复制粘贴、剪切、移动 yy 复制当前行 nyy 复制当前行开始的n行 先按 v 然后方向键选择区域，按 y 复制选中行 dd 剪切当前行 p（小） 在当前光标处下面粘贴内容。 P（大） 在当前光标处上面粘贴内容 n1,n2 co n3 将n1行到n2行之间的内容拷贝到第n3行下 n1,n2 m n3 将n1行到n2行之间的内容移至到第n3行下 选项设置 set number 显示行号 set number! 不显示行号，其它选项同理加！号 set all 列出所有选项设置情况 set term 设置终端类型 set ignorance 在搜索中忽略大小写 set list 显示制表位(Ctrl+I)和行尾标志（$) set report 显示由面向行的命令修改过的数目 set terse 显示简短的警告信息 set warn 在转到别的文件时若没保存当前文件则显示NO write信息 set nomagic 允许在搜索模式中，使用前面不带“”的特殊字符 set nowrapscan 禁止vi在搜索到达文件两端时，又从另一端开始 set mesg 允许vi显示其他用户用write写到自己终端上的信息 寄存器 “?nyy 将当前行及其下n行的内容保存到寄存器？中，其中?为一个字母，n为一个数字 “?nyw 将当前行及其下n个字保存到寄存器？中，其中?为一个字母，n为一个数字 “?nyl 将当前行及其下n个字符保存到寄存器？中，其中?为一个字母，n为一个数字 “?p 取出寄存器？中的内容并将其放到光标位置处。这里？可以是一个字母，也可以是一个数字 ndd 将当前行及其下共n行文本删除，并将所删内容放到1号删除寄存器中]]></content>
      <categories>
        <category>vi</category>
      </categories>
      <tags>
        <tag>vi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyCat－学习笔记]]></title>
    <url>%2Ftool%2Fmycat.html</url>
    <content type="text"><![CDATA[MyCat－学习笔记MyCat权威指南 拆表学习 当一张表的数量达到千万数据量以上的时候，加了索引可以正常查询， 但是在往上增加的话，可能就会出现查询速度慢的情况， 所有需要一些解决方案防止这种情况的发生。我暂时知道的解决方案如下： 数据读写分离：将应用的读写请求分到多个服务器上面，降低服务器访问压力。（适用于并发量大的情况下） 归档：将历史不用的数据进行归档处理，将数据压缩存放至硬盘、云盘等地方。 页面限制：用户查询时限制用户查询时间点，用户查询历史数据需求量大的话，可以单独做一个历史归档数据查询功能等。 拆库、拆表：同一个库里面的数据量太多，将数据拆分到多个表，多个库提高查询效率。解决表过大导致的访问出现卡顿现象。 &nbsp;&nbsp;读写分离的情况， 在并发量特别大的情况下很适用， 这种方法后期研究。 归档功能本公司已经在处理， 但是归档之后数据量还是特别大，这个时候就要拆库、拆表，拆库拆表之后对应用是有影响的，有两种情况， 一种就是改动应用的源代码，工作量就很大了，再有一种就是利用数据库中间件做一个数据库的代理。各种查询通过走中间件的方式进行，中间件负责分发查询请求到多个表，并汇总数据反馈给查询调用方。经过对比，最终选择了MyCat作为数据库中间件。由于数据库是oracle，MyCay对oracle的兼容性不是很好。后期可能调试的地方就比较多了。 水平拆表摘要 水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张表的数据拆成多张表来存放(数据结构一样，每个表存放不同的数据按时间存放、ID取模的方法等)。水平分库需要对系统做大的改造; 方式 部分业务逻辑也可以通过地区，年份等字段来进行归档拆分; 进行拆分后的表，只能满足部分查询的高效查询需求，这时我们可以从界面上约束用户查询行为。比如我们是按年来进行归档拆分的,这个时候在页面设计上就约束用户必须要先选择年,然后才能进行查询; 在做分析或者统计时，由于是自己人的需求,多点等待其实是没关系的,并且并发很低,这个时候可以用union把所有表都组合成一张视图来然后再进行查询; 垂直拆表摘要 垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表;垂直拆分更多时候就应该在数据表设计之初就执行的步骤，然后查询的时候用jion关联起来即可;数据库里的表太多，拿出部分到新的库里，一般是根据业务划分表，关系密切的表放同一数据库，应用修改数据库连接即可; 方式 把不常用的字段单独放在一张表; 把text，blob等大字段拆分出来放在附表中; 经常组合查询的列放在一张表中; 拆表需要注意 跨节点join的问题、跨节点合并、排序、分页等处理数据的问题。 MyCat安装下载 在MyCat官网:http://dl.mycat.io/1.6.6.1/下载并解压。 MyCat配置 schema.xml配置 管理着 MyCat 的逻辑库、表、分片规则、 DataNode 以及 DataSource 123456789101112131415161718&lt;!-- 定义逻辑库，MyCat可以有多个逻辑库，每个逻辑库都有自己的相关配置。用schema 标签划分不同的逻辑库，checkSQLschema：否去掉表前面的数据库的名称，缺省未false，db1的名称不是schema的名称则不会去掉，官方不建议设置为true。sqlMaxLimit：每次执行语句，如果没有加上 limit 语句，mycat自动加。--&gt;&lt;schema name=&quot;db1&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;!-- 定义逻辑表，所有需要拆分的表都需要在这个标签中定义。具体含义相见表1-1 &lt;table name=&quot;travelrecord&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;auto-sharding-long&quot; &gt; &lt;!-- 定义 E-R 分片的子表。通过标签上的属性与父表进行关联。 具体含义相见表1-2--&gt; &lt;childTable name=&quot;c_a&quot; primaryKey=&quot;ID&quot; joinKey=&quot;customer_id&quot; parentKey=&quot;id&quot; /&gt; &lt;/table&gt;&lt;/schema&gt;&lt;!-- 定义了 MyCat 中的数据节点，也就是我们通常说所的数据分片。一个 dataNode 标签就是一个独立的数据分片。具体含义相见表1-3--&gt;&lt;dataNode name=&quot;dNode1&quot; dataHost=&quot;dHost128&quot; database=&quot;db1&quot; &gt;&lt;/dataNode&gt;&lt;!-- 具体的数据库实例、读写分离配置和心跳语句.具体含义相见表1-4--&gt;&lt;dataHost name=&quot;localhost1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot;&gt; &lt;!--这个标签内指明用于和后端数据库进行心跳检查的语句。 例如：MYSQL 可以使用 select user()，Oracle 可以使用 select 1 from dual 等。--&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;!-- writeHost /readHost:这两个标签都指定后端数据库的相关配置，用于实例化后端连接池。唯一不同的是，writeHost 指定写实例、readHost 指定读实例。 在一个 dataHost 内可以定义多个 writeHost 和 readHost。但是，如果 writeHost 指定的后端数据库宕机，那么这个 writeHost 绑定的所有 readHost 都将不可用。另一方面，由于这个 writeHost 宕机，系统会自动的检测到，并切换到备用的 writeHost 上去. 具体含义相见表1-5--&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;localhost:3306&quot; user=&quot;root&quot; password=&quot;123456&quot;&gt; &lt;/writeHost&gt;&lt;/dataHost&gt; table标签：1-1 childTable标签：1-2 dataNode标签：1-3 dataHost标签：1-4 writeHost/readHost标签：1-5 详细注释 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt;&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;!-- schema 数据库设置，此数据库为逻辑数据库，name与server.xml中schema对应 dataNode 分片信息，也就是分库相关配置 dataHost 物理数据库，真正存储数据的数据库 命令行连接mycat: mysql -uroot -p123456 -h127.0.0.1 -P8066 -DTESTDB --&gt; &lt;!-- schema标签用来定义mycat实例中的逻辑库，mycat可以有多个逻辑库，每个逻辑库都有自己的相关配置。可以使用schema标签来划分这些不同的逻辑库如果不配置schema标签，所有表的配置会属于同一个默认的逻辑库。逻辑库的概念和MySql的database的概念一样，我们在查询两个不同逻辑库中的表的时候，需要切换到该逻辑库下进行查询。 name: 逻辑数据库名，与server.xml中的schema对应 checkSQLschema： 描述的是当前的连接是否需要检测数据库的模式 sqlMaxLimit： 表示返回的最大的数据量的行数 (sqlMaxLimit=&quot;100&quot;) 暂时不加limit限制 dataNode=&quot;dn1&quot;： 该操作使用的数据节点是dn1的逻辑名称 --&gt; &lt;schema name=&quot;TESTDB&quot; checkSQLschema=&quot;false&quot; dataNode=&quot;dn1&quot;&gt; &lt;!-- name 表名，物理数据库中表名 dataNode 表存储到哪些节点，多个节点用逗号分隔。节点为下文dataNode设置的name primaryKey 主键字段名，自动生成主键时需要设置 autoIncrement 是否自增 rule 分片规则名，具体规则下文rule详细介绍 type 该属性定义了逻辑表的类型，目前逻辑表只有全局表和普通表。全局表： global 普通表：无 注：全局表查询任意节点，普通表查询所有节点效率低 autoIncrement mysql对非自增长主键，使用last_insert_id() 是不会返回结果的，只会返回0.所以，只有定义了自增长主键的表，才可以用last_insert_id()返回主键值。 mycat提供了自增长主键功能，但是对应的mysql节点上数据表，没有auto_increment,那么在mycat层调用last_insert_id()也是不会返回结果的。 needAddLimit 指定表是否需要自动的在每个语句后面加上limit限制，由于使用了分库分表，数据量有时候会特别庞大，这时候执行查询语句， 忘记加上limt就会等好久，所以mycat自动为我们加上了limit 100，这个属性默认为true，可以自己设置为false禁用。如果使用这个功能，最好配合使用数据库模式的全局序列。 subTables 分表，分表目前不支持Join。--&gt; &lt;table name=&quot;pub_corporate&quot; dataNode=&quot;dn1&quot; type=&quot;global&quot;&gt;&lt;/table&gt; &lt;!-- childTable 标签用于定义 E-R 分片的子表。通过标签上的属性与父表进行关联。 name 子表的名称 joinKey 子表中字段的名称 parentKey 父表中字段名称 primaryKey 同Table needAddLimit 同Table --&gt; &lt;!-- &lt;childTable name=&quot;c_a&quot; primaryKey=&quot;ID&quot; joinKey=&quot;customer_id&quot; parentKey=&quot;id&quot; /&gt; --&gt; &lt;/schema&gt; &lt;!-- datanode标签定义了mycat中的数据节点，也就是我们所说的数据分片。一个datanode标签就是一个独立的数据分片。 例子中的表述的意思为，使用名字为localhost1数据库实例上的db1物理数据库，这就组成一个数据分片，最后我们用dn1来标示这个分片。 name 定义数据节点的名字，这个名字需要唯一。我们在table标签上用这个名字来建立表与分片对应的关系 dataHost 用于定义该分片属于哪个数据库实例，属性与datahost标签上定义的name对应 database 用于定义该分片属于数据库实例上的具体库。 --&gt; &lt;dataNode name=&quot;dn1&quot; dataHost=&quot;TESTLOCALHOST&quot; database=&quot;test&quot; /&gt; &lt;!-- name 唯一标示dataHost标签，供上层使用 maxCon 指定每个读写实例连接池的最大连接。 minCon 指定每个读写实例连接池的最小连接，初始化连接池的大小 balance 负载均称类型 balance=&quot;0&quot;：不开启读写分离机制，所有读操作都发送到当前可用的writeHost上 balance=&quot;1&quot;：全部的readHost与stand by writeHost参与select语句的负载均衡，简单的说，当双主双从模式（M1-S1，M2-S2 并且M1 M2互为主备），正常情况下，M2,S1,S2都参与select语句的负载均衡。 balance=&quot;2&quot;：所有读操作都随机的在writeHost、readHost上分发 balance=&quot;3&quot;：所有读请求随机的分发到writeHst对应的readHost执行，writeHost不负担读写压力。（1.4之后版本有） writeType 负载均衡类型。 writeType=&quot;0&quot;, 所有写操作发送到配置的第一个 writeHost，第一个挂了切到还生存的第二个writeHost，重新启动后已切换后的为准，切换记录在配置文件中:dnindex.properties . writeType=&quot;1&quot;，所有写操作都随机的发送到配置的 writeHost。1.5以后版本废弃不推荐。 switchType -1不自动切换 1 默认值 自动切换 2 基于MySql主从同步的状态决定是否切换心跳语句为 show slave status 3 基于mysql galary cluster 的切换机制（适合集群）1.4.1 心跳语句为 show status like &apos;wsrep%&apos; dbType 指定后端链接的数据库类型目前支持二进制的mysql协议，还有其他使用jdbc链接的数据库，例如：mongodb，oracle，spark等 dbDriver 指定连接后段数据库使用的driver，目前可选的值有native和JDBC。使用native的话，因为这个值执行的是二进制的mysql协议，所以可以使用mysql和maridb，其他类型的则需要使用JDBC驱动来支持。 如果使用JDBC的话需要符合JDBC4标准的驱动jar 放到mycat\lib目录下，并检查驱动jar包中包括如下目录结构文件 META-INF\services\java.sql.Driver。 在这个文件写上具体的driver类名，例如com.mysql.jdbc.Driver writeHost readHost指定后端数据库的相关配置给mycat，用于实例化后端连接池。 tempReadHostAvailable 如果配置了这个属性 writeHost 下面的 readHost 仍旧可用，默认 0 可配置（0、1）。 mysql: dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; oracle: dbType=&quot;oracle&quot; dbDriver=&quot;jdbc&quot; --&gt; &lt;dataHost name=&quot;TESTLOCALHOST&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;oracle&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;!--mysql心跳检查的语句 oracle: select 1 from dual mysql: select user()--&gt; &lt;heartbeat&gt;select 1 from dual&lt;/heartbeat&gt; &lt;!-- writeHost /readHost 标签 这两个标签都指定后端数据库的相关配置，用于实例化后端连接池。唯一不同的是，writeHost 指定写实例、readHost 指定读实例。 在一个 dataHost 内可以定义多个 writeHost 和 readHost。但是，如果 writeHost 指定的后端数据库宕机，那么这个 writeHost 绑定的所有 readHost 都将不可用。 另一方面，由于这个 writeHost 宕机，系统会自动的检测到，并切换到备用的 writeHost 上去。这两个标签的属性相同，这里就一起介绍。 host 用于标识不同实例，一般 writeHost 我们使用*M1，readHost 我们用*S1。 url 后端实例连接地址。Native：地址：端口 JDBC：jdbc的url password 后端存储实例需要的密码 user 后端存储实例需要的用户名字 weight 权重 配置在 readhost 中作为读节点的权重 usingDecrypt 是否对密码加密，默认0。具体加密方法看官方文档。--&gt; &lt;!--&lt;writeHost host=&quot;hostM1&quot; url=&quot;localhost:3306&quot; user=&quot;root&quot;--&gt; &lt;!--password=&quot;123456&quot;&gt;--&gt; &lt;!--&lt;/writeHost&gt;--&gt; &lt;!--&lt;writeHost host=&quot;hostM1&quot; url=&quot;localhost:3306&quot; user=&quot;root&quot; password=123456i&quot;&gt;--&gt; &lt;!--&lt;/writeHost&gt;--&gt; &lt;!--oracle: jdbc:oracle:thin:@IP地址:1521:orcl mysql: localhost:3306 --&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;jdbc:oracle:thin:@localhost:1521:orcl&quot; user=&quot;tysp&quot; password=&quot;123456&quot;&gt; &lt;/writeHost&gt; &lt;/dataHost&gt;&lt;/mycat:schema&gt; Server.xml的配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mycat:server SYSTEM &quot;server.dtd&quot;&gt;&lt;mycat:server xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;system&gt; &lt;property name=&quot;charset&quot;&gt;utf8&lt;/property&gt; &lt;property name=&quot;nonePasswordLogin&quot;&gt;0&lt;/property&gt; &lt;!-- 0为需要密码登陆、1为不需要密码登陆 ,默认为0，设置为1则需要指定默认账户--&gt; &lt;property name=&quot;useHandshakeV10&quot;&gt;1&lt;/property&gt; &lt;property name=&quot;useSqlStat&quot;&gt;0&lt;/property&gt; &lt;!-- 1为开启实时统计、0为关闭 --&gt; &lt;property name=&quot;useGlobleTableCheck&quot;&gt;0&lt;/property&gt; &lt;!-- 1为开启全加班一致性检测、0为关闭 --&gt; &lt;property name=&quot;sequnceHandlerType&quot;&gt;2&lt;/property&gt; &lt;property name=&quot;subqueryRelationshipCheck&quot;&gt;false&lt;/property&gt; &lt;!-- 子查询中存在关联查询的情况下,检查关联字段中是否有分片字段 .默认 false --&gt; &lt;!-- &lt;property name=&quot;useCompression&quot;&gt;1&lt;/property&gt;--&gt; &lt;!--1为开启mysql压缩协议--&gt; &lt;!-- &lt;property name=&quot;fakeMySQLVersion&quot;&gt;5.6.20&lt;/property&gt;--&gt; &lt;!--设置模拟的MySQL版本号--&gt; &lt;!-- &lt;property name=&quot;processorBufferChunk&quot;&gt;40960&lt;/property&gt; --&gt; &lt;!-- &lt;property name=&quot;processors&quot;&gt;1&lt;/property&gt; &lt;property name=&quot;processorExecutor&quot;&gt;32&lt;/property&gt; --&gt; &lt;!--默认为type 0: DirectByteBufferPool | type 1 ByteBufferArena | type 2 NettyBufferPool --&gt; &lt;property name=&quot;processorBufferPoolType&quot;&gt;0&lt;/property&gt; &lt;!--默认是65535 64K 用于sql解析时最大文本长度 --&gt; &lt;!--&lt;property name=&quot;maxStringLiteralLength&quot;&gt;65535&lt;/property&gt;--&gt; &lt;!--&lt;property name=&quot;sequnceHandlerType&quot;&gt;0&lt;/property&gt;--&gt; &lt;!--&lt;property name=&quot;backSocketNoDelay&quot;&gt;1&lt;/property&gt;--&gt; &lt;!--&lt;property name=&quot;frontSocketNoDelay&quot;&gt;1&lt;/property&gt;--&gt; &lt;!--&lt;property name=&quot;processorExecutor&quot;&gt;16&lt;/property&gt;--&gt; &lt;!-- &lt;property name=&quot;serverPort&quot;&gt;8066&lt;/property&gt; &lt;property name=&quot;managerPort&quot;&gt;9066&lt;/property&gt; &lt;property name=&quot;idleTimeout&quot;&gt;300000&lt;/property&gt; &lt;property name=&quot;bindIp&quot;&gt;0.0.0.0&lt;/property&gt; &lt;property name=&quot;frontWriteQueueSize&quot;&gt;4096&lt;/property&gt; &lt;property name=&quot;processors&quot;&gt;32&lt;/property&gt; --&gt; &lt;!--分布式事务开关，0为不过滤分布式事务，1为过滤分布式事务（如果分布式事务内只涉及全局表，则不过滤），2为不过滤分布式事务,但是记录分布式事务日志--&gt; &lt;property name=&quot;handleDistributedTransactions&quot;&gt;0&lt;/property&gt; &lt;property name=&quot;useOffHeapForMerge&quot;&gt;1&lt;/property&gt;&lt;!--off heap for merge/order/group/limit 1开启 0关闭--&gt; &lt;property name=&quot;memoryPageSize&quot;&gt;64k&lt;/property&gt; &lt;!--单位为m--&gt; &lt;property name=&quot;spillsFileBufferSize&quot;&gt;1k&lt;/property&gt;&lt;!--单位为k--&gt; &lt;property name=&quot;useStreamOutput&quot;&gt;0&lt;/property&gt; &lt;property name=&quot;systemReserveMemorySize&quot;&gt;384m&lt;/property&gt;&lt;!--单位为m--&gt; &lt;property name=&quot;useZKSwitch&quot;&gt;false&lt;/property&gt;&lt;!--是否采用zookeeper协调切换 --&gt; &lt;!-- XA Recovery Log日志路径 --&gt; &lt;!--&lt;property name=&quot;XARecoveryLogBaseDir&quot;&gt;./&lt;/property&gt;--&gt; &lt;!-- XA Recovery Log日志名称 --&gt; &lt;!--&lt;property name=&quot;XARecoveryLogBaseName&quot;&gt;tmlog&lt;/property&gt;--&gt; &lt;!--如果为 true的话 严格遵守隔离级别,不会在仅仅只有select语句的时候在事务中切换连接--&gt; &lt;property name=&quot;strictTxIsolation&quot;&gt;false&lt;/property&gt; &lt;property name=&quot;useZKSwitch&quot;&gt;true&lt;/property&gt; &lt;/system&gt; &lt;!-- 全局SQL防火墙设置 --&gt; &lt;!--白名单可以使用通配符%或着*--&gt; &lt;!--例如&lt;host host=&quot;127.0.0.*&quot; user=&quot;root&quot;/&gt;--&gt; &lt;!--例如&lt;host host=&quot;127.0.*&quot; user=&quot;root&quot;/&gt;--&gt; &lt;!--例如&lt;host host=&quot;127.*&quot; user=&quot;root&quot;/&gt;--&gt; &lt;!--例如&lt;host host=&quot;1*7.*&quot; user=&quot;root&quot;/&gt;--&gt; &lt;!--这些配置情况下对于127.0.0.1都能以root账户登录--&gt; &lt;!-- &lt;firewall&gt; &lt;whitehost&gt; &lt;host host=&quot;1*7.0.0.*&quot; user=&quot;root&quot;/&gt; &lt;/whitehost&gt; &lt;blacklist check=&quot;false&quot;&gt; &lt;/blacklist&gt; &lt;/firewall&gt; --&gt; &lt;!--name登录的用户名，也就是连接Mycat的用户名--&gt; &lt;user name=&quot;root&quot; defaultAccount=&quot;true&quot;&gt; &lt;!--password 登录的密码，也就是连接Mycat的密码--&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;!--schemas 数据库名，这里会和schema.xml中的配置关联，多个用逗号分开，例如需要这个用户需要管理两个数据库db1,db2，则配置db1,dbs--&gt; &lt;property name=&quot;schemas&quot;&gt;TESTDB&lt;/property&gt; &lt;!-- 表级 DML 权限设置 对用户的 schema以及表进行精细化的DML权限控制 check 表示是否开启DML权限检查。默认是关闭。server.dtd文件中 &lt;!ELEMENT privileges (schema)*&gt; 说明可以有多个schema的配置。 dml 顺序说明：insert,update,select,delete db1的权限是update,select。 tb01的权限是啥都不能干。 tb02的权限是insert,update,select,delete。 其他表默认是udpate,select。 --&gt; &lt;!-- &lt;privileges check=&quot;false&quot;&gt; &lt;schema name=&quot;TESTDB&quot; dml=&quot;0110&quot; &gt; &lt;table name=&quot;tb01&quot; dml=&quot;0000&quot;&gt;&lt;/table&gt; &lt;table name=&quot;tb02&quot; dml=&quot;1111&quot;&gt;&lt;/table&gt; &lt;/schema&gt; &lt;/privileges&gt; --&gt; &lt;/user&gt; &lt;user name=&quot;user&quot;&gt; &lt;property name=&quot;password&quot;&gt;user&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;TESTDB&lt;/property&gt; &lt;property name=&quot;readOnly&quot;&gt;true&lt;/property&gt; &lt;/user&gt;&lt;/mycat:server&gt; rule.xml配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mycat:rule SYSTEM &quot;rule.dtd&quot;&gt;&lt;mycat:rule xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;!--对表进行拆分所涉及到的规则定义。我们可以灵活的对表使用不同的分片算法，或者对表使用相同的算法但具体的参数不同。 name 属性指定唯一的名字，用于标识不同的表规则。 内嵌的 rule 标签则指定对物理表中的哪一列进行拆分和使用什么路由算法。 columns 内指定要拆分的列名字。 algorithm 使用 function 标签中的 name 属性。连接表规则和具体路由算法。当然，多个表规则可以连接到 同一个路由算法上。table 标签内使用。让逻辑表使用这个规则进行分片。 --&gt; &lt;tableRule name=&quot;rule1&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;func1&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;tableRule name=&quot;rule2&quot;&gt; &lt;rule&gt; &lt;columns&gt;user_id&lt;/columns&gt; &lt;algorithm&gt;func1&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;tableRule name=&quot;sharding-by-intfile&quot;&gt; &lt;rule&gt; &lt;columns&gt;sharding_id&lt;/columns&gt; &lt;algorithm&gt;hash-int&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;tableRule name=&quot;auto-sharding-long&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;rang-long&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;tableRule name=&quot;mod-long&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;mod-long&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;tableRule name=&quot;sharding-by-murmur&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;murmur&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;tableRule name=&quot;crc32slot&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;crc32slot&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;tableRule name=&quot;sharding-by-month&quot;&gt; &lt;rule&gt; &lt;columns&gt;create_time&lt;/columns&gt; &lt;algorithm&gt;partbymonth&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;tableRule name=&quot;latest-month-calldate&quot;&gt; &lt;rule&gt; &lt;columns&gt;calldate&lt;/columns&gt; &lt;algorithm&gt;latestMonth&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;tableRule name=&quot;auto-sharding-rang-mod&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;rang-mod&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;tableRule name=&quot;jch&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;jump-consistent-hash&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;!-- name 指定算法的名字。 class 制定路由算法具体的类名字。 property 为具体算法需要用到的一些属性。--&gt; &lt;function name=&quot;murmur&quot; class=&quot;io.mycat.route.function.PartitionByMurmurHash&quot;&gt; &lt;property name=&quot;seed&quot;&gt;0&lt;/property&gt;&lt;!-- 默认是0 --&gt; &lt;property name=&quot;count&quot;&gt;2&lt;/property&gt;&lt;!-- 要分片的数据库节点数量，必须指定，否则没法分片 --&gt; &lt;property name=&quot;virtualBucketTimes&quot;&gt;160&lt;/property&gt;&lt;!-- 一个实际的数据库节点被映射为这么多虚拟节点，默认是160倍，也就是虚拟节点数是物理节点数的160倍 --&gt; &lt;!-- &lt;property name=&quot;weightMapFile&quot;&gt;weightMapFile&lt;/property&gt; 节点的权重，没有指定权重的节点默认是1。以properties文件的格式填写，以从0开始到count-1的整数值也就是节点索引为key，以节点权重值为值。所有权重值必须是正整数，否则以1代替 --&gt; &lt;!-- &lt;property name=&quot;bucketMapPath&quot;&gt;/etc/mycat/bucketMapPath&lt;/property&gt; 用于测试时观察各物理节点与虚拟节点的分布情况，如果指定了这个属性，会把虚拟节点的murmur hash值与物理节点的映射按行输出到这个文件，没有默认值，如果不指定，就不会输出任何东西 --&gt; &lt;/function&gt; &lt;function name=&quot;crc32slot&quot; class=&quot;io.mycat.route.function.PartitionByCRC32PreSlot&quot;&gt; &lt;/function&gt; &lt;function name=&quot;hash-int&quot; class=&quot;io.mycat.route.function.PartitionByFileMap&quot;&gt; &lt;property name=&quot;mapFile&quot;&gt;partition-hash-int.txt&lt;/property&gt; &lt;/function&gt; &lt;function name=&quot;rang-long&quot; class=&quot;io.mycat.route.function.AutoPartitionByLong&quot;&gt; &lt;property name=&quot;mapFile&quot;&gt;autopartition-long.txt&lt;/property&gt; &lt;/function&gt; &lt;function name=&quot;mod-long&quot; class=&quot;io.mycat.route.function.PartitionByMod&quot;&gt; &lt;!-- how many data nodes --&gt; &lt;property name=&quot;count&quot;&gt;3&lt;/property&gt; &lt;/function&gt; &lt;function name=&quot;func1&quot; class=&quot;io.mycat.route.function.PartitionByLong&quot;&gt; &lt;property name=&quot;partitionCount&quot;&gt;8&lt;/property&gt; &lt;property name=&quot;partitionLength&quot;&gt;128&lt;/property&gt; &lt;/function&gt; &lt;function name=&quot;latestMonth&quot; class=&quot;io.mycat.route.function.LatestMonthPartion&quot;&gt; &lt;property name=&quot;splitOneDay&quot;&gt;24&lt;/property&gt; &lt;/function&gt; &lt;function name=&quot;partbymonth&quot; class=&quot;io.mycat.route.function.PartitionByMonth&quot;&gt; &lt;property name=&quot;dateFormat&quot;&gt;yyyy-MM-dd&lt;/property&gt; &lt;property name=&quot;sBeginDate&quot;&gt;2015-01-01&lt;/property&gt; &lt;/function&gt; &lt;function name=&quot;rang-mod&quot; class=&quot;io.mycat.route.function.PartitionByRangeMod&quot;&gt; &lt;property name=&quot;mapFile&quot;&gt;partition-range-mod.txt&lt;/property&gt; &lt;/function&gt; &lt;function name=&quot;jump-consistent-hash&quot; class=&quot;io.mycat.route.function.PartitionByJumpConsistentHash&quot;&gt; &lt;property name=&quot;totalBuckets&quot;&gt;3&lt;/property&gt; &lt;/function&gt;&lt;/mycat:rule&gt; 暂时在mysql测试是可以的。 oracle链接的时候，jdbc一直无法链接。后期在正式环境使用的时候，在记录吧！ mycat的权威指南链接： http://www.mycat.io/document/Mycat_V1.6.0.pdf]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>MyCat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oracle －学习笔记]]></title>
    <url>%2Fdatabase%2Foracle.html</url>
    <content type="text"><![CDATA[一些sql语句123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171-- 时间格式化to_date(&apos;2019-01-28&apos;, &apos;yyyy-mm-dd&apos;)TO_DATE(&apos;2018-1-21 17:21:11&apos;, &apos;YYYY-MM-DD HH24:MI:SS&apos;)-- 删除表空间以及内容drop tablespace tablespace_name including contents and datafiles;-- 查看oracle库的表空间以及使用情况select sum(bytes)/(1024*1024) as free_space,tablespace_name from dba_free_space group by tablespace_name; -- 服务器表空间的存储位置select tablespace_name,file_name,bytes/1024/1024 file_size,autoextensible from dba_temp_files;-- 创建临时表空间create temporary tablespace test_temptempfile &apos;/u01/app/oracle/oradata/XE/test_temp.dbf&apos;size 32mautoextend onnext 32m maxsize unlimitedextent management local;-- 创建表空间create tablespace test_dataloggingdatafile &apos;/u01/app/oracle/oradata/XE/test-data.dbf&apos;size 32mautoextend onnext 32m maxsize unlimitedextent management local;-- 创建用户create user test identified by manageraccount unlockdefault tablespace test_datatemporary tablespace test_temp;-- 授权给用户 grant connect,resource,dba to test;-- 创建索引CREATE UNIQUE INDEX ID_EQ ON TABLENAME (ID);-- 创建非唯一索引CREATE INDEX ID_EQ ON TABLENAME (ID);-- 查询当前被锁的对象 select t2.username, t2.sid, t2.serial#, t2.logon_timefrom v$locked_object t1, v$session t2where t1.session_id = t2.sidorder by t2.logon_time -- 杀会话136,45267为对应的ID ALTER SYSTEM KILL SESSION &apos;136,45267&apos;-- 普通查询（硬解析）SELECT * FROM TEST.DC_PROJECT WHERE SEQ_ID = 1-- 绑定变量查询（软解析）SELECT * FROM TEST.DC_PROJECT WHERE SEQ_ID = :SEQ_IDCREATE TABLE t (x int); -- 创建t表DELETE FROM TEST.T; -- 删除表数据-- 循环给t表添加100条数据 （硬解析）DECLARE i number := 0;BEGIN FOR i IN 1 .. 100 LOOP INSERT INTO TEST.T VALUES (i); END LOOP;COMMIT;END;-- 循环给t表添加100条数据(软解析）相比于硬解析快20倍（未验证， oracle编程艺术书解释）DECLARE i number := 0;BEGIN FOR i IN 1 .. 100 LOOP EXECUTE IMMEDIATE &apos;INSERT INTO TEST.T VALUES ( :X )&apos; USING i; END LOOP;COMMIT;END;-- 查看oracle版本select * from v$versionselect version from v$instance;Select version FROM Product_component_version Where SUBSTR(PRODUCT,1,6)=&apos;Oracle&apos;;-- SQL&gt;：查看当前的数据库参数undo_retention设置（闪回时间）SQL&gt;：show parameter undo-- 修改系统的undo_retention时间ALTER SYSTEM SET undo_retention=10800 SCOPE=BOTH;-- SQL&gt;：闪回测试SQL&gt;：variable scn NUMBERSQL&gt;：EXEC :scn := dbms_flashback.get_system_change_number;SQL&gt;：print scn;-- 查看闪回是否开启select flashback_on from V$database;-- 开启闪回alter system set db_recovery_file_dest_size=2G scope=both;alter system set db_recovery_file_dest=&apos;/u01/app/oracle/oradata/XE/flashback&apos; scope=both;root: su - oracle -- 必须用oracle用户访问 linux命令行执行oracle: sqlplus /nolog -- 进入sqlplus控制台 linux命令行执行SQL&gt;：connect / as sysdba -- 系统管理员登陆SQL&gt;：shutdown IMMEDIATE; -- 不允许新的连接、不等待会话结束、不等待事务结束、做一个检查点并关闭数据文件。没有结束的事务是自动ROLLBACK的。启动时不需要实例恢复。SQL&gt;：startup mount; -- mount数据库，仅仅给dba进行管理操作，不允许数据库的用户访问。仅仅只是当前实例的控制文件被打开，数据文件未打开。SQL&gt;：alter database archivelog; -- 归档日志SQL&gt;：alter database flashback on; -- 闪回开启 报错：ORA-00439: feature not enabled: Flashback Database 。 oracle的标准版和标准1版均不支持！只有购买了企业版本才支持flashback.SQL&gt;：alter database open; -- 打开数据库-- 闪回查询（在某个时间节点表做了什么）select count(*), :scn then_scn, dbms_flashback.get_system_change_number now_scn from test.emp as of scn :scn;-- 闪回查询（同一个对象在两个时间节点所做的事情）select count(*), :scn then_scn, dbms_flashback.get_system_change_number now_scn from (select count(*) cnt_now from test.emp), (select count(*) cnt_then from test.emp as of scn :scn-- 查询资源被锁的简单信息select username,object_name, sid,serial#,logon_time from v$locked_object,v$session, dba_objects where v$locked_object.session_id=v$session.sid AND dba_objects.object_id =v$locked_object.object_id ;/** 查询资源被锁的详细信息 v$locked_object 视图中记录了所有session中的所有被锁定的对象信息。 v$session 视图记录了所有session的相关信息。 dba_objects 为oracle用户对象及系统对象的集合，通过关联这张表能够获取被锁定对象的详细信息。 username：oracle用户名 sid：进程号 serial#：序列号 object_name：表名 osuser：操作系统用户名 machine：机器名 program：操作工具 logon_time：登陆时间 lockwait：表示当前这张表是否正在等待其他用户解锁这张表 locked_mode：锁表模式（下面详细说明） 0：none 1：null 空 2：Row-S 行共享(RS)：共享表锁，sub share 3：Row-X 行独占(RX)：用于行的修改，sub exclusive 4：Share 共享锁(S)：阻止其他DML操作，share 5：S/Row-X 共享行独占(SRX)：阻止其他事务操作，share/sub exclusive 6：exclusive 独占(X)：独立访问使用，exclusive 1级锁有：Select，有时会在v$locked_object出现。 2级锁有：Select for update,Lock For Update,Lock Row Share select for update当对话使用for update子串打开一个游标时，所有返回集中的数据行都将处于行级(Row-X)独占式锁定，其他对象只能查询这些数据行，不能进行update、delete或select for update操作。 3级锁有：Insert, Update, Delete, Lock Row Exclusive 没有commit之前插入同样的一条记录会没有反应, 因为后一个3的锁会一直等待上一个3的锁, 我们必须释放掉上一个才能继续工作。 4级锁有：Create Index, Lock Share locked_mode为2,3,4不影响DML(insert,delete,update,select)操作, 但DDL(alter,drop等)操作会提示ora-00054错误。 00054, 00000, “resource busy and acquire with NOWAIT specified” // *Cause: Resource interested is busy. // *Action: Retry if necessary. 5级锁有：Lock Share Row Exclusive 具体来讲有主外键约束时update / delete … ; 可能会产生4,5的锁。 6级锁有：Alter table, Drop table, Drop Index, Truncate table, Lock Exclusive */select t2.LOGON_TIME,t2.username,t2.sid,t2.serial#,t3.object_name,t1.LOCKED_MODE,t2.OSUSER,t2.MACHINE,t2.PROGRAM,t2.COMMAND,t2.LOCKWAITfrom v$locked_object t1, v$session t2, dba_objects t3 where t1.session_id = t2.sid and t1.object_id = t3.object_id order by t2.logon_time;--查某session 正在执行的sql语句，从而可以快速定位到哪些操作或者代码导致事务一直进行没有结束等.SELECT sql_text FROM v$sqltext a WHERE (a.hash_value, a.address) IN(SELECT DECODE(sql_hash_value, 0, prev_hash_value, sql_hash_value),DECODE(sql_hash_value, 0, prev_sql_addr, sql_address)FROM v$session b WHERE b.sid = &apos;665&apos;) ORDER BY piece ASC;-- kill 资源被锁alter system kill session &apos;988,24597&apos;-- 查看链接数select username,count(username) from v$session where username is not null group by username-- 查看表的剩余空间,是否自动扩展，可以自动扩展的最大值select FILE_NAME,TABLESPACE_NAME,BYTES/1024/1024 BYTES_M, MAXBYTES/1024/1024 MAX_M,AUTOEXTENSIBLE from dba_data_files;-- 查看表的表空间select tablespace_name,table_name from user_tables where table_name=&apos;TABLE_NAME&apos;;-- 查看表的实际使用情况，和剩余空间select f.tablespace_name tablespace_name,round((d.sumbytes/1024/1024)) total_m,round((d.sumbytes-f.sumbytes)/1024/1024) used_m,round(f.sumbytes/1024/1024,2) free_m,round((d.sumbytes-f.sumbytes)*100/d.sumbytes,2)||&apos;%&apos; used_percent,round((f.sumbytes)*100/d.sumbytes,2)||&apos;%&apos; free_percent from (select tablespace_name,sum(bytes) sumbytes from dba_free_space group by tablespace_name) f,(select tablespace_name,sum(bytes) sumbytes from dba_data_files group by tablespace_name) d where f.tablespace_name= d.tablespace_name(+) order by (d.sumbytes-f.sumbytes)*100/d.sumbytes desc;]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop学习笔记]]></title>
    <url>%2Ftool%2Fhadoop.html</url>
    <content type="text"><![CDATA[安装hadoop 在apache官网下载. 找到发布版本通过wget下载.gz的安装包。 1wget http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-3.1.1/hadoop-3.1.1.tar.gz 解压安装包 1tar zxvf hadoop-3.1.1.tar.gz hadoop环境变量 1234567891011121314151617sudo vi ~/.bashrc // 编辑环境变量的文件，并在最后追加如下内容。#HADOOP VARIABLES STARTexport HADOOP_INSTALL=/usr/hadoop/hadoop-3.1.1 // hadoop解压路径export PATH=$PATH:$HADOOP_INSTALL/binexport PATH=$PATH:$HADOOP_INSTALL/sbinexport HADOOP_MAPRED_HOME=$HADOOP_INSTALLexport HADOOP_COMMON_HOME=$HADOOP_INSTALLexport HADOOP_HDFS_HOME=$HADOOP_INSTALLexport YARN_HOME=$HADOOP_INSTALLexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_INSTALL/lib/nativeexport HADOOP_OPTS=&quot;-Djava.library.path=$HADOOP_INSTALL/lib&quot;#HADOOP VARIABLES ENDsource ~/.bashrc //生效hadoop version // 验证是否生效，查看版本 编辑/etc/hadoop/hadoop-env.sh的默认jdk路径 1JAVA_HOME=/usr/java-jdk //添加JAVA_HOME路径。不知道路径可以用echo $JAVA_HOME查看 配置hadoop/etc/hadoop/core-site.xml文件 12345678910111213&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;!-- hadoop数据存储路径 --&gt; &lt;value&gt;file:/usr/hadoop/hadoop-3.1.1/tmp&lt;/value&gt; &lt;description&gt;Abase for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;!-- hadoop访问路径 --&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置hadoop/etc/hadoop/hdfs-site.xml文件 1234567891011121314151617&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;!-- 副本份数 --&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;!-- namenode路径 --&gt; &lt;value&gt;file:/usr/hadoop/hadoop-3.1.1/tmp/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;!-- datanode路径 --&gt; &lt;value&gt;file:/usr/hadoop/hadoop-3.1.1/tmp/dfs/data&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置hadoop/etc/hadoop/yarn-site.xml文件 12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置hadoop/etc/hadoop/mapred-site.xml文件 12345678mv mapred-queues.xml.template mapred-queues.xml // 重命名mapred-queues.xml.template文件&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;value&gt;localhost:9001&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 格式化hadoop 12cd hadoop/bin ./hadoop // 应该2.8版本前需要初始化，3.1.1直接格式化一下 hadoop namenode -format 启动hadoop 12345678910在sbin文件夹下依次执行：start-dfs.sh start-yarn.sh 如果报错：ERROR: Attempting to launch hdfs namenode as root 需要在start-dfs.sh和sbin/stop-dfs.sh 顶部空白处添加内容：HDFS_DATANODE_USER=root HDFS_DATANODE_SECURE_USER=hdfs HDFS_NAMENODE_USER=root HDFS_SECONDARYNAMENODE_USER=root]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lead in开班笔记]]></title>
    <url>%2Fenglish%2Fleadin.html</url>
    <content type="text"><![CDATA[Lead in开班笔记名词 可数名词才有单复数变化，不可数名词一般只有单数形式，没有复数形式。物质名词和抽象名词借助单位词表示一定的数量,如：a cup of tea, a loaf of bread。 有些物质和抽象名词变为复数后意义就不一样了，如：air &gt; airs （神气）, good &gt; goods (商品), time &gt; times (时代）等。 规则变化 规则 单数变复数方式 例子 一般情况 直接加s map &gt; maps, car &gt; cars 以s,x,ch,sh 直接加es bus &gt; buses, box &gt; boxes 以y结尾 辅音+y结尾为i加es,元音直接s boy &gt; boys, baby &gt; babies 以f或fe结尾 变f／fe为ves wife &gt; wives, leaf &gt; leaves 以o结尾 有生命的加es，否则加s radio &gt; radios, hero &gt; heroes 特例 zero –&gt; zero(e)s. // 可加可不加 以y结尾的专有名词，若在某些特殊情况下需要用复数形式，通常直接加s。 不规则变化 规则 例子 改变单数名词中的元音字母 foot &gt; feet, tooth &gt; teeth 在词尾加-en 或 -ren child &gt; children 变man为men man &gt; men 单复数同形 series &gt; series 名称 总称（谓语用复数） 一个人 两个人 中国人 the Chinese a Chinese two Chinese 日本人 the Japanese a Japanese two Japanses 法国人 the French a Frenchman two Frenchmen 英国人 the English an Englishman two Englishmen 澳大利亚人 the Australians an Australian two Australians 德国人 the Germans a German two Germans 美国人 the Americans an American two Americans 俄国人 the Russians a Russian two Russians 复合词 变化方式 例子 变中心词 a son-in-low &gt; a sons-in-law 在最后加s a grown-up &gt; a grown-ups 前后名词变 woman doctor &gt; women doctors boy/girl在前，变后面词 a boy student &gt; a boy &gt; students 少数名词，单复数同形 sheep, people 名词所有格 名称 例子 解释 ‘s Tom’ pens the fox’s tail.各自拥有的Lily’s and Lucy’s root.共同拥有的 主要用于人或动物等有生命的名词词尾，有时用于时间、距离、国家、城市等。 of a photo of the family 表示无生命的名词的所有关系 双重 a photo of mime 由’s和of一起构成的即是双重所有格 句子种类陈述句 主－谓－宾 主－系－表 疑问句封闭式 Yes/No 人称代词基础版 第一人称 第二人称 第三人称 单数 I You She/He/It 复数 We You They 例子 肯定句 否定句 一般疑问句 I I play I don’t play Do you play? You You help You don’t help Do you help? He He answers He does not answer Does he answer? She She sings She does not sing Does she sing? It It rains It does not rain Does it rain? We We dream We does not dream Do we dream? You You read You does not read Do you read? They They work They don’t work Do they work? 123456789101112笔记：// 一般陈述句转一般疑问句在动词前加Do(第三人称单数用Does, 非三单用Do） not，其他的照搬。（加s/es，变y为i加es）// 第三人称单数的动词后要加s，非三单的动词为原型。// 西洋乐器动词前面加the， 运动项目的动词前不加the1. 为什么It rains后面加s，而It does not rain的rain不加s。 答： 一个三单的句子，动词已经加s了，后面的就不加s。2. 需要注意的如：My best friend seldom studies. 这个主要看friend这个词，friend是第三人称单数，所以study要变形为studies（加s）。3. He answers. 第三人单数加s？？？？？4. Do you play? 为什么不是Do i play? 答：第一人称转第二人称疑问句时，要将i变为you5. He has a bath every day. 转为： He doesn&apos;t have bath every day. 注意：has的原型为have， 不能照搬为has。 人称代词加强版 人称代词 主格 宾格 形容词性物主代词 名词性物主代词 第一人称单数 I Me My Mine 第二人称单数 You You Your Yours 第三人称单数 He/She/It Him/Her/It His/Her/Its His/Hers/Its 第一人称复数 We Us Our Ours 第二人称复数 You You Your Yours 第三人称复数 They Them Their Theirs 12// 名词性物主代词 ＝ 形容词物主代词 ＋ 名词// 形容词物主代词 ＝ 形容词 开放性 wh开头12345What is your name? // 你叫什么名字？Where do you live in? // 你住在那里？Who do you work for? // 你为谁工作When do you play basketball. // 你什么时候打篮球When do he plays basketball. // 他什么时候打篮球]]></content>
      <categories>
        <category>english</category>
      </categories>
      <tags>
        <tag>englishLearning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker模拟集群并进行代码同步功能的练习记录]]></title>
    <url>%2Ftool%2FdockerRsync.html</url>
    <content type="text"><![CDATA[多个服务器同步的需求，利用rsync就可以实现。线上正式环境中无法进行测试，因此只能在本地进行测试，测试通过之后才可以在线上进行运行。虚拟机和docker我就不犹豫的选择了docker。看了下docker的文档，pull了ubuntu的进行模拟测试。 dockerdocker Toolbox 更改镜像源12345678910111213// 临时处理docker-machine ssh default // 先进入虚拟机，default 是默认的虚拟机名称sudo vi /var/lib/boot2docker/profile // 编辑这个文件，添加镜像源 --registry-mirror https://registry.docker-cn.comsudo /etc/init.d/docker restart // 重启 docker 进程exit // 退出虚拟机docker info // 看一下镜像源是否设置成功（是否有刚刚设置的 --registry-mirror 这一行）docker pull nginx // 现在可以愉快地拉取`nginx`镜像了// 永久解决修改启动脚本 start.sh 注释掉 yes | &quot;$&#123;DOCKER_MACHINE&#125;&quot; regenerate-certs &quot;$&#123;VM&#125;&quot;if [ &quot;$&#123;VM_STATUS&#125;&quot; != &quot;Running&quot; ]; then &quot;$&#123;DOCKER_MACHINE&#125;&quot; start &quot;$&#123;VM&#125;&quot; # yes | &quot;$&#123;DOCKER_MACHINE&#125;&quot; regenerate-certs &quot;$&#123;VM&#125;&quot;fi docker 构建脚本1234567891011121314151617181920212223242526272829FROM ubuntu:18.04# 签名MAINTAINER ln &quot;1073825890@qq.com&quot;# 添加本地jdk到服务器ADD jdk-8u191-linux-x64.tar /usr/local# 添加本地tomcat到服务器ADD apache-tomcat-8.5.37.tar.gz /usr/local# 添加项目到tomcat的webapps文件中ADD dpm.war /usr/local/apache-tomcat-8.5.37/webapps# ADD时自动解压了，否则需要解压#RUN tar -xzvf /usr/local/jdk-8u191#RUN rm /usr/local/jdk-8u191-linux-x64.tar#环境变量ENV JAVA_HOME /usr/lib/jvm/java-8-oracle/ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarENV PATH $PATH:$JAVA_HOME/bin# 设置中文ENV LANG C.UTF-8RUN mkdir -p /usr/lib/jvm \ &amp;&amp; mv /usr/local/jdk1.8.0_191/ /usr/lib/jvm/java-8-oracle/ \ &amp;&amp; apt-get update \ &amp;&amp; apt-get install net-tools -y \ &amp;&amp; apt-get install curl -y \ &amp;&amp; apt-get install vim -y \ &amp;&amp; apt-get install rsync -y \ &amp;&amp; apt-get install openssh-server -y \ &amp;&amp; echo &quot;PermitRootLogin yes&quot; &gt;&gt; /etc/ssh/sshd_config \ &amp;&amp; echo &quot;Port 8000&quot; &gt;&gt; /etc/ssh/sshd_config \# &amp;&amp; sudo /etc/init.d/ssh stop &amp;&amp; sudo /etc/init.d/ssh start docker常用命令123456789101112docker build -t java:image . // 用docker脚本进行构建项目docker image ls // 查看镜像docker run --name=application001 -p 8888:8080 -itd ab // 将本地的8888端口映射到docker应用的8080端口以交互模式重新分配一个伪输入终端在后台运行容器docker exec -it ab /bin/bash // 进入应用的命令行页面docker stop ab // 停止应用 ab为ID或名词docker start ab // 启动应用docker rm ab // 删除未运行的应用docker image rm ab // 删除镜像， 删除镜像时需要删除应用，删除应用时需要停止应用docker inspect mycat // 检查docker运行的容器iptables -t nat -A docker -p tcp --dport 2222 -j DNAT --to-destination 172.17.0.2:22 // 把本地的2222映射到172.17.0.2的22端口上面。docker port id // 查看映射端口， 映射的端口直接用127.0.0.1访问 通过构建docker &gt; 查看镜像 &gt; 运行应用 &gt; 进入ubuntu命令行完成整个构建过程。强大的docker使用就这么简单的几步就把应用启动起来了。运行的时候可以用不同的端口运行多个应用。 rsync同步代码 rsync服务端需要安装sshpass、ssh、rsync才能进行同步 脚本 123456789101112131415161718192021222324252627282930313233#/bin/bash# 当前服务器项目绝对路径fromPath=/usr/local/apache-tomcat-8.5.37/webapps/dpm/WEB-INF/classes/templates/# tomcat里面的相对路径toPath=/webapps/dpm/WEB-INF/classes/templates# 依次为：IP 端口号 TOMCAT路径 SSH密码 登陆用户名。 多个服务器用如：(&quot;172.17.0.2 8000 /usr/local/apache-tomcat-8.5.37 123456&quot; &quot;172.17.0.2 8000 /usr/local/apache-tomcat-8.5.37 123456&quot;)注意中间空格隔开。 创建的是一个shell的二维数组servers=(&quot;172.17.0.2 8000 /usr/local/apache-tomcat-8.5.37 123456 root&quot;)currentDate=`date &quot;+%Y-%m-%d %H:%M:%S&quot;`input=$1rsyncFun()&#123; echo &quot;$&#123;currentDate&#125; INFO:rsync start !!!&quot; for key in $&#123;!servers[@]&#125; do server=($&#123;servers[$key]&#125;) rsync -e &quot;sshpass -p $&#123;server[3]&#125; ssh -p $&#123;server[1]&#125;&quot; -avH $&#123;fromPath&#125; $&#123;server[4]&#125;@$&#123;server[0]&#125;:$&#123;server[2]&#125;$&#123;toPath&#125; if [ -n &quot;$&#123;input&#125;&quot; ] then # 注意tomcat的bin目录下setclasspath.sh文件里面的JAVA_HOME和JRE_HOME是否正常.如&gt;果报错需要在if上方增加JAVA_HOME=/usr/lib/jvm/java-8-oracle和JRE_HOME=/usr/lib/jvm/java-8-oracle/jre sshpass -p $&#123;server[3]&#125; ssh -p $&#123;server[1]&#125; $&#123;server[4]&#125;@$&#123;server[0]&#125; &quot;sh $&#123;server[2]&#125;/bin/shutdown.sh&quot; sshpass -p $&#123;server[3]&#125; ssh -p $&#123;server[1]&#125; $&#123;server[4]&#125;@$&#123;server[0]&#125; &quot;sh $&#123;server[2]&#125;/bin/startup.sh&quot; fi done&#125;endDate=`date &quot;+%Y-%m-%d %H:%M:%S&quot;`timeFun()&#123; startTime=`date -d &quot;$currentDate&quot; +%s` entTime=`date -d &quot;$endDate&quot; +%s` return $(($entTime-$startTime))&#125;rsyncFuntimeFunecho &quot;$&#123;endDate&#125; INFO:rsync success!!! $?&quot; 运行的时候直接用bash fileName.sh进行启动，如果用sh fileName.sh启动的话，会报错。]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>linux docker rsync</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[归类记忆单词]]></title>
    <url>%2Fenglish%2Fmemory.html</url>
    <content type="text"><![CDATA[数字 1~10 one two three four five six seven eight nine ten 11~19 eleven twelve thirteen fourteen fifteen sixteen seventeen eighteen nineteen 20~100 twenty thirty forty fifty sixty seventy eighty ninety hundred 第1～第10 first second third fourth fifth sixth seventh eighth ninth tenth 第11～第20 eleventh twelfth thirteenth fourteenth fifteenth sixteenth seventeenth eighteenth nineteenth twenty 第30～第100 thirtieth fortieth fiftith Sixtieth Seventieth Eightieth Ninetieth Ninetieth 21: twenty-one, 第21: the twenty-first 星期和月份 星期一 星期二 星期三 星期四 星期五 星期六 星期天 monday tuesday wedensday thursday friday saturday sunday 一月 二月 三月 四月 五月 六月 january february march april may june 七月 八月 九月 十月 十一月 十二月 july august septemter october november december 名词 &gt; 形容词 &gt; 动词 &gt; 副词(频度) &gt; 场所 &gt; 句子 名词 客厅 living room / sitting room 厕所 bathroom / rest room 厨房 kitchen 餐厅 dinning room 卧室 bedroom / second lie 阳台 balcony 书房 study room 茶几 eat table 形容词 大 big/large-sized 中等大小 medium-sized 小 small-sized 宽敞 spacious 昏暗 dark ／ din 新 new 旧 old 明亮 bright 拥挤 narrow 动词 居住 watch TV 泡茶 make eat 喝茶 drink eat 吹牛 brag / talk horse / have a chat 玩电脑游戏 play computer games 看新闻 read news 洗衣服 wash clothes / do the laundany 洗碗筷 wash bowl 洗菜 wash food 做饭 make food / cook meals 洗脸 wash face 刷牙 brush teeth 洗澡 take a bath 频度副词(主语跟动词之间) usually 常常 often / frequently seldom 有时 sometimes 偶尔 once in a while never 从来不 我居住在中套户型的公寓里，公寓里面有三个房间，我的客厅很大很明亮，我经常晚上和我老妈在客厅看电视。 I live in a medium-sized apartment, there are three rooms in my apartment,my living room is large and bright, I often watch TV with my mom in the evening. I live in a small dorm. there are four rooms in my dorm, my living room is bright and clean. I only sleep every day.123456789英语语句 句子结构－主谓宾， 主系表）there be (什么地方有什么东西)！就近原则场所内的物品基本表述－出动作This is my bedroom, there is computer is on the desk.I always watch movie on my computer.电器： turn on 打开, turn off 关闭 wash^洗 clothes 衣服 bowl 碗 socks 袜子 car 汽车 hair 头发 hand 手 123456789101112131415161718192021222324252627282930313233343536373839404142washing clothes. // 洗衣服I&apos;m washing clothes. // 我洗衣服 I want to wash my clothes. // 我要洗衣服 现在时I will wash my clothes right away. // 我马上洗衣服 一般将来时I will wash my clothes tomorrow. // 我明天洗衣服 一般将来时I washed clothes yesterday. // 我昨天洗衣服 一般过去时do the washing up. // 洗碗I&apos;m do the washing up. // 我洗碗I want to wash the dishes // 我要洗碗I will wash the dishes right away. // 我马上洗碗I will wash the dishes tomorrow. // 我明天洗碗I washed the dishes yesterday. // 我昨天洗碗washing socks // 洗袜子I&apos;m washing socks. // 我洗碗I want to wash my socks. // 我要洗袜子I will wash my socks right away. // 我马上洗袜子I will wash my socks tomorrow. // 我明天洗袜子I washed clothes yesterday. // 我昨天洗袜子washing the car. // 洗汽车I wash the car. // 我洗车I want to wash the car. // 我要洗车I am washing the car right away. // 我马上洗车I will wash the car tomorrow. // 我明天要洗车I washed the car yesterday. // 我昨天洗车washing hair. // 洗头发I wash my hair. // 我洗头I want to my hair. // 我要洗头I will wash my hair right away. // 我马上洗头I will wash my hair tomorrow. // 我明天洗头I washed my hair yesterday. // 我昨天洗头washing hands. // 洗手I wash my hands. // 我洗手I want to wash my hands. // 我要洗手I will wash my hands right away. // 我马上洗手I will wash my hands tomorrow. // 我明天洗手I washed my hands yesterday. // 我昨天洗手 总结百度的动词变换方式（昨天干了什么……一般过去时: 动词＋ed） 直接加ed：work—— worked look——looked 以不发音e结尾的单词，直接加d：live ——lived hope——hoped use——used 以辅音字母+y结尾的，变y为i加ed：study—— studied carry——carried worry——worried 以重读闭音节结尾的，双写最后的辅音字母+ed：stop—— stopped plan——planned重读闭音节体现形式为辅-元-辅结构，例如nod,n为辅音，o为元音，d为辅音。 以ic结尾的动词，要把ic变成ick再加ed，如picnic→picnicked，traffic→trafficked 不规则变化的动词过去式：have—had are—were get—got say—said feel—felt do/does—did is—was go—wentdrink–drank eat–ate bring—-brought think—-thought buy—-bought catch—- caught teach —- taught sit—-sat wear—-wore cut—-cut sweep—-swept sleep——slept become—-became 以辅元辅结尾的加d 明天干什么……一般将来时: will + 动词 颜色 red 红色 green 绿色 purple 紫色 black 黑色 brown 棕色 bule 蓝色 yellow 黄色 white 白色 pink 粉红色 body body 身体 eye 眼睛 ear 耳朵 hand 手 foot 脚 tummy 胃 face 脸 nose 鼻子 mouth 嘴 hair 头发 lash 睫毛 ass 屁股 https://www.bilibili.com/video/av15390641/?p=4 第8节到10:58地方]]></content>
      <categories>
        <category>english</category>
      </categories>
      <tags>
        <tag>englishLearning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The fifth week of English learning]]></title>
    <url>%2Fenglish%2Fsort_out.html</url>
    <content type="text"><![CDATA[星期五单词(归类记忆) body 身体 eye 眼睛 ear 耳朵 hand 手 foot 脚 tummy 胃 face 脸 nose 鼻子 mouth 嘴 hair 头发 lash 睫毛 ass 屁股 星期三(初级英语学习方法 Lead-ing) 训练营学习内容 词性＋记忆 句子成分和结构 常见句子种类 基本实用时态－一般时 基本实用时态－景象 精讲精练－全盘大复习 词性＋记忆单词方法 名词 第一位， 动作给予 动词 形容词 I 用am 第三人称单数用is 其他用are 星期一 winter 冬季 drum 击鼓 listen 倾听 music 音乐 piano 钢琴 come 来 read 读 love 爱 plan 飞机 ship 船 星期一 together 一起 play 玩 lion 狮子 like 喜欢 ping-pong 兵乓 football 足球 clothes 衣服 put on 穿上 sock 袜子 swim 游泳 星期四 get up 起床 party 聚会 trousers 裤子 dress 连衣裙 T-shirt t桖衫 favourite 特别喜欢的 really 真的 tomato 番茄 fruit 水果 milk 牛奶 句子成份（常用的五种基本句型） 《主语＋谓语》；《主语＋系动词＋表语》；《主语＋谓语＋宾语》；《主语＋谓语＋间接宾语＋直接宾语》；《主语＋谓语＋宾语＋宾语补足语》； 主语＋谓语： 特点：句子的谓语动词都能表达完整的意思。这类动词叫做不及物动词，后面可以跟副词、介词短语、状语从句等。 12345The moon ｜ rose. // 月亮升起The sun ｜ was shining. // 太阳照耀The pen | writes smoothly. // 这支笔书写流利 主语 ＋ 系动词 ＋ 表语 特点：句子谓语动词都不能表达一个完整的意思，必须加上一个表明主语身份或状态的表语构成复合谓语，才能表达完整的意思。 123This | is | an English-Chinese dictionary; //这是本英汉词典。He | is growing | tall and strong; // 他长的又高又壮 主语 ＋ 谓语 ＋ 宾语 谓语动词都具有实义，都是主语产生的动作，但不能表达完整的意思，必须跟一个宾语，即动作的承受者，才能使意思完整。 12345Who ｜ knows ｜ the answer? // 谁知道答案 He | enjoys | reading; // 他喜欢看书I | want | to have a cup of tea; // 我想喝杯茶 主语 ＋ 谓语 ＋ 间宾 ＋直宾 有些及物动词有两个宾语。这两个宾语通常一个指人，为间接宾语。一个指物，为直接宾语。间接宾语一般位于直接宾语之前。一般顺序：动词 ＋ 间接宾语 ＋ 直接宾语 123456789I | gave | my car | a wash. // 我洗了我的车He | showed | me | how to run the machine. // 他教我开机器 ``` #### 主语 ＋ 谓语 ＋ 宾语 ＋ 补语- 动词虽然是及物动词，但是只跟一个宾语还不能表达完整的意思，必须加一个补充成份来补足宾语，才能使意思完整。 We | saw | him | out. // 我们送他出去。 He | asked | me | to come back soon. // 他要我早点回来。 `]]></content>
      <categories>
        <category>english</category>
      </categories>
      <tags>
        <tag>englishLearning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[项目集群，实现单个服务器操作其余服务器自动同步。]]></title>
    <url>%2Flinux%2Fgit_rsync.html</url>
    <content type="text"><![CDATA[原因项目是一个分布式集群的项目，一个项目运行在多个tomcat服务器上面。功能需要改动，如果手动管理代码，是一件很容易出现操作失误导致项目代码同步不一致的情况。 实现目标 在一个地方操作，其余服务器中的代码自动同步。 支持回滚操作，如果同步之后的代码有问题，立马回滚到之前的版本（不影响线上操作）。 实现思路方案一：git ＋ shell（svn和git的部署方式思路一致） git是程序员常用的代码版本控制工具，比较重要的功能就是分支和版本，回退到之前的版本是一件很很容易的事情。第一种方式可以利用git的版本机制。 用一台服务器A专门管理代码，并创建git仓库。 在这台服务器A上面用maven进行代码编译生成.class文件。（非maven管理的项目，可以在本地编译成功后上传到git仓库） 在其他需要同步的服务器上面clone服务器A上面的代码。 在其他服务器上面创建同步脚本和回退脚本。 同步脚本： 拉取最新代码 关闭tomcat服务器 启动tomcat服务器 如果代码出现问题的回退脚本: 关闭tomcat服务器 代码回退 启动tomcat 用工具远程执行脚本。如果配置了ssh免密码登陆，可以用：ssh user@remoteNode “sh /home/sync.sh” 来执行远程脚本。也可以在服务器A上面写一个执行多个服务器远程命令的命令脚本。 缺点：每台子服务器都要部署svn或git 方案二: jenkins + rsync + git/svn 环境: ssh, rsync, git/svn 安装ssh： apt-get install openssh-server rsync -y ssh启动：/etc/init.d/ssh start 直接用rsync的ssh命令同步： rsync -e “ssh -p 8000” -avH /home root@172.17.0.2:/home 每次执行的时候都需要输入密码， 可以安装sshpass在脚本中写入密码实现不输入密码自动同步（在执行的命令前加sshpass -p password即可）。或者让两台服务器的ssh互信，实现免密码远程执行ssh命令（）。 还有一种通过daemon方式通过tcp同步的，需要写配置文件，没有实现出来。 jenkins+svn+rsync+php_一键自动化部署可持续化集成服务器集群项目_支持回滚 这个写的比较详细，只是语言是php的，换成java的语言应该影响不大。 方案三：rsync + svn/git + svn上传class文件 思路：找一台分发服务器（安装svn，rsync）或者本地电脑代替分发服务器，开发者将代码提交至svn之后，分发服务器进行拉取代码之后，即进行测试环境和生产环境的代码的发布（利用rsync写脚本进行代码增量同步，可同步至多台服务器）。需要注意的就是非maven环境的代码编译（如果svn上传class文件，负担就是svn占用空间大）。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The first month of English learning]]></title>
    <url>%2Fenglish%2F%20composition.html</url>
    <content type="text"><![CDATA[总结句子成份 主、谓、宾、表、定、状、补 名称 描述 充当者 例子 位置 主语《句子最主要的》 需要描述的事物或者对象，全句诉说的对象 名词、代词、数词、短语 I^主语 will drink water 一般句子开头 谓语《主语的行为》 表示主语的行为或状态，对主句加以称述 be动词、行为动词(跑、动等实际动作意义的词) I will^谓语 drink water 一般主语之后 宾语《谓语行为的承受》 动作承受的对象就是宾语 名词、代词、数词构成 我敲打了电视。“电视”就是宾语 动词、谓语后面 表语《表明主语特征》 表明主语的身份或者特征。 名词、代词、数词、介词短语、副词 This table^表语 is long. (这个桌子是长的。) 放在be动词和系动词的后面。 定语《给名词等定位》 修饰名词或代词（即在汉语里的……的），一般起描述作用 形容词或者相当于形容词的短语或从句担任 优秀的人。“优秀的”就是定语 名词前 状语《形容词等的状态》 修饰动词，形容词或副词，有的修饰全句，用于说明地点，时间，方式，程度，原因，目的，结果，条件，让步等 副词 I often^状语 write to him. (我常给他写信。) 不定 宾语补足语（宾补）《对宾语的补充》 就是对宾语的描述（有时如果没有宾语补足语，句子就不完整） (定语） 主语 （状语） 谓语 （定语） 宾语 （状语） 如：(The tall) boy (often) go (to the big) zoo. &nbsp;&nbsp;// 这个高大的男孩经常去大动物园。 词性 名称 描述 分类 常见 简写 名词 表示人或者事物的名称 可数和不可数 toy 玩具，head 头 n 代词 代替名词、数词、形容词（人称代词） 单数、复数 I, you, it pron 形容词 用来修饰名词、表示人或事物的特征 litte 小的、big 大的 adv 副词 表示行为或状态特征的词 adv 动词 表示动作或状态 look 看，know 认识 v 数词 表示数量或者顺序的词 one、 two num 冠词 说明名词所指的范围 a、an、the art 介词 说明它与别的词之间的关系，时间介词 in， down prep 连词 逻辑关系词，表示人或事物的名称 if、but conj 感叹词 语气词，代替名词，数词，形容词等 oh、hi int 第四周 Fourthly week of English learning星期一单词 toy 玩具 n under 在…之下 prep in 在…里 prep on 在…上 prep nurse 护士 n hat 帽子 n pupil 护士 n policeman 警察 n doctor 医生 n driver 医生 n 星期二单词 nose 鼻子 touch 触摸 head 头 tree 树 fish 鱼 know 知道 bear 熊 at 在 look 看 bed 床 星期三单词 cow 奶牛 baby 宝贝 feet 脚 hand 手 leg 腿 body 身体 eye 眼睛 mouth 嘴巴 ear 耳朵 face 脸 星期四 snake 蛇 little 少的 big 大的 fat 肥胖的 thin 瘦的 egg 蛋 chicken 鸡肉 duck 鸭 farm 农场 pig 猪 星期五 cute 宝贝 tiger 老虎 tall 高大的 giraffe 长颈鹿 long 长的 zoo 动物园 go 走 elephant 大象 small 小的 short 短的 星期天(句子的成份)主语 位置：句子开头 充当者：名词、代词、数词、短语。 描述：需要描述的事物或者对象。 例子：I^主语 will drink water. // 我要喝水的“我”就是主语 谓语 位置：主语之后 描述：描述表示主语的动作或状态。 充当者：be动词（am,is,are）、行为动词（跑、动等实际动作意义的词） 例子：I will^谓语 drink water. // 我要喝水的“要”就是谓语 表语 位置：放在be动词（与感觉有关的东西。look、smell等）和系动词（包括be动词，表示状态变化的动词）的后面。 描述：表明主语的身份或者特征。 充当者：名词、代词、数词、介词短语、副词 例子： 宾语 位置：动词后面、谓语后面。 描述：动作承受的对象就是宾语 充当者：名词、代词、数词构成。 例子：我敲打了电视。“电视”就是宾语。 宾语补足语（宾补） 位置：宾语的后面。 描述：就是对宾语的描述（有时如果没有宾语补足语，句子就不完整）。 充当者： 例子： 定语 位置：名词前。 描述：修饰名词或代词（即在汉语里的……的），一般起描述作用。 例子：优秀的人。“优秀的”就是定语 状语 位置：不定（开头，中间，末尾都可以） 描述：修饰动词，形容词或副词，有的修饰全句，用于说明地点，时间，方式，程度，原因，目的，结果，条件，让步等。 例子： 第三周 Thirdly week of English learning星期一笔记 看 123456789look // 不看内容， look at（小心）／ look out （小心）／ look after（照顾）， 不看内容whatch // 有思想的看，watch＋内容（watch TV）,有动作的。read // read book(看书)／ newspaper／mind **mind reader**see // 看到实质，会面。见到一个朋友。看到一只狗。see sb doing。see tv（想看电视）meet // 接近see meet-see-visit(参观)。 visit＋place 听 123456listen //不听内容。listen-lookhear //听见有实质的内容。 hear-watch/read。hear from sb/n-receive // 收到来信，收取sound // 声音 sounds good(听起来很棒) 拿 123456789101112take // take up (占据)，take away(带走), take off(脱掉，起飞),拿起来pick // pick up(接送某人)，pick out(挑出来)get // get up （起床）， get out(滚)，get on ， get down，get away from(离某人或某物远) ，get ingrab // grab sth（抢夺）／sbcarry //挑、抗。carry on （坚持前行），carry out(执行)hold // hold a meeting(举办)， be held in（在哪里举办什么内容） 被动语态 Be held in 1234567891011121314Be + Ved2 The woman killed a dog last night.The dog is killed by the woman last night.The school published some English books last summer.Some English books were published by the school.Be - vingshe is reading a book.Be - vedThe book is read by her. 单词 four 四 three 三 two 二 one 一 box 盒子 house 房子 monster 怪物 monkey 猴子 kite 风筝 crayon 蜡笔 星期三单词 ball 球 pink 粉色 ten 10 nine 9 eight 8 seven 7 six 6 five 5 say 说 count 计算 星期四 has 他的 friend 朋友 grandpa 爷爷 mother 妈妈 father 爸爸 but 但是 birthday 生日 happy 快乐 brown 棕色 many 许多 星期天（词性分类）词性分类名词(noun,n) 描述：表示人或者事物的名称 分类： 可数名词(countable noun,c)（有单数变复数的变化[plural,pl]，apple – apples） 不可数名词(uncountable noun,u)， 没有变化形式。 常见 toy 玩具 pupil 小学生 driver 驾驶员 doctor 医生 head 头 tree 树 bear 熊 baby 宝贝 feet 脚 body 身体 eye 眼睛 face 脸 hat 帽子 policeman 警察 nurse 护士 nose 鼻子 fish 树 bed 床 cow 奶牛 mouth 嘴 ear 耳朵 代词 (pronoun,pron) 描述：代替名词、数词、形容词(人称代词) 常见 第一人称、我 第二人称、你 第三人称、他她它 单数 I you It 复数 we You They 形容词(adjective,adj) 描述：用来修饰名词、表示人或事物的特征 位置：放在名词前面修饰名词 常见：little 小的，fat 肥胖的，thin 瘦的，big 大的 副词(adverb,adv) 描述：表示行为或状态特征的词 位置：修饰动词或者形容词 动词(verb,v) 描述：表示动作或者状态 位置：动作或者状态的词 touch 触摸 look 看 know 认识 数词(numeral,num) 描述：表示数量或顺序的词语 冠词(article,art) 描述：帮忙说明名词名词所指的范围 位置：用在名词前 共三个 an a 不定冠词 一、一个 the 定冠词 这、这个 中文样式：我今天买了一支^不定冠词 笔，这^定冠词 支笔很好看 介词(preposition, prep) 位置：用在名词或者代词前。 描述：说明它与别的词之间的关系，时间介词，方位介词 常见： in 在…离,on 在 … 上,down,up,under 在 … 之下，at 在 连词(conjunction,conj) 描述：逻辑关系词,表示人或事物的名称。 常见：if,because,but 感叹词(interjection,int) 描述：语气词，代替代替名词，数词，形容词等。 常见：oh,hello,hi,yeah 第二周 Second week of English learning星期三单词 up 向上 panda 熊猫 stand 站立 down 向下 sit 坐 girl 女孩 boy 男孩 bird 鸟 please 请 name 名字 星期四单词 red 红色 door 门 window 窗口 colour 颜色 open 打开 point 点 yellow 黄色 desk 桌子 chair 椅子 blue 蓝色 星期五单词 school 学校 teacher 老师 orange 橘子 look 看 cat 猫 dog 狗 white 白色 black黑色 how 怎么 green 绿色 星期六 pencilcase 文具盒 eraser 橡皮擦 ruler 尺子 pencil 铅笔 pen 钢笔 book 书 schoolbag 学校 bag 包 child 孩子 classroom 教师 音标 音标分为元音、辅音。 辅音就是通过辅助的发音，就可以是音标。如：B [bi:]，读的时候就是b和i连在一起读就是B了，单独的b就是B的音标读法。 J: zh /dʒ/ ｝ 红色标记的辅音是比较特殊的辅音，读法不一样。 C: ce, cy, ci ｛ /k/ ｝ G: ge, gy, gi ｛ /g/ ｝ H: sh, ch, gh ｛ /h/ ｝ 元音就是字母除了辅音之外还有另一个读法的音标。 A , E , I , O , U 星期天 音标技巧提示 θ si ts ci ʃ sh tr chuo tʃ 吃 ð ri dz 资 ʒ 日 dr zhuo dʒ 知 第一周（2018-11-19）First week of English learning星期一单词 run out of 用完 since 从…以来 collect 收集 shell 外壳 several 几个 marathon 马拉松 skate 溜冰 pair 一对 raise 举起 russian 俄罗斯 several 若干 stamp 邮票 kite 风筝 monster 怪物 emperor 皇帝 笔记123456789101112It&apos;s pink // 它是粉红色It&apos;s red // 它是红色It&apos;s white // 它是白色It&apos;s yellow // 它是黄色It&apos;s gray // 它是灰色It&apos;s orange // 它是橘黄色It&apos;s brown // 它是棕色It&apos;s blue // 它是蓝色It&apos;s black // 它是黑色It&apos;s green // 它是绿色It&apos;s purple // 它是紫色 复习 chair椅子 eraser 橡皮擦 book 书 pen 钢笔 ruler 尺子 bag书包 desk 桌子 pencil 铅笔 星期二 particularly 特别地 capital 首都 writer 作家 extra 额外的 thousand 一千 topic 主题 jewith 犹太人 coin 硬币 european 欧洲人 globe 球体 common 通用 foreigner 外国人 by the way 顺便说一下 cake 蛋糕 anyone 任何人 难记的单词：particularly 特别地。 笔记123456They&apos;re notebook // 它们是笔记本 They&apos;re calculators // 它们是计算器They&apos;re markers // 它们是记号笔单数用It is 简写为： It&apos;s复数用They are 简写为: They&apos;re 星期三单词 clothing 衣服 bring 带来 waitress 作家 poster 海报 the Olympic Games 奥林匹克 task 任务 dish 盘子 right away 立即 yard 院 quite 相当 turn down 拒绝 not at all 一点也不 mind 头脑 miss 想念 certain 肯定的 笔记1234567who&apos;s he? // 他是谁？who&apos;s she? // 她是谁？It&apos;s he old? // 它是老的Yes, he is. // 是的，他是It&apos;s yang. // 她是年轻的 No, she is not. // 不她不是It&apos;s he short // 他是小的 星期四单词 cut 剪 line 行 door 门 perhaps 也许 polite 客气的 annoyed 愤怒的 wait the line 排队等候 annoy 烦恼的 solution 解答 笔记1234Is it a book? // 它是书？Is it a ball? Is it little? // 他是小的？Is it a doll? // 它是一个娃娃？ 星期五单词 europe 欧洲人 asian 亚洲人 behavior 行为 normal 正确的 etiquette 礼仪 term 学期 voice 语音 keep 保持 cut 剪 public 公众 笔记1234567891011Where is the bag? // 包在那里Where are the books? // 书都在那里are the cars by the bag? // 我的汽车都在包里吗？no，they are not？ // 不，它们不在Is the yo-yo on the table? // yo-yo 在桌子下面?Is the doll in the tree? // 玩偶在树下？Is the bag on the table? // 包在桌子上？Are the crayons in the bag? // 蜡笔都在包里？Are the bats by the tree? // 球拍都在树下单数is，复数are 星期六单词 criticize 批评 cigarette 香烟 put out 熄灭 smoke 烟 sneene 喷嚏 sough 咳嗽 allow 允许 impolite 不礼貌的 uncomfortable 不舒服的 in 在…里 笔记123I want fish an milk. // 我要鱼和牛奶Do you want bread? // 你想要面包 星期天 看到字母‘n’，‘m’ 发鼻音。 看到’r’ 发卷舌。看到‘v’咬嘴唇，‘w‘不咬嘴唇 发音。 自然拼读（字母、字母组合）＋音标 字母 音标 典型单词 备注 字母 音标 典型单词 备注 A a /æ/ /ei/ apple 元音 N n /n/ nice 发鼻音 B b /b/ * book O o /o/ /au/ open 元音 C c /k/ * cat P p /p/ * pencil D d /d/ dog Q q /k/ * quit E e /e/ /i/ egg 元音 R r /r/ ruler 卷舌 F f /f/ fish S s /s/ six G g /g/ good T t /t/ * time H h /h/ * head U u / ^ / /ju:/ under 元音 I i /əu/ /ɔ/ in 元音 V v /v/ van 咬嘴唇 J j /dƷ/ jeep W w /w/ want 不咬嘴唇 K k /k/ * kill X x /x/ x L l /l/ like 不发鼻音 Y y /y/ yes M m /m/ money 发鼻音 Z z /z/ zero A a ／æ／ apple ant 元音字母之一。／æ／ ／ei／ B b ／b／ book bag C c ／k／ cat cake can D d ／d／ Dad dead Dog door E e ／e／ bed egg end 五个元音字母之一／e／ ／i／ F f ／f／ fish G g ／g／ good girl game goat green go H h ／h／ hat head hand house I i ／i／ in it ink internet 五个元音字母之一 ／i／ ／e／ J j ／dj／ jam jeep jenny K k ／k／ kill kitten kind take kick kiss kill L l ／l／ like lie land look large little M m ／m／ mother mind morning money monkey mouse N n ／n／ notebook nine notice nice night O o ／o／ octopus on open orange office 备注：五个元音之一。／o／ ／au／ P p ／p／ pay paint picture paper pencil Q q ／k／ quick quit quite Question R r ／r／ [卷舌] Ruler rainy rice right rude S s ／s／ sun six some summer sunday T t ／t／ Table Tall teacher time ten U u |^| [嘴巴两边张] under hug uncle ugly 五个元音字母之一。／^／ ／ju:／ V v ／v／ ［咬嘴唇］ van violin five virus W w ／w／ ［不咬嘴唇］ window walk windy want win X x ／eks／ x Y y ／y／ yellow young yes you Yo-yo Z z ／z／ zero zoo zone zipper A E I O U 元音字母 one two three four five six seven eight nine ten eleven twenty thirteen fourteen fifteen sixteen eventeen eighteen nineteen twenty 总结： 这一周每天背了10个单词，记的单词基本忘记了，一点效果都没有，今天是第一周的最后一天。Amanda老师调整了我背单词的难度，下周从小学的星期三开始。这两天练习上面学习的自然拼读。从零开始，加油！]]></content>
      <categories>
        <category>english</category>
      </categories>
      <tags>
        <tag>englishLearning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用js写了一个比较方便的表单验证器]]></title>
    <url>%2Fweb%2FjqueryForm.html</url>
    <content type="text"><![CDATA[一、实现方式 导入jquery 将以下代码复制到html页面中 12345678910111213141516171819202122232425262728293031323334353637&lt;script&gt;$(function() &#123; // 调用此方法获取表单是否合法 function checkInputPostData() &#123; var list = $(&quot;.validInputs&quot;) var j = 0 for(var i = 0; i&lt;list.length; i++) &#123; j = j+inputDataValid(list[i]) &#125; if (j == 4) &#123; return false &#125; return true &#125; // 自定义表单效验 gqs function inputDataValid(then) &#123; var th, promt, value, reg th = $(then) promt = th.parent().find(&quot;.Validform_info&quot;)[0] value = th.val() if(value == null || value == &quot;&quot;) &#123; $(promt).html(&apos;&lt;span style=&quot;color:red&quot;&gt;&apos;+th.attr(&apos;nullmsg&apos;)+&apos;&lt;/span&gt;&apos;) $(promt).removeClass(&apos;Validform_right&apos;).addClass(&apos;Validform_wrong&apos;) return false &#125; reg = th.attr(&quot;datatype&quot;) if(!eval(reg).test(value))&#123; $(promt).html(&apos;&lt;span style=&quot;color:red&quot;&gt;&apos;+th.attr(&apos;errormsg&apos;)+&apos;&lt;/span&gt;&apos;) $(promt).removeClass(&apos;Validform_right&apos;).addClass(&apos;Validform_wrong&apos;) return false &#125; $(promt).html(&apos;&lt;span style=&quot;color:red&quot;&gt;&lt;/span&gt;&apos;) $(promt).removeClass(&apos;Validform_wrong&apos;).addClass(&apos;Validform_right&apos;) return true &#125;&#125;&lt;/script&gt; input框写入自定义属性 123456789&lt;input id=&quot;name&quot; onblur=&quot;inputDataValid(this)&quot; name=&quot;name&quot; type=&quot;text&quot; class=&quot;span3 validInputs&quot; &lt;!-- 必须要validInputs的class,或者和checkInputPostData函数中的validInputs一致 --&gt; datatype=&quot;/^[a-zA-Z\u4E00-\u9FA5]&#123;1,20&#125;$/&quot; &lt;!-- 正则：用于效验表单 --&gt; value=&quot;123&quot; nullmsg=&quot;此项不能为空&quot; &lt;!-- 表单为空时的提示 --&gt; errormsg=&quot;请填写字母或汉字&quot;/&gt; &lt;!-- 正则效验失败时的提示 --&gt; 在input下创建 1&lt;div class=&quot;Validform_info&quot;&gt;&lt;/div&gt; 注：需要和下面的代码层级一致，如果不一致要注意层级查找（ th.parent().find(“.Validform_info”) ）的更换 二、全部代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt; &lt;title&gt;简单的表单验证器&lt;/title&gt; &lt;script src=&quot;https://cdn.bootcss.com/jquery/3.3.1/core.js&quot;&gt;&lt;/script&gt; &lt;style&gt; .Validform_right&#123; 正确提示的css &#125; .Validform_wrong&#123; 错误提示的css &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;table class=&quot;gritter-with-table&quot; cellspacing=&quot;1&quot;&gt; &lt;tbody id=&quot;tbody&quot;&gt; &lt;tr name=&quot;posts&quot;&gt; &lt;th&gt;姓名：&lt;/th&gt; &lt;td&gt; &lt;input id=&quot;name&quot; onblur=&quot;inputDataValid(this)&quot; name=&quot;name&quot; type=&quot;text&quot; class=&quot;span3 validInputs&quot; datatype=&quot;/^[a-zA-Z\u4E00-\u9FA5]&#123;1,20&#125;$/&quot; value=&quot;123&quot; nullmsg=&quot;此项不能为空&quot; errormsg=&quot;请填写字母或汉字&quot;/&gt; &lt;div class=&quot;Validform_info&quot;&gt;&lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr name=&quot;posts&quot;&gt; &lt;th&gt;电话：&lt;/th&gt; &lt;td&gt; &lt;input onblur=&quot;inputDataValid(this)&quot; nullmsg=&quot;此项不能为空&quot; value=&quot;1234&quot; datatype=&quot;/^[a-zA-Z\u4E00-\u9FA5]&#123;1,40&#125;$/&quot; placeholder=&quot;例：*********&quot; class=&quot;span3 validInputs&quot; id=&quot;phone&quot; type=&quot;text&quot; name=&quot;phone&quot; &gt; &lt;div class=&quot;Validform_info&quot;&gt;&lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt;&lt;script&gt;$(function() &#123; // 调用此方法获取表单是否合法 function checkInputPostData() &#123; var list = $(&quot;.validInputs&quot;) var j = 0 for(var i = 0; i&lt;list.length; i++) &#123; j = j+inputDataValid(list[i]) &#125; if (j == 4) &#123; return false &#125; return true &#125; // 自定义表单效验 gqs function inputDataValid(then) &#123; var th, promt, value, reg th = $(then) promt = th.parent().find(&quot;.Validform_info&quot;)[0] value = th.val() if(value == null || value == &quot;&quot;) &#123; $(promt).html(&apos;&lt;span style=&quot;color:red&quot;&gt;&apos;+th.attr(&apos;nullmsg&apos;)+&apos;&lt;/span&gt;&apos;) $(promt).removeClass(&apos;Validform_right&apos;).addClass(&apos;Validform_wrong&apos;) return false &#125; reg = th.attr(&quot;datatype&quot;) if(!eval(reg).test(value))&#123; $(promt).html(&apos;&lt;span style=&quot;color:red&quot;&gt;&apos;+th.attr(&apos;errormsg&apos;)+&apos;&lt;/span&gt;&apos;) $(promt).removeClass(&apos;Validform_right&apos;).addClass(&apos;Validform_wrong&apos;) return false &#125; $(promt).html(&apos;&lt;span style=&quot;color:red&quot;&gt;&lt;/span&gt;&apos;) $(promt).removeClass(&apos;Validform_wrong&apos;).addClass(&apos;Validform_right&apos;) return true &#125;&#125;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>javaScript</category>
      </categories>
      <tags>
        <tag>javaScript jquery form</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[看《码农翻身》的一些收获]]></title>
    <url>%2Fbook%2Facmen.html</url>
    <content type="text"><![CDATA[今天是双十一，哪里也没去，早晨10点多就出门了，在新华书店里面呆了一天，在书架中找到了这本书，很容易的就看了进去，这本书用故事的方式描述生涩的代码以及程序。前段时间看的head frist也是比较很容易理解的书籍，自己购买的java并发编程实战看了几页总是无法集中精力看下去，内容很充实，可能一直在家里躺在床上太安逸的看书，导致看着看着就放弃了，希望坚持下去。 这本书学会了一个很重要的做事方式&lt;凡事必先骑上虎背&gt;，在自己做一件事情犹豫不决的时候，想想这句话,在做事情的时候，需要先骑在老虎的背上。和明知山有虎，偏上虎山行差不多。在这种状态下，经常会出现骑虎难下的尴尬情况。只要不恐惧这种情况，那么在这种状态下学习就收获更多的东西。 一、概要书籍用第一人称描述计算机的各个组成如：内存、进程等，和日本的《工作细胞》动漫差不多。从底层描述描述进程、线程、cpu、内存、硬盘等。整本书籍阅读起来相当的有趣，看的时候完全当成一本小说在读，但是读到最后，确实学到很多知识，虽然很多东西都是之前学习过的，但是很多也是自己理解不够透彻的。还是推荐大家可以阅读以下，一方面可以巩固自己的知识，一方面也可以学习一些自己没接触过的东西。 二、计算机的世界 进程：比如QQ运行，QQ音乐运行，微信运行，都需要一个进程去处理，一个计算机可以有多个进程。进程之间的切换实现了多个程序同时运行的效果。（理解不够透彻，需要完善） 线程：一个进程可以拥有多个线程 cpu：由寄存器和运算器组成，寄存器用来存储数据，运算器负责运算，速度特别快 内存：内存负责把硬盘的数据加载到内存里面，并且各种指令，执行速度一半 硬盘：负责把数据持久化，存储数据，防止断电，执行速度特别慢 汇编语言：比较难理解的语言，负责和底层的二进制（机器语言）打交道 高级语言： 如c、c++、java、python等。用人类方便理解的语言和汇编语言打交道 tcp/ip：只要解决的就是网络传输数据的问题，通过没次发送少量数据拆包，并进行失败重发的功能解决发送大量数据的问题。发送的过程中由多个路由器进行转发到目的地完成。 三、java帝国 java class : java类主要由java的类加载调用，每个线程都会有一个函数栈（栈祯），用来进行方法调用 JDBC ： 由一个工厂方法实现，封装了各种实现，用于和各种数据库对接，便于数据的持久化，代替的文件存储方法，提高效率。 jsp : java的模版套用mvc的view。用于将html和数据组合生成html页面。freemarker也是类似的，但是freemarker静态的页面也是可以浏览的。 JTA : 在多个数据库之间传送数据，保证数据的事务性。由一个全局事务管理器实现，统一准备和统一提交。失败案例（全局事务管理器出现问题，将无法保存数据的一致性） 消息队列（JMS - java message service）：为了实现分布式项目的数据传递问题。如订单服务器给物流服务器发送订单，物流服务器出现问题，暂时无法接受订单。就可以由一个消息队列处理，有订单了，由订单服务器发送订单到消息队列排队，物流服务器可以随时接收订单，就是物流服务器有事情，也不会影响到订单服务器。 动态代理：可以实现给一个类动态的添加新的行为。动态代理可以实现aop的切面功能。 java注解：注解相当于加强的注释。注解有元注解^(注解的注解)，通过注解可以减少xml文件的编写，只好的方式就是xml和注解配合一起使用。 泛形：泛形就是可以限制一组数据的数据类型。&lt;? extends Object&gt; 的意思就是可以传入继承了对象类的任意对象。 序列化：把java对象编程二进制字节流存储在硬盘上，当然还有一种办法就是把二进制字节流反序列化为java对象。 java程序的锁：在java中synchronized就是同步锁，每个线程需要访问锁里面的内容必须要拿到锁，没有拿到的就需要在线程池里面等待。这个是一个重量级的悲观锁（觉得线程随时都会更改数据）。另一种办法就是乐观锁（认为大部分情况多线程的情况都比较少），可以给数据添加一个版本号，每次更改数据后版本变化。在实现功能的时候，可以把数据获取出来更改之后，在修改的时候对比版本号是否一致，如果不一致则继续重新获取，直到版本号一致为止。这样就减少了同步锁导致的线程在线程里面等待所消耗的资源。 spring DI和IOC、AOP: 在一个大型的项目中日志、事务、登录等功能都会涉及到程序的各个层面，如果统一管理，就回出现大量冗余的代码，而去大量的代码会导致代码的臃肿。想这些经常会出现的代码，可以用模版方法和装饰者模式区封装常用的代码，但是这样很多类都需要实现接口。为了避免这种情况，于是出现了控制反转ioc，和依赖注入di（把类的依赖情况转交给spring容器）。aop利用的java动态代理实现的面向切面编程。 四、web冲浪 hyperText Transfer Protocol (HTTP) : 超文本传输协议,这里的超文本就是HyperText Markup Language (HTML，一种文本的标记形语言) HTTPS : 在使用HTTP在网上传输HTML的时候是使用的明文，如果中途被截取了，隐私就会被泄露。HTTPS解决了安全性问题，用对称数据加密和非对称数据加密结合解决了网络传输HTML的安全性问题。对称加密利用一个公匙和私匙，公匙加密（所有人都可以知道公私），私匙解密（对应的公私加密的文件只有对应的私匙解密）。解密的私匙是需要双方都持有的，因为双方都需要加密解密，所以在保证安全的情况下把私匙传给对方就需要非对称加密了。非对称加密需要第三方的证书＋签名，才可以完成（非对称加密还需要理解一下）。 SSO : 一个由很多子系统组合在一起的大型项目就需要实现在一个小的项目中登录之后，进入相关的项目就不用再次登录的单点登录功能。实现原理就是利用一个认证中心实现登录，用户首次登录时会获取到认证中心的一个cookie用于存放在浏览器端，浏览器上面存两个cookie，一个是认证中心的cookie一个是当前访问应用的cookie。用户访问另一个应用时，只需要将之前的cookie携带访问应用，后端通过应用验证cookie是否有效即可判断用户是否已经登录。 授权 ： 比如QQ、微信、微博第三方登录等，都是使用的授权登录方法。应用可以通过自己申请的第三方的appid和密匙，获取授权的code，授权code会有超时时间等，通过code可以获得token，最后通过token就可以实现登录逻辑。 负载均衡 ： 多台服务器运行相同的应用，nginx在进行接口转发时均衡的转化，不出现有的服务器严重负载，有的服务器轻松自在。 高可用 ： 当服务器出现故障之后，有备用的服务器顶上去，不会出现无法访问的情况。 tomcat集群：通过多台tomcat服务器实现高可用，由nginx来进行服务转发（实现负载均衡）。 redis集群：通过jedis负责分发tomcat的请求（redis cluster）。 数据库读写分离：由多台数据库实现，一个master数据库可读可写已写为准，多个slave数据库进行只读操作（读时需将数据同步至slave数据库，master出现故障由slave数据库顶替） 五、代码管理 VCS(Version Controller System): 版本控制系统，svn采取的就是这种方式管理的代码！采用更新，提交的方式进行。 分支，多版本并行: 通过分支实现多版本并行，在代码开发的时候可以有多个版本并行开发，每个人在本地都有一个私有库，每个人都可以有选择性的提交不同版本的代码，最后只需进行合并即可。git就是采用的这种方式。 build: 代码的自动化构建。manven的pom.xml就是可以用build脚本进行自动化构建的一个工具（自动打包、编译、部署）。 六、其他 声明式编程： SQL语句就是命令式编程（只提供声明，具体实现有系统负责） 命令式编程： 大多数程序员使用的语言都是命令式编程（通过指令告诉计算机怎么做）。]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>java code</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－总结]]></title>
    <url>%2Fpatterm%2Fsum.html</url>
    <content type="text"><![CDATA[已经将head first一书看完了，应该总结一下这本书学到了些什么，下面就将自己学习的设计模式整理一下，方便自己后期复习，以及简短的描述各个设计模式的定义，以及在哪些方面需要使用到设计模式。 什么是设计模式设计模式就是很多面向对象的开发者，根据自己开发的经验，想出来的一些模式，经过时间的认证和大多数程序员的认同后形成的一种比较好的开发模式。利用这些模式，程序员之间可以有自己的方言，程序之间沟通也更加便捷。也很利于代码的维护和扩展。是一套反复使用、多人知晓、分类遍目的代码设计经验的总结。 模式词汇(23个) 创建型 5个 singleton 单例 builder 生成器（建造者） prototype 原型 abstract factory 抽象工厂 factory method 工厂方法 行为型 11个 template method 模版方法 command 命令 observer 观察者 state 状态 mediator 中介 iterator 迭代器 strategy 策略 interpreter 解释器 chain of responsibility 责任链 memento 备忘录 visitor 访问者 结构型 7个 proxy 代理 decorator 装饰 composite 复合 facade 外观 adapter 适配器 flyweight 享元 bridge 桥接 模式何时用创建型模式 模式名称 何时用 备注 单例 singleton 你需要程序中只用一个共享的对象 确保一个类只有一个实例 建造者 builder 需要创建一个复杂对象的时候 由多个简单对象构建为一个复杂对象 原型 prototpye 需要创建许多重复且互不干扰的对象时 通过复制对象实现 抽象工厂 abstract factory 创建一系列产品族时 提供一个创建一系列相互依赖对象的接口 工厂方法 factory method 一个抽象对象，想动态产生你想要的具体对象 通过简单工厂模式的抽象和推广 行为型模式 模式名称 何时用 备注 模版方法 template method 很多类都需要执行固定或者可选的步骤 可以用钩子实现不改变算法结构的时候改变步骤 命令 command 多个回退操作，宏纪录 通过把请求或操作封装到类中，支持撤销、恢复操作 观察者 observer 想让你的发送者和接收者不用同步阻塞的时候 依赖它的对象都会收到通知并自动更新，就像微信订阅号 迭代器 iterator 遍历不同类型集合的一种方式 通过访问迭代器接口实现‘下一个’、和’有下一个方法‘ 策略 strategy 客服端可以根据自己的需求进行相应的选择 把一系列的算法分别封装到对应的类中，实现相同接口之后可以相互替换 解释器模式 interpreter 当需要使用一个简单的语言时 将每一个语法规则表示为一个类 访问者 visitor 在封装不是很重要，需要给类添加新的能力时 封装某些结构元素的操作，在不改变数据结构的情况下新增新的操作 中介者 mediator 利用中介者改善类与类之间的过多耦合 利用星型结构改善 备忘录 在需要纪录操作备忘时，捕获类的内部状态 将被记录的状态记录在外部，帮助维护类聚 责任链 chain of responsibility 一个请求需要多个对象处理，形成链条 让对个对象都可以接受请求，就像请假一样(日志打印、请求等) 状态 state 在内部状态改变时，进行不同的行为操作 一个状态一个类，改变状态时，对象看这向修改了类 结构型模式 模式名称 何时用 备注 代理 proxy A调不到C，而A可以通过B来调C 通过类似黄牛的代理角色去处理 装饰者 decorator 动态的给类添加职责，有别于继承的另外一种选择 通过动态运行时选择不同的具体装饰类，从而实现不同的行为。常见的就是io流 复合 composite 大杂烩，多种模式混合使用 常见的有经典的mvc模式，mvvm模式等 外观模式 facade 接口特别多，比较混乱，需要统一调用时 将各个接口统一在一个类中，调用时只需要调用一次 适配器 adapter 将一个对象转化为另一个对象 就想转换插头，适配不同的插座一样 享元模式 flyweight 共享之前的元对象，减少实例化次数 在相同的对象特别多的时候，通过map存储对象。每次需要新对象时，就去map里面查找，没有则创建 桥接模式 bridge 好几个接口，需要同时使用他们的部分特性 就像多种颜色和多种形状组合一样，两种类别都需要扩展 模式定义与用途创建型模式单例模式 定义：确保一个类只有一个实例，并提供全局访问点 用途：当只需要一个实例的时候 建造者模式 定义：将复杂对象的建造过程抽象出来（抽象类别），使这个抽象过程的不同实现方法可以构造出不同表现（属性）的对象。 用途：经常被用来创建组合结构 原型模式 定义：通过‘复制’一个已经存在的实例来返回新的实例，而不是新建实例。被复制的实例就是我们称之为的‘原型’，这个原型是可定制的。 用途：在一个复杂的类层次中，当系统必须从其中的许多类型创建新对象的时候，可以考虑使用原型。 抽象工厂模式 定义：提供一个创建一系列相关或相互依赖对象的接口。 用途：系统中有多个的产品族，而每次只使用一个产品族。用来创建一系列相关或相互依赖对象的接口 工厂方法模式 定义：由子类决定要创建的具体类是那一个 用途：由工厂生产产品，如果用简单工厂模式生产新的产品，就要更改工厂类，违背了开闭原则。工厂方法模式就是将类更工厂化，让扩展更简单。 行为型模式模版方法 定义：在一个方法中定义一个算法的骨架,而将一些步骤延伸到之类中，模版方法使得之类可以在不改变算法结构的情况下，重新定义算法中的某些步骤 用途：一个可共用的模版，在共用的方法中子类可以利用钩子重新定义算法步骤。 命令模式 定义：将请求封装成对象，这可以让你使用不同的请求、队列或者日志请求来参数化其他对象。命令模式也支持撤销操作 用途：将单个的请求封装为对象。 观察者模式 定义：让对象在状态改变时被通知 用途：观察者模式就是相当于公众号一样，你关注公众号就会受到消息，取消就收不到消息，一对多的关系。 迭代器 定义：提供一种方法，顺序访问一个聚合对象中的各个元素，而又不暴露内部的实现。 用途：用来遍历集合中有不同对象的一种统一方式。 策略模式 定义：封装可以交互的行为，并使用委托来决定要使用那一个 用途：策略模式就是通过不同的策略可以给对象组装不同的行为，比如给小猫小狗添加不同的行为等。 解释器模式 定义：提供了评估语言的语法或表达式的方式，这种模式实现了一个表达式接口，该接口解释一个特定的上下文。 用途: 当需要实现一个简单的语言时，可以使用解释器。 访问者模式 定义：封装某些作用于某种数据结构中各元素的操作，它可以在不改变数据结构的情况下定义作用于这些元素的新的操作。 用途：当你想要为一个对象的组合增加新的能力，且封装并不重要时，可以使用访问者模式。 中介者模式 定义：用一个中介者对象封装一系列的对象交互，中介者使各对象不需要显示的相互作用，从而时耦合松散，而且可以独立地改变它们之间的交互。 用途：使用中介者模式来集中相关对象之间复杂的沟通和控制方式。常常用来协调相关的GUI组件。 备忘录模式 定义：在不破坏封装的情况下，捕获一个对象的内部状态，并在该对象之外保存这个状态。这样就可以将该对象恢复到原先保存的状态。 用途：当你需要让对象返回之前的状态，如你的用户请求‘撤销’，就可以使用备忘录模式。常常用来存储状态。 责任链模式 定义：使多个对象都有机会处理请求，从而避免了请求的发送者与接收者之间的耦合关系。将这些对象连成一条链，并沿着一条链传递这请求，直到有对象处理它为止。 用途：当你想让一个以上的对象能有机会处理某个请求的时候，就可以使用责任链模式。 状态模式 定义：允许一个对象在其内部状态发生改变时改变它的行为，对象看起来似乎修改了它的类。又叫状态对象。 用途：在工作流和游戏等类型的软件中经常使用，经常处理一批状态。比如请假流程（主管批准、经理批准、总经理批准） 结构型模式代理模式 定义：为另一个对象提供一个替身或占位符以访问这个对象。 用途：代理常常用来保护目标对象的作用，协调调用者和被调用者，降低了系统的耦合度。 装饰者模式 定义：包装一个对象，并提供新的行为 用途：就像装修房子一样，选择不同的厂商，不同的材料装饰房子。java io流就是使用的装饰模式 复合模式 定义：结合两个或两个以上的模式，组成一个解决方案，解决一再发生的一般性问题。 用途：通过多个模式去解决复杂的问题，实现不同的功能。常见的就是mvc模式 外观模式 定义：提供了一个统一的接口。用来访问子系统中的一群接口。外观定义了一个高层接口，让子系统更容易访问。 用途: 封装一个统一的接口，就像很多插头插在一个大擦板上面，每次使用的时候，只需要按大插板的开关。 适配器模式 定义：将一个类的接口，转换成客户期望的另一个接口。适配器让原本接口不兼容的类可以合作无间。 用途: 就像转换插头一样，转换接口。 享元模式 定义：运用共享技术有效地支持大量细粒度对象的复用，系统只使用少量的对象，而这些对象都很相似，状态变化很小，可以实现对象的多次反复使用，由于享元模式对象需要是细粒度对象，所以又叫轻量模式、蝇量模式。 用途：如果想让某个实例能提供很多的虚拟实例，就可以使用享元模式，也叫蝇量模式。 桥接模式 定义：将抽象部分与它的实现部分分离，使它们可以独立的变化 用途：不只改变你的实现，也改变你的抽象，适合使用在跨越多个平台的图形和窗口系统上。]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－访问者模式]]></title>
    <url>%2Fpatterm%2Fvisitor.html</url>
    <content type="text"><![CDATA[一、理解访问者模式访问者模式定义:封装某些作用于某种数据结构中各元素的操作，它可以在不改变数据结构的前提下定义作用于这些元素的新的操作。 个人理解访问者模式就是让不同的访问者可以访问不同的操作。访问者模式在实现过程中可以在不改变数据结构的情况下，添加新的操作，实现开闭原则。 二、代码实现创建电脑访问者 12345678910111213141516171819// 电脑组件访问者public interface ComputerPartVisitor &#123; public void visit(Keyboard k); // 访问键盘 public void visit(Mouse mouse); // 访问鼠标&#125;class ComputerPartDisplayVisitor implements ComputerPartVisitor&#123; @Override public void visit(Keyboard k) &#123; System.out.println(&quot;键盘&quot;); &#125; @Override public void visit(Mouse mouse) &#123; System.out.println(&quot;鼠标&quot;); &#125; &#125; 创建电脑 123456789101112131415161718192021222324252627282930313233// 电脑组件public interface ComputerPart &#123; public void accept(ComputerPartVisitor cpv); // 接受方法&#125;// 键盘class Keyboard implements ComputerPart&#123; @Override public void accept(ComputerPartVisitor cpv) &#123; cpv.visit(this); &#125;&#125;// 鼠标class Mouse implements ComputerPart&#123; @Override public void accept(ComputerPartVisitor cpv) &#123; cpv.visit(this); &#125;&#125;// 电脑class Computer implements ComputerPart&#123; ComputerPart[] parts; public Computer() &#123; // 构造器给parts赋值 parts = new ComputerPart[]&#123;new Mouse(), new Keyboard()&#125;; &#125; @Override public void accept(ComputerPartVisitor cpv) &#123; for(ComputerPart cp : parts) &#123; cp.accept(cpv); &#125; &#125;&#125; main 方法实现 1234public static void main(String[] args) &#123; ComputerPart cp = new Computer(); cp.accept(new ComputerPartDisplayVisitor()); &#125; 运行结果 12鼠标键盘 三、UML类图 四、笔记当你想要为一个对象的组合添加新的能力的时候，而且感觉封装不是很重要的时候，就可以使用访问者模式。 访问者模式的优点： 允许你对组合结构加入新的操作，而无需改变结构本身。 想要加入新的操作，相对容易 访问者所进行的操作，其代码是集中在一起的。 访问者的用途和缺点 在使用访问者模式的时候，会打破组合类的封装。 因为经常性的新增操作，所以对组合结构的改变就更加困难]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java visitor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－原型模式]]></title>
    <url>%2Fpatterm%2Fprototype.html</url>
    <content type="text"><![CDATA[一、对原型模式的理解原型模式是创建模式的一种，主要通过复制一个实例来创建一个实例，而不是通过新建一个实例。被复制的实例，我们称之为原型，这个原型是可定制的。 二、代码实现创建原型类，实现原型接口 1234567891011121314151617181920// 原型public abstract class Prototype implements Cloneable&#123; public Object clone() throws CloneNotSupportedException&#123; return super.clone(); &#125;&#125;class ConcretePrototype1 extends Prototype&#123; public static int classFlay = 1; // 克隆自身方法 public Object clone() throws CloneNotSupportedException&#123; return (ConcretePrototype1)super.clone(); &#125;&#125;class ConcretePrototype2 extends Prototype&#123; public static int classFlay = 2; // 克隆自身方法 public Object clone() throws CloneNotSupportedException&#123; return (ConcretePrototype2)super.clone(); &#125;&#125; main方法实现 12345678public static void main(String[] args) throws CloneNotSupportedException&#123; Prototype pro = new ConcretePrototype1(); ConcretePrototype1 cp = (ConcretePrototype1)pro.clone(); System.out.println(&quot;标记：&quot;+ cp.classFlay); Prototype pro2 = new ConcretePrototype2(); ConcretePrototype2 cps = (ConcretePrototype2)pro2.clone(); System.out.println(&quot;标记：&quot;+ cps.classFlay); 运行结果 12标记：1标记：2 三、UML类图 四、笔记原型的优点: 性能提高 避免构造函数的约束 让客户隐藏制造新实例的复杂性 提供然客户能够产生未知类型对象的选项 在有些时候，复制对象比创建对象更有效 原型的用途和缺点 在一个复杂类层次中，当系统需要许多类型创建新对象的时候，可以考虑使用原型模式 对象复制的时候，有些时候特别的复杂]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java prototype</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－备忘录模式]]></title>
    <url>%2Fpatterm%2Fmemento.html</url>
    <content type="text"><![CDATA[一、对备忘录模式的理解 备忘录就是备忘的意思，就像git一样，每个状态都记得，如果代码写错了，还可以回到历史版本。而且对现有版本不回产生影响，如果还需要回到现有版本也是可以的。可以实现撤销功能。实现的时候主要需要一个发起人、守护人、和一个备忘录类。 二、代码实现创建备忘录类，用于存放数据 1234567891011 // 备忘录public class Memento &#123; private String state; public Memento(String state) &#123; this.state = state; &#125; public String getState() &#123; return this.state; &#125;&#125; 创建发起人类、用来设置状态，获取备忘录、设置备忘录等功能。 1234567891011121314151617181920// 发起人public class Originator &#123; private String state; public void setState(String state)&#123; this.state = state; &#125; public String getState() &#123; return this.state; &#125; // 保存状态到备忘录 public Memento saveStateToMemento()&#123; return new Memento(state); &#125; // 通过备忘录获取状态 public void getStateFromMemento(Memento m) &#123; state = m.getState(); &#125;&#125; 创建守护者类、用于存放历史备忘录、增加历史版本备忘录，通过下标获取备忘录等 1234567891011// 守护者public class CareTaker &#123; private List&lt;Memento&gt; list = new ArrayList&lt;Memento&gt;(); public void add(Memento m) &#123; list.add(m); &#125; public Memento getMemento(int i) &#123; return list.get(i); &#125;&#125; main 方法实现 1234567891011121314151617public static void main(String[] args) &#123; Originator origin = new Originator(); CareTaker ct = new CareTaker(); origin.setState(&quot;状态1&quot;); origin.setState(&quot;状态2&quot;); ct.add(origin.saveStateToMemento()); origin.setState(&quot;状态3&quot;); ct.add(origin.saveStateToMemento()); origin.setState(&quot;状态4&quot;); System.out.println(&quot;当前状态为:&quot;+ origin.getState()); origin.getStateFromMemento(ct.getMemento(0)); System.out.println(&quot;回到第一个状态为:&quot;+ origin.getState()); origin.getStateFromMemento(ct.getMemento(1)); System.out.println(&quot;回到第二个状态为:&quot;+ origin.getState()); &#125; 运行结果 123当前状态为:状态4回到第一个状态为:状态2回到第二个状态为:状态3 三、UML类图 四、笔记定义：在不破坏封装的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，这样可以在以后将对象恢复到原先保存的状态。 备忘录的优点： 将被存储的状态放在外面，不要和关键对象混在一起，这可以帮助维护内聚。 保持关键对象的数据封装 提供了容易实现的恢复能力 备忘录的用途和缺点： 备忘录用于存储状态 存储和恢复状态可能比较费时间 java中可以考虑使用序列化机制存储系统的状态。]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java memento</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－中介者模式]]></title>
    <url>%2Fpatterm%2Fmediator.html</url>
    <content type="text"><![CDATA[一、对中介者模式的理解中介者就是处理很多类与类之前耦合太多的的一种方式。比如5个类都互相耦合，改动一个类都会动到其他的类，中介者模式利用星形结构改善这种情况。 二、 代码实现中介类 12345678910111213141516171819202122232425262728293031// 抽象中介者public abstract class AbstractMediator &#123; public AbstractColleague A; public AbstractColleague B; public AbstractMediator(AbstractColleague A, AbstractColleague B)&#123; this.A = A; this.B =B; &#125; public abstract void AaffectB(); // a转b public abstract void BaffectA(); // b转a&#125;// 中介者class Mediator extends AbstractMediator&#123; public Mediator(AbstractColleague A, AbstractColleague B) &#123; super(A, B); &#125; @Override public void AaffectB() &#123; int i = A.getNumber(); B.setNumber(i*1000); &#125; @Override public void BaffectA() &#123; int i = B.getNumber(); A.setNumber(i/1000); &#125; &#125; 同事类 12345678910111213141516171819202122232425262728293031// 抽象中介者public abstract class AbstractMediator &#123; public AbstractColleague A; public AbstractColleague B; public AbstractMediator(AbstractColleague A, AbstractColleague B)&#123; this.A = A; this.B =B; &#125; public abstract void AaffectB(); // a转b public abstract void BaffectA(); // b转a&#125;// 中介者class Mediator extends AbstractMediator&#123; public Mediator(AbstractColleague A, AbstractColleague B) &#123; super(A, B); &#125; @Override public void AaffectB() &#123; int i = A.getNumber(); B.setNumber(i*1000); &#125; @Override public void BaffectA() &#123; int i = B.getNumber(); A.setNumber(i/1000); &#125; &#125; main方法运行 1234567891011121314public static void main(String[] args) &#123; AbstractColleague collA = new ColleagueA(); AbstractColleague collB = new ColleagueB(); AbstractMediator am = new Mediator(collA, collB); collA.setNumber(1000, am); System.out.println(&quot;collA:&quot;+collA.getNumber()); System.out.println(&quot;collB:&quot;+collB.getNumber()); System.out.println(&quot;-------&quot;); collB.setNumber(1000, am); System.out.println(&quot;collA:&quot;+collA.getNumber()); System.out.println(&quot;collB:&quot;+collB.getNumber()); &#125; 运行结果 12345collA:1000collB:1000000----collA:1collB:1000 三、UML类图 四、笔记中介者模式定义: 用一个中介者对象封装一系列的对象交互，中介者使各对象不需要显示的相互作用，从而使耦合松散，而且可以独立的改变它们之间的交互。 中介者模式的优点： 将对象解耦之后，可以增加对象的互用 通过将控制逻辑集中，可以简化系统维护 可以让对象之间传递的消息变的简单，而且大幅度减少 中介者模式用途和缺点 中介者模式常常被用来协调相关的GUI组件 如果设计不当，中介者对象本身会变的过于复杂]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java mediator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－解释器模式]]></title>
    <url>%2Fpatterm%2Finterpreter.html</url>
    <content type="text"><![CDATA[一、对解释器的理解解释器就像翻译一样，将我们不认识的语言（简化的语言如o2o）翻译为我们认识的普通的语言。如果事物频繁的出现，但是比较复杂，不容易看懂。我们就可以把它表述为一个简单的事物，最用用一个解释器去解释简单的事物就可以了。 二、代码实现创建表达式接口 1234// 创建一个表达式接口public interface Expression &#123; public boolean interpret(String content); // 解释&#125; 终端表达式 1234567891011121314// 终端表达式public class TerminalExpression implements Expression&#123; private String data; public TerminalExpression(String data)&#123; this.data = data; &#125; @Override public boolean interpret(String content) &#123; if (content.contains(data)) &#123; // 包含 return true; &#125; return false; &#125;&#125; 与表达式 12345678910111213// 与表达式public class OrExpression implements Expression&#123; private Expression ex1; private Expression ex2; public OrExpression (Expression ex1, Expression ex2) &#123; this.ex1 = ex1; this.ex2 = ex2; &#125; @Override public boolean interpret(String content) &#123; return this.ex1.interpret(content) || this.ex2.interpret(content); &#125;&#125; 和表达式 12345678910111213// 和表达式public class AndExpression implements Expression&#123; private Expression ex1; private Expression ex2; public AndExpression(Expression ex1, Expression ex2) &#123; this.ex1 = ex1; this.ex2 = ex2; &#125; @Override public boolean interpret(String content) &#123; return ex1.interpret(content) &amp;&amp; ex2.interpret(content); &#125;&#125; 解析器 123456789101112131415// 解析器public class Interpreter &#123; // 获取男性表达式 public static Expression getMaleExpression()&#123; Expression wang = new TerminalExpression(&quot;小王&quot;); Expression zhang = new TerminalExpression(&quot;小张&quot;); return new OrExpression(wang,zhang); &#125; // 获取女性表达式 public static Expression getWomanExpression() &#123; Expression wu = new TerminalExpression(&quot;小吴&quot;); Expression li = new TerminalExpression(&quot;小李&quot;); return new OrExpression(wu,li); &#125;&#125; main方法实现 1234567public static void main(String[] args) &#123; Expression isMale = Interpreter.getMaleExpression(); Expression isWoman = Interpreter.getWomanExpression(); System.out.println(&quot;小李是女的&quot;+ isWoman.interpret(&quot;小李&quot;)); System.out.println(&quot;小王是男的&quot;+ isMale.interpret(&quot;小王&quot;)); System.out.println(&quot;小王是男的&quot;+ isMale.interpret(&quot;小李&quot;)); &#125; 运行结果 123小李是女的true小王是男的true小王是男的false 三、UML类图 四、笔记解释器模式的优点: 将每一个语法规则表示成一个类，方便与实现语言. 因为语法由多个类组成，因此你可以轻易的扩张语言. 可以在新的类中增加新的方法，可以在解释的同时增加新的行为。 解释器的用途和缺点: 当需要实现一个简单的语言的时候，可以使用解释器。 当有一个简单的语法，简单比效率更重要是，使用解释器。 可以处理脚本语言和编程语言 如果语法规则数量太多，使用解释器模式可能会很复杂。这个时候可以使用解析器／编译器的产生器更合适。]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java interpreter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－蝇量模式]]></title>
    <url>%2Fpatterm%2Fchain_of_responsibility.html</url>
    <content type="text"><![CDATA[一、对蝇量模式（享元模式）的理解蝇量模式的作用就是减少对象的创建次数，比如相同的对象，总是需要实例化，而且量比较大这个时候就可以考虑使用蝇量模式了。它的实现方式就是创建Map去存储对象，每次需要新创建对象的时候，就可以在map中去判断是否存在，如果不存在则新创建，否则共享之前的对象。所有也称之为享元模式。 二、代码实现创建汽车类 1234567891011public class Car &#123; private String brand; public Car(String brand)&#123; System.out.println(&quot;___创建&quot;+brand+&quot;汽车&quot;); this.brand = brand; &#125; public void drive() &#123; System.out.println(&quot;开&quot;+ brand + &quot;车&quot;); &#125;&#125; 创建汽车管理者 12345678910111213public class CarKeeper &#123; private Map&lt;String, Car&gt; map = new HashMap&lt;String, Car&gt;(); public Car getCar(String name) &#123; Car car = this.map.get(name); if (car == null) &#123; car = new Car(name); this.map.put(name, car); return car; &#125; return car; &#125;&#125; main方法实现 123456789101112131415public static void main(String[] args) &#123; CarKeeper ck = new CarKeeper(); Car car1 = ck.getCar(&quot;奥迪&quot;); car1.drive(); Car car2 = ck.getCar(&quot;宝马&quot;); car2.drive(); Car car3 = ck.getCar(&quot;雷克萨斯&quot;); car3.drive(); Car car4 = ck.getCar(&quot;雷克萨斯&quot;); car4.drive(); Car car5 = ck.getCar(&quot;宝马&quot;); car5.drive(); Car car6 = ck.getCar(&quot;奥迪&quot;); car6.drive(); &#125; 运行结果 123456789___创建奥迪汽车开奥迪车___创建宝马汽车开宝马车___创建雷克萨斯汽车开雷克萨斯车开雷克萨斯车开宝马车开奥迪车 三、UML类图 四、笔记感觉这个模式的UML图是最简单的，和单例模式差不多。 蝇量模式的优点： 减少运行时对象实例的个数，节省内存。 将许多“虚拟”对象的状态集中管理 蝇量模式的用途和缺点: 当一个类有许多的实例，而这些实例能被同一个方法控制的时候，就可以使用蝇量模式 一旦实现了蝇量模式，那么单个的逻辑实例将无法独立的实现不同的行为。]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java chainOfResponsibility</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在2018结束之前的目标]]></title>
    <url>%2Flife%2Ftarget.html</url>
    <content type="text"><![CDATA[2018年还有最多四个月就结束了，从写第一行代码到现在已经有两年多了。在这两年多的时间里，学习的很多的知识，总是在马不停蹄的学习，但是总是感觉学习的不够，也总是很浮躁，总想学习更多的东西，总是想贪多。但是如果一直这样下去的话，自己只会变的越来越浮躁。必须逼自己一下，要让自己沉淀下来，深入学习底层原理，这样才能走的更远。 一、设计模式 最近买了head first的书，已经看完了，总共23个设计模式。距离实现全部的模式我还差6个。学习的方式，就是先看一遍书籍，然后想一个相同案例,之后源码实现，画UML类图，通过自己的总结之后在纪录到自己的博客里面。在写博客的时候，全部手打，不能容忍自己command c 之后 command v 。当然只是这样还是不够的，需要在以后的代码中灵活的使用这些设计模式，这才是最重要的。 目标总的目标就是实现完所有的设计模式，并理解每个设计模式的原理。并大量的在代码中实现。 二、英语对于我的垃圾英语，我已经无力吐槽了。总是想好好的学习，但是自己总是给了自己种种的借口，这种借口我也不知道要持续到什么时候。我想要尽快的结束这种借口，能让自己可以在看English的文档的时候能游刃有余。今天看到了有大牛写的关于学习English的博客，自我感觉最重要的就是坚持，只要在学习的道路上坚持下去就会有所沉淀。对于English的学习也就是听、说、读、写。我现在写English文档那是还有很大一段的路要走的。听和说，对于不想讲话的我也是比较遥远的。所以只剩下了读，这也是对我最重要的，也是最迫切需要的。对许学习读的方法对我比较好的就是看各种美剧的剧本（很喜欢看美剧），或者技术文档（很大文档都是需要看的）。于是我选择的就是看技术文档。 目标 每天看技术文档，目前想要学习的技术就是spring,spring boot,spring cloud，就从这个开始，尽量多的抽时间看技术文档。让自己的技术和英语一起进步，让自己泡在English的spring里面。 如果看的实在费劲，就写博客，一边翻译spring的技术，一边学习English. 三、spring, spring boot, spring cloud现在公司写的项目就是基于spring boot实现的，虽然功能实现了，但是感觉很多的技术，自己都没有摸透。需要花大量的时间，去好好的琢磨。spring 也是只会基础的。底层原理自己也没有去梳理一遍。spring cloud更是才了解一点。 目标看spring源码，了解spring底层实现。了解spring boot原理，学习spring cloud搭建以及实现。 总结总的来说，事情还是很多的，首先先看spring的英文文档。通过文档学习技术和英语。如果技术无法增长，就购买最近很想买的spring 三剑客。好好学习。 在就是自己的娱乐时间，感觉需要缩短一些。现在看新闻、看短视频、看朋友圈，总是会花很多的时间。希望自己能合理安排时间，多一些学习的时间，加油。 后面学习的路线 给自己的一些规划总是在各种借口中推脱掉了。]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>life 2018</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 笔记]]></title>
    <url>%2Fjava%2Fbase.html</url>
    <content type="text"><![CDATA[一、基础1.1 java方法中参数的传递(java中只有值传递)： 一个方法不能修改一个基本数据类型的参数（即数值型或布尔型)(方法中改变基本类型数据，不会影响到之前的数据。相当于拷贝数据) 一个方法可以改变一个对象参数的状态。(对象: 方法中改变对象的数据，原始的对象的值会跟着改变。) 一个方法不能让对象参数引用一个新的对象 1.2 ==与equals的区别== 判断的是是否是对象的地址，即判断连个对象是不是同一个地址。（基本数据类型对比的是值，引用数据类型对比的是对象地址） equals 判断的是值是否相同（对象没有覆盖equals方法相当于== ，否则通过覆盖的equals判断对象的值是否相等） 如果对象需要用equals对比，需要重写equals方法。 String 对象是重写过equals方法的，所有string的equals对比的是值。 当创建string类型对象的时候，虚拟机会在常量池中找是否有相同的对象，如果有就把它赋给当前引用，否则就新创建对象 1.3 hashCode与equals hashCode的作用就是获取哈西码。它实际返回的是一个int整数。这个哈西码的作用就是确定索引的位置（可以快速找到所需要的对象）。 hashCode在map中的作用就是为了减少equals的执行次数,相应就提高了执行速度。 如果不同的对象拥有相同的hashCode值，他们也不一定是相等的。如果相同的情况下，就像HashSet一样，会使用equals去对比值是否相同。 二、事务2.1 @transactional注解在什么情况下会失效 只能应用到public修饰符上，其它修饰符不起作用，但不报错 数据库引擎不支持事务(Mysql的MyISAM不支持事务) 没有被 Spring 管理 数据源没有配置事务管理器 异常捕获之后不抛出。try{}catch(Exception e){} @Transactional 注解属性 propagation 设置错误，如：TransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。这3种设置都会滚。 @Transactional 注解属性 rollbackFor 设置错误（抛出异常如果不是运行时异常需要添加注解@Transactional(rollbackFor = Exception.class)） 同一个类中方法调用，导致@Transactional失效。比如有一个类Test，它的一个方法A，A再调用本类的方法B（不论方法B是用public还是private修饰），但方法A没有声明注解事务，而B方法有。则外部调用方法A之后，方法B的事务是不会起作用的（只有当事务方法被当前类以外的代码调用时，才会由Spring生成的代理对象来管理）]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java base</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－责任链模式]]></title>
    <url>%2Fpatterm%2Fchain_ofResponsibilitys.html</url>
    <content type="text"><![CDATA[一、对责任链模式的理解一个请求需要由多个对象处理，这些对象可以链接成为一条链。具体由那个类处理，由判断条件决定，如果该对象不能处理，则传给下一个对象处理。责任链将请求和处理分开。责任链比较好的例子就向请假一样，你需要请假10天，需要由你的主管确认，经理确认，总经理确认，全部通过才可以休假。但是如果请假5天，可能总经理就不用审核了，经理直接就可以处理这件事情。还有Logger的异常处理也是这种方式。下面的代码就是基于日志实现的。 二、代码实现创建一个抽象日志类 1234567891011121314151617181920212223// 抽象日志public abstract class AbstractLogger &#123; public static int INFO = 1; public static int DEBUG = 2; public static int ERROR = 3; public int level; public AbstractLogger nextLogger; // 下一个链条 public void setNextLogger(AbstractLogger al) &#123; this.nextLogger = al; &#125; public void logMessage(int le, String message) &#123; if (this.level&lt;=le) &#123; write(message); &#125; if (this.nextLogger != null) &#123; this.nextLogger.logMessage(le, message); &#125; &#125; abstract public void write(String message);&#125; 创建其他类继承抽象日志类 123456789101112131415161718192021222324252627282930// 打印日志public class ConsoleLogger extends AbstractLogger&#123; public ConsoleLogger(int le) &#123; this.level = le; &#125; @Override public void write(String message) &#123; System.out.println(&quot;打印日志:&quot;+message); &#125;&#125;class ErrorLogger extends AbstractLogger&#123; public ErrorLogger(int le) &#123; this.level = le; &#125; @Override public void write(String message) &#123; System.out.println(&quot;异常日志:&quot;+message); &#125;&#125;// 文件日志class FileLogger extends AbstractLogger&#123; public FileLogger(int le) &#123; this.level = le; &#125; @Override public void write(String message) &#123; System.out.println(&quot;文件日志:&quot; + message); &#125;&#125; 创建责任链链条 12345678910public class Chain &#123; public static AbstractLogger getChainOfLogger() &#123; AbstractLogger el = new ErrorLogger(AbstractLogger.ERROR); AbstractLogger fl = new FileLogger(AbstractLogger.DEBUG); AbstractLogger cl = new ConsoleLogger(AbstractLogger.INFO); el.setNextLogger(fl); fl.setNextLogger(cl); return el; &#125;&#125; main方法实现 1234567public static void main(String[] args) &#123; AbstractLogger al = Chain.getChainOfLogger(); al.logMessage(AbstractLogger.INFO, &quot;文件信息&quot;); al.logMessage(AbstractLogger.DEBUG, &quot;debug信息&quot;); al.logMessage(AbstractLogger.ERROR, &quot;异常信息&quot;); &#125; 执行结果 123456打印日志:文件信息文件日志:debug信息打印日志:debug信息异常日志:异常信息文件日志:异常信息打印日志:异常信息 三、UML类图 四、笔记 责任链定义: 避免请求发送者和接收者耦合到一起，让多个对象都有可能接收请求，将这些对象连接成一条链，并且沿着这条链传递请求，直到有对象处理它为止。责任链模式是一种对象行为行模式。 责任链优点 将请求的发送者和接收者解耦。 简化对象，它不需要知道链的结构。 通过改变或调用链内成员的次序，允许动态新增和删除责任 责任链的用途和缺点 经常用到窗口系统中，处理鼠标键盘等事件。 并不保证请求一定会被执行，如果没有处理类去处理请求的话，可以会落到链尾之外。有好有坏 比较不容易观察运行特征，不好排除错误。 github源码：https://github.com/gaoqisen/java-pattern]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java chainOfResponsibility</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－桥接模式]]></title>
    <url>%2Fpatterm%2Fbridge.html</url>
    <content type="text"><![CDATA[一、对桥接模式的理解在很多个网站都看到了桥接模式的定义，最直观的理解就是要画正方形、圆形、长方形，画笔有红色、蓝色、紫色。当出现了两个以上的类别(形状、颜色。一个类出现了两个独立的变化的维度，且这两个维度都需要进行扩展)的时候，就可以考虑使用桥接模式了。 桥接模式定义:将抽象部分与实现部分分离，使他们都可以独立的变化。它是一种对象结构型模式，又称为柄体模式或接口模式。 二、 代码实现创建颜色和形状的api接口，并创建红色、绿色、圆形、正方形等实现各自的接口。 12345678910111213141516171819202122232425262728293031323334353637383940// 颜色apipublic interface ColorAPI &#123; // 画 public void Draw();&#125;// 红色class Red implements ColorAPI&#123; @Override public void Draw() &#123; System.out.println(&quot;用红色的笔&quot; ); &#125;&#125;// 绿色class Green implements ColorAPI&#123; @Override public void Draw() &#123; System.out.println(&quot;用绿色的笔&quot;); &#125; &#125;// 形状apiinterface ShapeAPI &#123; // 画 public void Draw();&#125;// 圆形class Circle implements ShapeAPI&#123; @Override public void Draw() &#123; System.out.println(&quot;画圆形&quot;); &#125; &#125;class Square implements ShapeAPI&#123; @Override public void Draw() &#123; System.out.println(&quot;画正方形&quot;); &#125; &#125; 创建形状的抽象类，与抽象类的实现类 123456789101112131415161718192021222324// 形状抽象类public abstract class Shape &#123; ColorAPI colorAPI; ShapeAPI shapeAPI; Shape(ColorAPI ca ,ShapeAPI sa) &#123; this.colorAPI = ca; this.shapeAPI = sa; &#125; // 画的抽象方法 public abstract void draw();&#125;// 形状实现class ShapeImpl extends Shape&#123; ShapeImpl(ColorAPI ca, ShapeAPI sa) &#123; super(ca, sa); // TODO Auto-generated constructor stub &#125; @Override public void draw() &#123; this.colorAPI.Draw(); this.shapeAPI.Draw(); &#125;&#125; main方法运行 12345678public static void main(String[] args) &#123; Shape redCircle = new ShapeImpl(new Red(), new Circle()); Shape greenSquare = new ShapeImpl(new Green(), new Square()); Shape greenCircle = new ShapeImpl(new Green(), new Circle()); redCircle.draw(); greenSquare.draw(); greenCircle.draw(); &#125; 运行结果 123456用红色的笔画圆形用绿色的笔画正方形用绿色的笔画圆形 三、UML类图 四、 笔记 桥接模式定义: 将抽象个部分与它的实现部分分离，使他们可以独立的变化。它是一种对象结构型模式。 00原则 封装变化 针对接口编程，不针对实现编程 对增加开放，对修改关闭 不要来找我，我来找你 只对朋友交谈 为交互对象之间的松耦合设计而努力 多用组合，少用继承 类应该只有一个被改变的理由 依赖抽象，不依赖具体实现类 github源码：https://github.com/gaoqisen/java-pattern]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－建造者模式]]></title>
    <url>%2Fpatterm%2Fbuilder.html</url>
    <content type="text"><![CDATA[一、对建造者模式的理解就是将多个简单的对象一步一步构建为一个复杂的对象。主要解决软件开发中的一个复杂对象的创建。代码就实现汉堡和饮料的点餐功能。我们创建包装接口，由瓶子装饮料，包装纸包装汉堡的实现类去实现包装接口。在创建一个项目接口，由汉堡和冷饮的抽象类去实现，之后创建各自的实现类去实现，汉堡有蔬菜汉堡和鸡肉汉堡，冷饮后百事可乐和可口可乐。在然后创建用餐的类采用list存放项目。最后创建一个用餐建造类来建造蔬菜餐和非蔬菜餐。 二、代码实现创建包装接口和各自的实现类 123456789101112131415161718192021package study.builder;// 装食物的填料接口public interface Packing &#123; public String pack(); // 大包&#125;// 包装纸材料class Wrapper implements Packing&#123; @Override public String pack() &#123; return &quot;包装材料&quot;; &#125;&#125;// 瓶子包装class Bottle implements Packing&#123; @Override public String pack() &#123; return &quot;瓶子包装&quot;; &#125; &#125; 创建项目接口，汉堡、冷饮接口以及各自的实现类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// 项目接口public interface Item &#123; public String name(); public Packing packing(); public float price();&#125;// 汉堡使用包装纸包装抽象类abstract class Burger implements Item&#123; public Packing packing()&#123; return new Wrapper(); &#125;; public abstract float price(); &#125;// 冷饮抽象类abstract class ColdDrink implements Item&#123; public Packing packing() &#123; return new Bottle(); &#125; public abstract float price();&#125;// 蔬菜汉堡class VegBurger extends Burger&#123; @Override public String name() &#123; return &quot;蔬菜汉堡&quot;; &#125; @Override public float price() &#123; return 18.8f; &#125;&#125;// 鸡肉汉堡class ChickenBurger extends Burger&#123; @Override public String name() &#123; return &quot;鸡肉汉堡&quot;; &#125; @Override public float price() &#123; return 28.8f; &#125;&#125;// 可口可乐class Coke extends ColdDrink&#123; @Override public String name() &#123; return &quot;可口可乐&quot;; &#125; @Override public float price() &#123; return 5.5f; &#125;&#125;// 百事可乐class Pepsi extends ColdDrink&#123; @Override public String name() &#123; return &quot;百事可乐&quot;; &#125; @Override public float price() &#123; return 5.6f; &#125;&#125; 创建用餐类 123456789101112131415161718192021// 餐public class Meal &#123; private List&lt;Item&gt; items = new ArrayList&lt;Item&gt;(); public void add(Item it )&#123; this.items.add(it); &#125; public float getCost() &#123; float cost = 0.0f; for(Item it : items) &#123; cost += it.price(); &#125; return cost; &#125; public void showItem()&#123; for(Item it : items) &#123; System.out.print(&quot;项目：&quot;+it.name()); System.out.print(&quot;, &quot; +it.packing().pack()); System.out.println(&quot;, 价格&quot; + it.price()); &#125; &#125;&#125; 创建构造餐类 12345678910111213141516// 建造餐public class MealBuilder &#123; // 准备蔬菜餐 public Meal prepareVegMeal() &#123; Meal meal = new Meal(); meal.add(new VegBurger()); meal.add(new Coke()); return meal; &#125; public Meal prepareNonVegMeal() &#123; Meal meal = new Meal(); meal.add(new ChickenBurger()); meal.add(new Pepsi()); return meal; &#125;&#125; main方法实现 12345678910public static void main(String[] args) &#123; MealBuilder mb = new MealBuilder(); Meal vegMeal = mb.prepareVegMeal(); vegMeal.showItem(); System.out.println(&quot;蔬菜餐的总价：&quot;+ vegMeal.getCost()); Meal nonvegMeal = mb.prepareNonVegMeal(); nonvegMeal.showItem(); System.out.println(&quot;肉类餐的总价：&quot;+ nonvegMeal.getCost()); &#125; 运行结果 123456项目：蔬菜汉堡, 包装材料, 价格18.8项目：可口可乐, 瓶子包装, 价格5.5蔬菜餐的总价：24.3项目：鸡肉汉堡, 包装材料, 价格28.8项目：百事可乐, 瓶子包装, 价格5.6肉类餐的总价：34.399998 三、 UML类图 四、 笔记 定义: 将一个复杂的对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。 github源码：https://github.com/gaoqisen/java-pattern]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java builder</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7部署MinDoc API在线文档管理系统]]></title>
    <url>%2Ftool%2Fmindoc.html</url>
    <content type="text"><![CDATA[前言： 由于是前后端分离的项目，API是前后端最重要的沟通工具，用一个好的在线文档管理系统代替FTP等文本传输API是一个很不错的选择。在线文档比较好的开源文档系统就是wiki。MediaWiki是基于wiki用PHP开发的，配置起来比较复杂。后来发现一个MinDoc使用go语言开发的，特别方便。我将两种配置方式都记录一下。两种方式都需要安装mysql，CentOS7 的yum里面没有mysql，需要手动下载。 需要准备的就是配置外网可以访问的端口号，mindoc默认8181，可以先去配置好，阿里云的ECS服务器可以直接在安全组里面配置。 没有安装mysql的可以先安装mysql 123456789101112131415161718wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm //下载mysql的repo源sudo rpm -ivh mysql-community-release-el7-5.noarch.rpm // 安装mysql-community-release-el7-5.noarch.rpm包sudo yum install mysql-server // 安装mysqlmysql -u root // 重置mysql密码// 出现ERROR 2002 (HY000): Can‘t connect to local MySQL server through socket ‘/var/lib/mysql/mysql.sock‘ (2)sudo chown -R root:root /var/lib/mysqlservice mysqld restart // 重启mysqlmysql //直接回车进入mysql控制台mysql &gt; use mysql; // 使用mysql数据库mysql &gt; update user set password=password(&apos;123456&apos;) where user=&apos;root&apos;; // 更改密码 一、MinDoc1. 下载MinDoc12345mkdir mindoc &amp;&amp; cd mindoc //创建一个目录wget https://github.com/lifei6671/mindoc/releases/download/v0.9/mindoc_linux_amd64.zip //下载二进制包unzip mindoc_linux_amd64.zip // 解压 2. 修改conf/app.conf 文件，打开文件注释123456789db_adapter=mysqldb_host=127.0.0.1db_port=3306db_database=mindoc_dbdb_username=rootdb_password=123456adb_adapter=sqlite3db_database=./database/mindoc.db 3. 当前目录进行安装1./mindoc_linux_amd64 install 4. 出现Install Successfully! 之后就可以运行并访问123./mindoc_linux_amd64 // 在线运行，不能退出nohup ./mindoc_linux_amd64 &amp; // 后台运行 访问http://IP:8181 即可，帐号admin 密码123456 end 二、mediawiki1. 安装需要的一些配置1yum install httpd php php-mysql php-gd php-xml mysql-server mysql libxml2 2. 在mysql启动的状态下配置mysql1mysql_secure_installation 3. 在mysql里面配置项目1234567create database wikidb; grant all on wikidb.* to root; grant all on wikidb.* to root@localhost; grant all on wikidb.* to wikiuser; grant all on wikidb.* to wikiuser@localhost; set password for wikiuser@localhost=password(&apos;wikipw&apos;); 4.修改httpd配置123456789vim /etc/httpd/conf/httpd.conf#ServerName www.example.com:80 // 前面的#去掉(去掉注释)vim /etc/hosts 127.0.0.1 localhost localhost.localadmin xxhost // 添加hostnameservice httpd restart // 启动网络服务 5.Mediawiki的手动安装12345678wget http://releases.wikimedia.org/mediawiki/1.22/mediawiki-1.22.5.tar.gztar -xvf mediawiki-1.22.5.tar.gz // 解压mv mediawiki-1.22.5 /var/www/html/w // 将解压后的文件夹移动到httpd.conf中DocumentRoot指定的文件夹中，默认是&quot;var/www/html&quot;chown -R 777 /var/www/html/w/chmod 777 /var/www/html/w/mw-config // 改变权限 通过http://ip/w/index.php访问，出现下面标志表示成功 两种方式都实现了，最后就需要自己去配置个性化的设置。这两个都有自己不同的展示方式，个人偏好与第一种页面风格很友好。功能也更加完善，编辑器也是基于Markdown的。]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>MinDoc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－复合模式]]></title>
    <url>%2Fpatterm%2Fobservable.html</url>
    <content type="text"><![CDATA[一、对于复合模式的理解复合模式就是很多模式一起乱炖。工厂模式、抽象工厂模式、迭代器模式、组合模式、装饰模式、适配器模式、观察者模式，在一起使用。但是每次使用的时候都是在需要的时候使用。每个模式都有各自的作用，使用在一起就是会觉得代码非常的拥挤，很混乱。这个模式我是照搬书上的代码实现的。下面的代码就比较多了，书上面是循序渐进的讲解的，我是直接粘贴自己写的代码，不是很容易理解。可以先看看下面的类图。 二、代码实现创建鸭叫观察者，用于统计鸭子 123456789101112131415161718192021222324252627282930// 鸭叫观察者接口public interface QuackObservable &#123; public void registerObserver(Observer observer); public void notifyObservers();&#125;interface Observer &#123; public void update(QuackObservable duck);&#125;// 观察者辅助类class Observable implements QuackObservable&#123; ArrayList observers = new ArrayList(); QuackObservable duck; public Observable(QuackObservable q)&#123; this.duck = q; &#125; @Override public void registerObserver(Observer observer) &#123; this.observers.add(observer); &#125; @Override public void notifyObservers() &#123; Iterator it = this.observers.iterator(); while (it.hasNext()) &#123; Observer ob = (Observer)it.next(); ob.update(duck); &#125; &#125; &#125; 创建鸭叫能力接口以及各种鸭子 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128// 鸭叫能力接口public interface Quackable extends QuackObservable&#123; public void quack(); // 呱呱叫&#125;// 绿头鸭实现鸭叫能力接口class MallardDurk implements Quackable&#123; Observable ob; @Override public void quack() &#123; System.out.println(&quot;绿头鸭嘎嘎叫&quot;); this.ob = new Observable(this); &#125; @Override public void registerObserver(Observer observer) &#123; this.ob.registerObserver(observer); &#125; @Override public void notifyObservers() &#123; this.ob.notifyObservers(); &#125;&#125;// 红头鸭也实现鸭叫能力接口class RedheadDuck implements Quackable&#123; Observable ob; @Override public void quack() &#123; System.out.println(&quot;红头鸭嘎嘎叫&quot;); this.ob = new Observable(this); &#125; @Override public void registerObserver(Observer observer) &#123; this.ob.registerObserver(observer); &#125; @Override public void notifyObservers() &#123; this.ob.notifyObservers(); &#125;&#125;//鸭鸣器也实现了鸭叫能力接口class DuckCall implements Quackable&#123; Observable ob; @Override public void quack() &#123; System.out.println(&quot;鸭鸣器嘎嘎叫&quot;); this.ob = new Observable(this); &#125; @Override public void registerObserver(Observer observer) &#123; this.ob.registerObserver(observer); &#125; @Override public void notifyObservers() &#123; this.ob.notifyObservers(); &#125;&#125;// 橡皮鸭也实现了鸭叫能力接口class RubberDuck implements Quackable&#123; Observable ob; @Override public void quack() &#123; System.out.println(&quot;橡皮鸭嘎嘎叫&quot;); this.ob = new Observable(this); &#125; @Override public void registerObserver(Observer observer) &#123; this.ob.registerObserver(observer); &#125; @Override public void notifyObservers() &#123; this.ob.notifyObservers(); &#125;&#125;// 鹅class Goose&#123; public void honk() &#123; System.out.println(&quot;鹅咯咯叫&quot;); &#125;&#125;// 用适配器模式将鹅适配为鸭子class GooseAdapter implements Quackable&#123; Observable ob; Goose goose; public GooseAdapter(Goose goose) &#123; this.ob = new Observable(this); this.goose = goose; &#125; @Override public void quack() &#123; this.goose.honk(); &#125; @Override public void registerObserver(Observer observer) &#123; this.ob.registerObserver(observer); &#125; @Override public void notifyObservers() &#123; this.ob.notifyObservers(); &#125;&#125;// 利用装饰者模式，在不改变原来鸭子类的情况下给鸭子添加计数功能class QuackCounter implements Quackable&#123; Observable ob; Quackable duck; static int num; public QuackCounter (Quackable quack) &#123; this.ob = new Observable(quack); this.duck = quack; &#125; @Override public void quack() &#123; this.duck.quack(); num++; &#125; public static int getNum() &#123; return num; &#125; @Override public void registerObserver(Observer observer) &#123; this.ob.registerObserver(observer); &#125; @Override public void notifyObservers() &#123; this.ob.notifyObservers(); &#125;&#125; 创建鸭叫的各种工厂 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// 鸭叫抽象工厂public abstract class AbstractDuckFactory &#123; public abstract Quackable createMallardDuck(); public abstract Quackable createRedheadDuck(); public abstract Quackable createDuckCall(); public abstract Quackable createRubberDuck();&#125;// 鸭叫工厂实现鸭叫抽象工厂class DuckFactory extends AbstractDuckFactory&#123; @Override public Quackable createMallardDuck() &#123; return new MallardDurk(); &#125; @Override public Quackable createRedheadDuck() &#123; return new RedheadDuck(); &#125; @Override public Quackable createDuckCall() &#123; return new DuckCall(); &#125; @Override public Quackable createRubberDuck() &#123; return new RubberDuck(); &#125;&#125;// 统计鸭子工厂继承鸭子抽象工厂class CountingDuckFactory extends AbstractDuckFactory&#123; @Override public Quackable createMallardDuck() &#123; // 先用叫声计数装饰着将quackable装饰起来 return new QuackCounter(new MallardDurk()); &#125; @Override public Quackable createRedheadDuck() &#123; return new QuackCounter(new RedheadDuck()); &#125; @Override public Quackable createDuckCall() &#123; return new QuackCounter(new DuckCall()); &#125; @Override public Quackable createRubberDuck() &#123; return new QuackCounter(new RubberDuck()); &#125;&#125; 创建一群鸭子 123456789101112131415161718192021222324252627// 用组合模式实现一群鸭子public class Flock implements Quackable&#123; Observable ob; ArrayList list = new ArrayList(); public Flock() &#123; this.ob = new Observable(this); &#125; @Override public void quack() &#123; Iterator it = list.iterator(); // 迭代器模式 while(it.hasNext()) &#123; Quackable q = (Quackable)it.next(); q.quack(); &#125; &#125; public void add(Quackable q) &#123; list.add(q); &#125; @Override public void registerObserver(Observer observer) &#123; this.ob.registerObserver(observer); &#125; @Override public void notifyObservers() &#123; this.ob.notifyObservers(); &#125;&#125; 创建呱呱叫学家 12345678public class Quackologist implements Observer&#123; @Override public void update(QuackObservable duck) &#123; System.out.println(&quot;呱呱叫学家：&quot;+duck); &#125;&#125; 创建鸭子模拟器 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// 鸭子模拟器public class DuckSimulator &#123; public void simulate() &#123; // 模拟 Quackable mallardDuck =new QuackCounter( new MallardDurk()); Quackable redheadDuck = new QuackCounter(new RedheadDuck()); Quackable duckCall = new QuackCounter(new DuckCall()); Quackable rubberDuck = new QuackCounter(new RubberDuck()); Quackable goose = new GooseAdapter(new Goose()); // 一只鹅 sumulate(mallardDuck); sumulate(redheadDuck); sumulate(duckCall); sumulate(rubberDuck); sumulate(goose); System.out.println(&quot;鸭子的数量为:&quot;+QuackCounter.getNum()); &#125; private void sumulate(Quackable qa) &#123; qa.quack(); &#125; // 重写构造方法 public void simulate(AbstractDuckFactory adf) &#123; Quackable mallardDuck =adf.createMallardDuck(); Quackable redheadDuck = adf.createRedheadDuck(); Quackable duckCall = adf.createDuckCall(); Quackable rubberDuck = adf.createRubberDuck(); Quackable goose = new GooseAdapter(new Goose()); // 一只鹅 Flock fock = new Flock(); // 一群乱七八糟的鸭子 fock.add(redheadDuck); fock.add(rubberDuck); fock.add(duckCall); fock.add(mallardDuck); Flock focks = new Flock(); Quackable redheadDuck1 = adf.createRedheadDuck(); //一群红头鸭子 Quackable redheadDuck2 = adf.createRedheadDuck(); Quackable redheadDuck3 = adf.createRedheadDuck(); Quackable redheadDuck4 = adf.createRedheadDuck(); focks.add(redheadDuck4); focks.add(redheadDuck3); focks.add(redheadDuck2); focks.add(redheadDuck1); System.out.println(&quot;红头鸭子打头&quot;); sumulate(focks); System.out.println(&quot;乱七八糟的鸭子来了&quot;); sumulate(fock); System.out.println(&quot;鸭子的数量为:&quot;+QuackCounter.getNum()); Quackologist ql = new Quackologist(); fock.registerObserver(ql); sumulate(fock); System.out.println(&quot;鸭子的数量为:&quot;+QuackCounter.getNum()); &#125;&#125; main方法运行 12345678public static void main(String[] args) &#123; DuckSimulator ds1 = new DuckSimulator(); ds1.simulate(); DuckSimulator ds = new DuckSimulator(); AbstractDuckFactory adf = new CountingDuckFactory(); ds.simulate(adf); &#125; 实现结果 12345678910111213141516红头鸭子打头红头鸭嘎嘎叫红头鸭嘎嘎叫红头鸭嘎嘎叫红头鸭嘎嘎叫乱七八糟的鸭子来了红头鸭嘎嘎叫橡皮鸭嘎嘎叫鸭鸣器嘎嘎叫绿头鸭嘎嘎叫鸭子的数量为:8红头鸭嘎嘎叫橡皮鸭嘎嘎叫鸭鸣器嘎嘎叫绿头鸭嘎嘎叫鸭子的数量为:12 三、UML类图 这个复合模式很复杂，需要掌握的技巧特别多，需要反复学习。后面就要学习mvc模式了，也是属于复合模式。 github源码：https://github.com/gaoqisen/java-pattern]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式 - 代理模式]]></title>
    <url>%2Fpatterm%2Fproxy.html</url>
    <content type="text"><![CDATA[昨天将组合模式完成了，组合模式可以遍历树状的集合。迭代器模式可以遍历不同类型的集合。如果有树状结构的集合，可以优先考虑使用组合模式。 一、对于代理模式的理解定义：给目标对象提供一个代理对象，并由代理对象控制对目标对象的引用。就想黄牛一样，委托代买票业务给黄牛，黄牛收钱买票，我不知道黄牛是如何买票的，卖票的人不知道是谁买票的，便于保护真实用户。代理模式也经常用于远程代理，和虚拟代理等 二、代码实现创建一个主题，用于黄牛和真实的我继承。12345// 创建主题接口public interface Subject &#123; // 买票 public void buyTicket();&#125; 创建一个真的我，买票.实现主题 1234567// 真实主题（我）public class RealSubject implements Subject&#123; @Override public void buyTicket() &#123; System.out.println(&quot;我要买票回家&quot;); &#125;&#125; 创建代理类，实现主题 1234567891011121314// 代理买票（黄牛）public class Proxy implements Subject&#123; @Override public void buyTicket() &#123; RealSubject rs = new RealSubject(); rs.buyTicket(); this.compterTicket(); &#125; // 不公开的买票方式，通过电脑买票 private void compterTicket() &#123; System.out.println(&quot;黄牛进行买票&quot;); &#125;&#125; mian方法运行 12345public static void main(String[] args) &#123; // 调用者完全不知道是谁买票，只知道是一个黄牛保护目标 Subject sb =new Proxy(); sb.buyTicket(); &#125; 运行结果 12我要买票回家黄牛进行买票 三、UML类图 四、笔记 封装变化 针对接口编程，不针对实现编程 对修改关闭，对扩展开放 多用组合，少用继承 为交互对象之间的松耦合设计而努力 依赖抽象，不依赖具体类 只和朋友交谈 别找我，我会找你 类应该只有一个改变的理由 定义: 为另一个对象提供一个替身或占位符以访问这个对象 github源码：https://github.com/gaoqisen/java-pattern]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 使用jenkins+maven+git实现自动化部署java项目]]></title>
    <url>%2Flinux%2Fjenkins.html</url>
    <content type="text"><![CDATA[要将项目发布到通过外网访问，就需要将jar或者war通过scp传到服务器，在启动项目。如果项目中更改了一行代码，那么就需要进行一下步骤： 本地将项目打包为war或者jar包 将打包后的文件传到服务器 将之前项目kill掉 将新项目移动到指定位置启动 但有了jenkins后我们就可以只需要将代码提交到git或者svn上面就可以了，其它的事情全部交给jenkins去完成。要实现这个功能大概的思路如下： 1、安装jenkins（自动化配置）2、安装git（管理项目）3、安装maven(编译项目)4、配置jenkins如下 安装插件 （jenkins集成tomcat、svn、git等的插件） 全局工具配置（让jenkins找到jdk,maven,git的环境变量等） 创建任务一、安装jenkins由于yum的repo里面没有jenkins,先配置yum12sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.reposudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key yum安装1yum -y install jenkins 更改jenkins配置 1vi /etc/sysconfig/jenkins 将JENKINS_NAME改为root,JENKINS_PORT改为8081 启动jenkins1service jenkins start 开通8081的端口号之后，通过在外网用http://ip地址:8081 访问出现如下页面即可： 根据提示，在/var/lib/jenkins/secrets/initialAdminPassword中找到密码复制进去点击继续，不要着急稍微等待一会之后即可看到如下页面 之后点击第一个默认配置，右边的是自定义配置，不熟悉的可以选择第一个（左边的那个）之后就是漫长的等待，等jenkins下载基础插件 安装完成之后就创建自己的账号和密码吧！ 之后点击继续后出现下面这个页面就安装完成了 二、安装maven配置yum1wget http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo -O /etc/yum.repos.d/epel-apache-maven.repo yum安装1yum -y install apache-maven 查看是否安装成功 1mvn -v 三、安装git12yum -y install gitgit --version // 查看git版本号 四、配置jenkins1、安装插件maven integration 插件：用于maven集成jenkins，如果不安装就不会有“构建一个maven”项目选项 2、全局工具配置（让jenkins找到jdk,maven,git等）3、新建任务遇到的坑：1、配置git出现如下错误 因为此仓库为我的私有仓库，需要配置Credentials，点开add， Add Credentials的 Kind选择SSH Username with private key，Username选择之前在github上传的公钥用户的用户名，此次为root，Private Key为jenkins服务器登录github的本地私钥，查看私钥cat /root/.ssh/id_rsa （如果没有这个文件则生成命令为：ssh-keygen -t rsa）复制粘贴到Key区域，完成添加。此时可以发现报错已经消失。构建的时候可能会遇到git超时可以安装这个处理[https://www.jianshu.com/p/264772bb9264](https://www.jianshu.com/p/264772bb9264)要这个页面将超时时间设置长一些，我设置的是260分钟。默认是10分钟，由于项目比较大，通过git将项目迁到服务器总是超时。设置这个就好了 2、构建触发器，就是设置何时开始启动build，运行程序。选这里选默认3、其它的先不动将build改为如下： 4.在写sh脚本的时候要加 BUILD_ID=dontKillMe 否则项目不会启动 1234567891011121314151617#!/bin/bashport=8098echo &quot;check $port&quot;grep_port=`netstat -tlpn | grep &quot;\b$port\b&quot;`echo &quot;grep port is $grep_port&quot;if [ -n &quot;$grep_port&quot; ]then echo &quot;端口 $port 在使用&quot; netstat -nlp |grep :8098 |grep -v grep|awk &apos;&#123;print $7&#125;&apos; |awk -F &apos;/&apos; &apos;&#123;print $1&#125;&apos; |xargs kill -9 echo &quot;kill 掉$port 端口&quot;else echo &quot;端口没有被使用&quot;fiecho &quot;开始重启&quot;# 此处要注意加BUILD_ID=dontKillMe 否则jenkins不会将项目启动下去BUILD_ID=dontKillMe nohup java -jar /var/lib/jenkins/workspace/projectName/target/projectName-0.0.1-SNAPSHOT.jar &amp;echo &quot;jenkins 自动化部署成功&quot; 最后在控制台查看jenkins部署日志，项目需要用maven可以编译通过 五、配置git钩子触发jenkins构建]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7 安装mysql]]></title>
    <url>%2Ftool%2FmysqlInstall.html</url>
    <content type="text"><![CDATA[一、下载mysql的repo源1wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm 二、安装mysql-community-release-el7-5.noarch.rpm包1sudo rpm -ivh mysql-community-release-el7-5.noarch.rpm 三、安装mysql1sudo yum install mysql-server 四、进入mysql1mysql 五、报错 ERROR 2002 (HY000): Can‘t connect to local MySQL server through socket ‘/var/lib/mysql/mysql.sock‘ (2)，原因是/var/lib/mysql的访问权限问题。下面的命令把/var/lib/mysql的拥有者改为当前用户： 1sudo chown -R root:root /var/lib/mysql 六、重启mysql1service mysqld restart 七、更改密码1update user set password=password(&apos;123456&apos;) where user=&apos;root&apos;;]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>mysql CentOS7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式 - 组合模式]]></title>
    <url>%2Fpatterm%2Fcomponent.html</url>
    <content type="text"><![CDATA[已经有一段时间没有写模式了，在把迭代器模式写了之后，本应该是写组合模式的，但是组合模式涉及到递归，感觉很麻烦，于是就跳跃了，没有及时写下来，之后看了代理模式，复合模式等。都没有记录下来。现在是时候好好理一下这些模式了，昨天复习了下之前的模式，特别感觉工厂方法和抽象工厂都有些模糊了。看来要努力了，加油！ 一、对组合模式的理解组合模式定义：允许你将对象组合成树形结构来表现“整体／部分”层次结构。组合能让客户以一致的方式处理个别对象以及对象集合。 个人理解就是处理树形结构集合的一种模式就想树一样，是有根，有无数的树枝，无数的叶子，一成一层的，就像电脑文件夹一样 二、代码实现实现抽象类12345678// 抽象组合类public abstract class Component &#123; String name; public Component(String name) &#123; this.name = name; &#125; public abstract void operation(int index); // 操作&#125; 实现叶子类,继承抽象组合类 1234567891011121314151617// 叶子public class Leaf extends Component&#123; public Leaf(String name) &#123; super(name); // TODO Auto-generated constructor stub &#125; @Override public void operation(int index) &#123; String str = &quot;&quot;; for (int i=0; i&lt;index; i++) &#123; str = str+ &quot; &quot;; &#125; System.out.println(str + name); &#125;&#125; 实现树枝类，继承抽象组合类 123456789101112131415161718192021222324252627282930public class Composite extends Component&#123; private LinkedList&lt;Component&gt; childer; public Composite(String name) &#123; super(name); this.childer = new LinkedList&lt;&gt;(); &#125; @Override public void operation(int index) &#123; String str = &quot;&quot;; for (int i=0; i&lt;index; i++) &#123; str = str+ &quot; &quot;; &#125; LinkedList&lt;Component&gt; list = this.getChilder(); System.out.println(str + name); for (Component c : list) &#123; c.operation(index+1); &#125; &#125; public void add(Component com) &#123; this.childer.add(com); &#125; public void remove(Component com) &#123; this.childer.remove(com); &#125; public LinkedList&lt;Component&gt; getChilder()&#123; return this.childer; &#125; &#125; main方法实现 123456789101112131415161718192021222324public static void main(String[] args) &#123; Composite root = new Composite(&quot;root&quot;); Composite branch = new Composite(&quot;branch&quot;); Composite branch1 = new Composite(&quot;branch1&quot;); Composite branch2 = new Composite(&quot;branch2&quot;); Composite branch3 = new Composite(&quot;branch3&quot;); branch.add(new Leaf(&quot;leaf1&quot;)); branch.add(new Leaf(&quot;leaf2&quot;)); branch1.add(new Leaf(&quot;leaf3&quot;)); branch2.add(new Leaf(&quot;leaf4&quot;)); branch1.add(branch2); branch2.add(new Leaf(&quot;leaf5&quot;)); branch2.add(new Leaf(&quot;leaf6&quot;)); branch3.add(new Leaf(&quot;leaf7&quot;)); branch3.add(new Leaf(&quot;leaf8&quot;)); branch2.add(branch3); root.add(branch); root.add(branch1); root.operation(0); &#125; 运行结果 12345678910111213root branch leaf1 leaf2 branch1 leaf3 branch2 leaf4 leaf5 leaf6 branch3 leaf7 leaf8 三、UML类图 四、笔记oo原则 封装变化 多用组合，少用继承 针对接口编程，不针对实现编程 为交互对象之间的松耦合设计而努力 类应该对扩展开放，对修改关闭 依赖抽象，不依赖具体类 只和朋友交谈 别找我，我会找你 类应该只有一个改变的理由 组合模式：允许你将对象组成树形结构来表现“整体／部分”的层次结构，组合能让客户以一致的方式处理个别对象和对象组合。 组合也可以和迭代器一起使用 github源码：https://github.com/gaoqisen/java-pattern]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式 - 状态模式]]></title>
    <url>%2Fpatterm%2Fstate.html</url>
    <content type="text"><![CDATA[之前学习的是组合模式和迭代器模式，迭代器模式已经实现了，但是组合模式，涉及到递归，没怎么理解透彻，因此准备最后攻克难关 一、对于状态模式的理解状态就像初中学习的物理一样（水），水是液态的、加热之后就变成了蒸汽就是雾态、结冰了就是固态。我们就可以描述水的不同状态。例如经常在公共场所会遇到自动售货机，没有用户投币的时候就可以理解为一种状态，投币之后是一种投币状态、用户选择产品就是一种选择状态、售货机从货架推出产品就是一种出售状态、产品卖空了就是一种售罄状态。如果我们只写一个类用if else去实现这种功能，就会有很多重复的代码。后期添加新的功能也特别不方便，需要改动的源代码也特别多。但是用状态模式去管理这些状态的话，后期添加新的功能，就会是一件很轻松的事情。而且对于后期的维护，也会大有裨益。状态模式就是将所有不同的状态都封装成类，最后通过一个展示的类去调用这些状态类，当然所有的状态类都实现了一个状态接口，方便利用多态在展示的类中去调用。最后实现，通过同一种调用方式，可以改变不同的状态。在不同的状态下，同一个方法，可以实现不同的业务逻辑。状态模式的定义：允许对象在内部状态改变时改变它的行为，对象看起来像是修改了它的类 二、代码实现创建状态接口，并创建通用的投币、退币、选择产品、出货等方法 1234567// 状态接口public interface State &#123; public void insertMoney(); // 投币 public void exitMoney(); // 退币 public void selectProduct(); // 选择产品 public void dispense(); // 发放产品&#125; 创建自动售货机类 123456public class AutoSales &#123; State soldOutState; State noMoneyState; State hasMoneyState; State soldState;&#125; 创建售罄类实现状态接口 1234567891011121314151617181920212223242526272829303132// 售謦状态public class SoldOutState implements State&#123; AutoSales autoSales; public SoldOutState() &#123; super(); &#125; public SoldOutState(AutoSales as) &#123; this.autoSales = as; &#125; @Override public void insertMoney() &#123; System.out.println(&quot;以售罄，请不要投币&quot;); this.autoSales.setState(this.autoSales.getSoldOutState()); // 将状态改为售罄 &#125; @Override public void exitMoney() &#123; System.out.println(&quot;以售罄，无法退币&quot;); &#125; @Override public void selectProduct() &#123; System.out.println(&quot;以售罄，无法选择产品&quot;); &#125; @Override public void dispense() &#123; System.out.println(&quot;以售罄，无法获得产品&quot;); &#125;&#125; 待投币状态实现状态接口 1234567891011121314151617181920212223242526272829303132// 没有投币的状态public class NoMoneyState implements State&#123; AutoSales as; public NoMoneyState() &#123; super(); &#125; public NoMoneyState(AutoSales as) &#123; this.as = as; &#125; @Override public void insertMoney() &#123; System.out.println(&quot;投币了&quot;); this.as.setState(this.as.getHasMoneyState()); // 将状态改为以投币 &#125; @Override public void exitMoney() &#123; System.out.println(&quot;没有投币，无法退币&quot;); &#125; @Override public void selectProduct() &#123; System.out.println(&quot;没有投币，无法选择产品&quot;); &#125; @Override public void dispense() &#123; System.out.println(&quot;没有投币，无法出货&quot;); &#125; &#125; 已投币状态也实现状态接口 123456789101112131415161718192021222324252627282930313233// 已投币public class HasMoneyState implements State&#123; AutoSales as; public HasMoneyState() &#123; super(); &#125; public HasMoneyState(AutoSales as) &#123; this.as = as; &#125; @Override public void insertMoney() &#123; System.out.println(&quot;又投币了&quot;); &#125; @Override public void exitMoney() &#123; System.out.println(&quot;开始退币了&quot;); this.as.setState(this.as.getNoMoneyState()); &#125; @Override public void selectProduct() &#123; System.out.println(&quot;选择产品&quot;); &#125; @Override public void dispense() &#123; System.out.println(&quot;发放产品&quot;); this.as.setState(this.as.getSoldState()); &#125; &#125; 已售出状态实现状态接口 1234567891011121314151617181920212223242526272829303132333435// 售出状态public class SoldState implements State&#123; AutoSales as; public SoldState(AutoSales as) &#123; this.as = as; &#125; @Override public void insertMoney() &#123; System.out.println(&quot;又投币了&quot;); &#125; @Override public void exitMoney() &#123; System.out.println(&quot;产品已售出,无法退币&quot;); &#125; @Override public void selectProduct() &#123; System.out.println(&quot;选择产品&quot;); &#125; @Override public void dispense() &#123; System.out.println(&quot;出货&quot;); if (this.as.getCount() &gt;0 ) &#123; this.as.setState(as.getNoMoneyState()); // 将状态变为没投币之前 &#125; else &#123; System.out.println(&quot;产品卖完了&quot;); this.as.setState(as.getSoldOutState()); // 将状态变为售罄 &#125; &#125;&#125; 完善自动售货机 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// 自动售货机public class AutoSales &#123; State soldOutState; State noMoneyState; State hasMoneyState; State soldState; State state = soldState; int count = 0; public AutoSales(int num) &#123; this.count = num; soldOutState = new SoldOutState(this); noMoneyState = new NoMoneyState(this); hasMoneyState = new HasMoneyState(this); soldState = new SoldState(this); if (num&gt;0) &#123; state = noMoneyState; &#125; &#125; // 投币 public void insertMoney()&#123; state.insertMoney(); &#125;; // 退币 public void exitMoney()&#123; this.state.exitMoney(); &#125;; // 选择产品 public void selectProduct()&#123; this.state.selectProduct(); &#125;; // 发放产品 public void dispense()&#123; this.state.dispense(); &#125;; public void setState(State state) &#123; this.state = state; &#125; public State getSoldOutState() &#123; return soldOutState; &#125; public State getNoMoneyState() &#123; return noMoneyState; &#125; public State getHasMoneyState() &#123; return hasMoneyState; &#125; public State getSoldState() &#123; return soldState; &#125; public State getState() &#123; return state; &#125; public int getCount() &#123; return count; &#125; @Override public String toString() &#123; return &quot;AutoSales [售罄=&quot; + soldOutState.getClass() + &quot;, 待投币=&quot; + noMoneyState.getClass() + &quot;, 已投币=&quot; + hasMoneyState.getClass() + &quot;, 出售=&quot; + soldState.getClass() + &quot;, state状态=&quot; + state.getClass() + &quot;, count=&quot; + count + &quot;]&quot;; &#125;&#125; main方法运行 1234567891011121314151617181920public static void main(String args[]) &#123; // 给自动售货机装5个产品 AutoSales as = new AutoSales(5); System.out.println(&quot;--当前状态：&quot; +as.getState().getClass()); as.insertMoney(); System.out.println(&quot;--当前状态：&quot; +as.getState().getClass()); as.selectProduct(); as.dispense(); System.out.println(&quot;--当前状态：&quot; +as.getState().getClass()); as.exitMoney(); System.out.println(&quot;--当前状态：&quot; +as.getState().getClass()); as.insertMoney(); as.selectProduct(); as.insertMoney(); as.selectProduct(); as.dispense(); System.out.println(&quot;--当前状态：&quot; +as.getState().getClass()); &#125; 运行结果 1234567891011121314--当前状态：class study.state.NoMoneyState投币了--当前状态：class study.state.HasMoneyState选择产品发放产品--当前状态：class study.state.SoldState产品已售出,无法退币--当前状态：class study.state.SoldState又投币了选择产品又投币了选择产品出货--当前状态：class study.state.NoMoneyState 三、UML类图 四、笔记oo原则 封装变化 多用组合、少用继承 针对接口编程，不针对实现编程 对修改关闭，对增加开放 你不要来找我，我来找你 为交互之间的松耦合设计而努力 依赖抽象，不依赖具体类 只和朋友交谈 类应该只有一个被改变的理由 状态模式定义： 允许对象在内部状态改变时改变它的行为，对象看起来好像修改了它的类。 github源码：https://github.com/gaoqisen/java-pattern]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－单例模式]]></title>
    <url>%2Fpatterm%2Fsingle.html</url>
    <content type="text"><![CDATA[之前学习是简单工厂模式、工厂方法模式、抽象工厂模式，复习一下 简单工厂模式简单工厂模式大概就是创建一个简单工厂类，由工厂类实例化对象。由参数决定实例化那个类 工厂方法模式创建一个抽象工厂类，里面包含一个抽象方法。由这个工厂去生产产品，具体的就是实现类实现工厂，并完成抽象方法的功能实现（如月饼抽象生产类，南方月饼类实现月饼抽象生产类，北方月饼实现月饼抽象生产类，等等）。调用不是由参数决定，是由创建者决定 抽象工厂模式创建抽象工厂类生产工厂，创建抽象产品类生产产品，并各自实现。形成产品族（一个大的家族）对于之前的理解模糊可以看这个：https://www.zhihu.com/question/20367734 一、 对单例模式的理解单例模式就像太阳一样，只有一个。在使用的时候，只能实例化一次。不能多次实例化。二、代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 单例模式 太阳（synchronized，重量级）public class sun &#123; private static sun s = null; private sun() &#123;&#125; // 单例模式 这种方式多线程时会出现混乱的情况，不建议使用 public static sun getSun() &#123; if (s == null) &#123; s = new sun(); &#125; return s; &#125; // (同步方法)添加同步锁，在不考虑性能的时候可以使用该方法 public static synchronized sun getSunSyn() &#123; if (s == null) &#123; s = new sun(); &#125; return s; &#125;&#125;// 月亮（双重检查加锁）class moon &#123; // volatile 当moon初始化为实例时，能保证多个线程正确的处理moon变量 private volatile static moon m; private moon() &#123;&#125;; // 减少synchronized的使用 public static moon getMoon() &#123; if (m == null) &#123; synchronized (moon.class) &#123; if (m == null) &#123; m = new moon(); &#125; &#125; &#125; return m; &#125;&#125;// 地球（急切）class earth&#123; // 在静态初始化器中创建单件，这段代码保证了线程安全 private static earth e = new earth(); private earth()&#123;&#125;; // 在jvm 加载这个类的时候创建此唯一的单例模式。 public static earth getEarth() &#123; return e; &#125;&#125; 三、UML类图 四、笔记oo设计原则 封装变化 多用组合、少用继承 针对接口编程、不针对实现编程 为对象之间的松耦合设计而努力 类应该对扩展开发、修改关闭 依赖抽象、不要依赖具体类单例模式定义：确保一个类只有一个实例，并提供全局访问点 github源码：https://github.com/gaoqisen/java-pattern]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－命令模式]]></title>
    <url>%2Fpatterm%2Fcommand.html</url>
    <content type="text"><![CDATA[之前学习的是单例模式。单例模式就是只有一个对象被实例化，如注册表等。单例模式有几种实现方式一是用同步锁创建一个私有的构造器，和一个同步的公开的方法。这种方式简便，但是性能不是很好，使用的是同步锁（重量级的）。二是创建一个静态产量直接new一个对象。也是有私有的构造器不让对象创建。通过公开的方法返回静态常量new的对象，保证对象只有一个。这种方法在jvm创建的时候就会产生对象，如果不使用该对象，则会产生浪费三是用volatile创建静态属性。用私有构造器不让对象创建，通过公开的get方法获取对象，获取的时候判断对象是否存在，如果不存在则用同步锁防止多线程出现错误。最后返回对象。这种是常用的方法。 一、对于命令模式的理解一个命令执行一个操作。每个命令都是一个操作。不用去关心对象是怎么做的，只需要发送命令即可。就像传菜员一样。 二、 代码实现创建一个命令接口 12345// 命令接口public interface Command &#123; public void execute(); // 执行 public void undo(); // 撤销&#125; 在创建一个电视 123456789// 电视public class TV &#123; public void on() &#123; System.out.println(&quot;开电视&quot;); &#125; public void off() &#123; System.out.println(&quot;关电视&quot;); &#125;&#125; 创建一个开电视命令 123456789101112131415161718// 开电视public class TVOnCommand implements Command&#123; TV tv; public TVOnCommand(TV tv) &#123; this.tv = tv; &#125; @Override public void execute() &#123; tv.on(); &#125; @Override public void undo() &#123; System.out.println(&quot;开电视撤销准备。。。&quot;); tv.off(); &#125;&#125; 创建一个关电视命令 1234567891011121314151617public class TVOffCommand implements Command&#123; TV tv; public TVOffCommand(TV tv) &#123; this.tv = tv; &#125; @Override public void execute() &#123; tv.off(); &#125; @Override public void undo() &#123; System.out.println(&quot;关电视撤销准备。。。&quot;); tv.on(); &#125;&#125; 创建一个简单的远程控制器（遥控器） 1234567891011121314151617// 简单远程控制public class SimpleRemoteController &#123; Command command; Command undoCommand; public SimpleRemoteController()&#123;&#125;; // 利用有参构造器初始化命令 public void setCommand(Command command) &#123; this.command = command; &#125; public void start() &#123; command.execute(); this.undoCommand = this.command; &#125; public void undo() &#123; this.undoCommand.undo(); &#125;&#125; main方法实现 123456789101112131415public static void main(String args[]) &#123; // 创建远程控制器 SimpleRemoteController simpleRemoteController = new SimpleRemoteController(); TV tv = new TV(); // 创建电视 TVOnCommand tvon = new TVOnCommand(tv); // 创建关电视命令 simpleRemoteController.setCommand(tvon); // 通过远程控制器设置关电视的命令 simpleRemoteController.start(); // 按开始按钮 simpleRemoteController.undo(); TVOffCommand tvoff = new TVOffCommand(tv); // 创建关电视命令 simpleRemoteController.setCommand(tvoff); // 通过远程控制器设置关电视的命令 simpleRemoteController.start(); // 按开始按钮 simpleRemoteController.undo();&#125; 运行结果 123456开电视开电视撤销准备。。。关电视关电视关电视撤销准备。。。开电视 实现宏命令（实现一组命令）创建宏命令 123456789101112131415161718192021// 宏命令public class MacroCommand implements Command&#123; Command[] commands; public MacroCommand(Command[] command)&#123; this.commands = command; &#125; @Override public void execute() &#123; for(Command c : this.commands )&#123; c.execute(); &#125; &#125; @Override public void undo() &#123; for(Command c : this.commands )&#123; c.undo(); &#125; &#125;&#125; 创建宏的远程控制 12345678910111213141516171819// 遥控器public class RemoteController &#123; Command[] onCommands; Command[] offCommands; public RemoteController () &#123; this.onCommands = new Command[2]; this.offCommands = new Command[2]; &#125; public void setCommand(int index, Command on,Command off) &#123; this.onCommands[index] = on; this.offCommands[index] = off; &#125; public void on(int index) &#123; this.onCommands[index].execute(); &#125; public void off(int index) &#123; this.offCommands[index].execute(); &#125;&#125; 创建一个电脑操作类 12345678public class Computer &#123; public void on() &#123; System.out.println(&quot;开电脑&quot;); &#125; public void off() &#123; System.out.println(&quot;关电脑&quot;); &#125;&#125; 关电脑命令 1234567891011121314151617public class ComputerOffCommand implements Command&#123; Computer computer; public ComputerOffCommand(Computer com) &#123; this.computer = com; &#125; @Override public void execute() &#123; this.computer.off(); &#125; @Override public void undo() &#123; System.out.println(&quot;关电脑撤销准备。。。&quot;); this.computer.on(); &#125;&#125; 开电脑命令 1234567891011121314151617public class ComputerOnCommand implements Command&#123; Computer computer; public ComputerOnCommand(Computer computer) &#123; this.computer = computer; &#125; @Override public void execute() &#123; this.computer.on(); &#125; @Override public void undo() &#123; System.out.println(&quot;开电脑撤销准备。。。&quot;); this.computer.off(); &#125;&#125; main方法运行 1234567891011121314Computer computer = new Computer();RemoteController remoteController = new RemoteController();ComputerOffCommand coffc = new ComputerOffCommand(computer);ComputerOnCommand conc = new ComputerOnCommand(computer);// 实现宏命令Command[] on = &#123;tvon, conc&#125;;Command[] off = &#123;tvoff,coffc&#125;;MacroCommand onmc = new MacroCommand(on);MacroCommand offmc = new MacroCommand(off);remoteController.setCommand(0, onmc, offmc);System.out.println(&quot;宏命令结束&quot;);remoteController.on(0);System.out.println(&quot;单独执行&quot;);remoteController.off(0); 运行结果 123456宏命令结束开电视开电脑单独执行关电视关电脑 三、UML类图 四、笔记 封装变化 多用组合少用继承 针对接口编程，不针对实现编程 为交互对象之间的松耦合设计而努力 对扩展开放、对修改关闭 依赖抽象，不依赖具体类 命令模式定义： 将请求封装成对象，这可以让你使用不同的请求、队列，或者日志请求来参数化其它对象。命令模式也可以支持撤销操作。 github源码：https://github.com/gaoqisen/java-pattern]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－模版方法模式]]></title>
    <url>%2Fpatterm%2Ftemplate.html</url>
    <content type="text"><![CDATA[之前学习的是适配器模式与外观模式。 对外观模式与适配器模式的理解适配器模式的意思就是适配，将三孔插座转换为二孔插座的转换头。通过适配器可以将两个不一样的接口（有共同点）适配在一起。外观模式就是统一接口，将很多方法，统一在一个类里面实现。让使用者不会感觉方法太多杂乱。就像一个开关控制所有电器，和每个电器单独使用的一样。如果使用一个开关控制所有，就会特别方便。但是之前的开关也存在，如果需要单独使用，也是可以的。 先看下定义 模版方法：在一个方法中定义一个算法的骨架，而将一些步骤延伸到子类中。模版方法使得子类可以在不改变算法结构的情况下，重新定义算法中的某些步骤 一、 对模版方法的理解模版方法就是将重复的方法封装在一个类中，变动的方法就用抽象方法抽象出来。将方法模版化，其它子类使用的时候，公用的方法就不用再次实现类，只需要实现抽象方法。大大的降低类代码的重复。比较好玩的就是钩子方法，可以通过子类控制父类的通用方法，很方便。 二、 代码实现创建烹饪抽象类123456789101112131415161718192021222324252627282930public abstract class Cooking &#123; // 准备烹饪 public void prepareCooking() &#123; WashingVegetables(); addVegetables(); addSalt(); // 根据菜的样式判断是否加辣椒 if (isChiliHooks()) &#123; addChili(); &#125; &#125; // 洗菜 public void WashingVegetables() &#123; System.out.println(&quot;洗菜&quot;); &#125; // 加盐 public void addSalt()&#123; System.out.println(&quot;加盐&quot;); &#125; // 加辣椒 public void addChili() &#123; System.out.println(&quot;加辣椒&quot;); &#125; // 是否加辣椒钩子 public boolean isChiliHooks() &#123; return true; &#125; // 放菜进锅炒，根据不同的实现，炒不同的菜 abstract void addVegetables();&#125; 创建大白菜类，大白菜重构类模版方法的抽象方法，放入类大白菜123456789// 大白菜public class ChineseCabbage extends Cooking&#123; @Override void addVegetables() &#123; System.out.println(&quot;放入大白菜&quot;); &#125;&#125; 创建生菜类，也实现类抽象方法。最后重写类父类的钩子，实现类不加辣椒 123456789101112// 炒生菜public class lettuce extends Cooking&#123; @Override void addVegetables() &#123; System.out.println(&quot;放入生菜&quot;); &#125; // 不放辣椒 public boolean isChiliHooks() &#123; return false; &#125;&#125; main方法实现 1234567public static void main(String agrs[]) &#123; ChineseCabbage cc = new ChineseCabbage(); cc.prepareCooking(); System.out.println(&quot;+++++++++&quot;); lettuce lt = new lettuce(); lt.prepareCooking(); &#125; 运行结果 12345678洗菜放入大白菜加盐加辣椒+++++++++洗菜放入生菜加盐 三、UML类图 四、笔记 封装变化 多用组合、少用继承 面向接口编程、不面向实现编程 只和朋友交谈 对修改关闭、对扩展开放 为交互对象之间的松耦合设计而努力 别找我、我会找你（好莱坞原则） 依赖抽象、不要依赖具体类 巩固模版方法定义: 在一个方法中定义一个算法的骨架，而将一些步骤延伸到子类中。模版方法使得子类可以在不改变算法结构的情况下，重新定义算法中的某些步骤 github源码：https://github.com/gaoqisen/java-pattern]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－适配器与外观模式]]></title>
    <url>%2Fpatterm%2Ffacade.html</url>
    <content type="text"><![CDATA[之前学习的是命令模式 对于命令模式的理解命令模式就是将操作封装为一个类（一个命令）。在通过一个控制器把命令封装进去，就像一个遥控器，最后通过不同的命令就可以实现不同的操作 一、 对适配器模式和观察者模式的理解适配器模式就是改变一个接口，实现不同的操作。就像插座转换头一样，将三孔插座转换为二孔插座。外观模式字面上就是好的形象的意识。将一些操作集合在一起，统一调用，简单又方便。就像家里面的插头到处都是。我们可以把所有的插头都插在一个大插板上面。每次使用的时候，就可以只用开、关大插板就可以。不用每次都插很多插头。 二、代码实现适配器模式三孔插座1234567891011// 三孔插座public interface SocketThree &#123; public void chargeThree();&#125;class SocketThreeImpl implements SocketThree&#123; @Override public void chargeThree() &#123; System.out.println(&quot;三孔插座&quot;); &#125;&#125; 两孔插座123456789101112// 两孔插座public interface SocketTwo &#123; public void chargeTwo();&#125;class SocketTwoImpl implements SocketTwo&#123; @Override public void chargeTwo() &#123; System.out.println(&quot;两孔插座&quot;); &#125; &#125; 插座适配器123456789101112// 插座适配器 将三孔插座转换为二孔插座， 看着像二孔，但是实际上还是三孔public class SocketAdapter implements SocketTwo&#123; SocketThree socketThree; public SocketAdapter(SocketThree socketThree) &#123; this.socketThree = socketThree; &#125; @Override public void chargeTwo() &#123; System.out.println(&quot;转换后的两孔插座&quot;); this.socketThree.chargeThree(); &#125;&#125; main方法运行 123456// 适配器模式 SocketThree st = new SocketThreeImpl(); st.chargeThree(); // 通过转换器将三孔插座转换为两孔插座 SocketTwo stwo = new SocketAdapter(st); stwo.chargeTwo(); 运行结果123三孔插座转换后的两孔插座三孔插座 外观模式新建电视、电灯、烤火炉类12345678910111213141516171819202122232425public class TV &#123; public void on() &#123; System.out.println(&quot;开电视&quot;); &#125; public void off() &#123; System.out.println(&quot;关电视&quot;); &#125;&#125;class Light&#123; public void on() &#123; System.out.println(&quot;开电灯&quot;); &#125; public void off() &#123; System.out.println(&quot;关电灯&quot;); &#125;&#125;class Stove&#123; public void on() &#123; System.out.println(&quot;开火炉&quot;); &#125; public void off() &#123; System.out.println(&quot;关火炉&quot;); &#125;&#125; 大插板（不让插头凌乱，外观好看）12345678910111213141516171819202122// 买了一个大插板，将电视、烤火炉、电灯的插头都插在这个大插板上面public class FacadeSocket &#123; TV tv; Light light; Stove stove; public FacadeSocket(TV tv,Light light,Stove stove) &#123; this.tv = tv; this.light = light; this.stove = stove; &#125; // 通过外观模式统一处理 public void on() &#123; this.tv.on(); this.light.on(); this.stove.on(); &#125; public void off() &#123; this.tv.off(); this.light.off(); this.stove.off(); &#125;&#125; main方法实现12345678910public static void main(String srgs[])&#123; // 外观模式 TV tv = new TV(); Light light = new Light(); Stove stove = new Stove(); // 创建大插板， 统一开关 FacadeSocket fs = new FacadeSocket(tv, light,stove); fs.on(); fs.off();&#125; 运行结果123456开电视开电灯开火炉关电视关电灯关火炉 三、UML类图 四、笔记oo设计原则 封装变化 依赖接口编程，不依赖实现编程 为交互对象之间的松耦合设计而努力 对修改关闭、对扩展开放 多用组合，少用继承 依赖抽象、不依赖具体类 只和朋友交谈 适配器模式定义： 将一个类的接口，转移成为可以期望的另一个接口。适配器让原本不兼容的两个类可以合作无间 外观模式定义： 提供类一个统一的接口，用来访问子系统中的一群接口。外观定义类一个高层接口，让子系统更容易使用。 github源码：https://github.com/gaoqisen/java-pattern]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－迭代器模式]]></title>
    <url>%2Fpatterm%2Fiterator.html</url>
    <content type="text"><![CDATA[昨天学习的是模版方法模式复习一下 对于模版方法的理解：模版方法模式就是创建一个模版类，并创建一个抽象方法，和调用方法。该方法（一般是静态方法，不能修改的）调用复用的模版类方法（实现通用的业务逻辑）和抽象方法。子类继承模版类之后，重写抽象方法（不同的业务逻辑）。模版类中可以设置钩子方法，用于控制模版类的通用方法是否调用。这样做的好处就是可以子类可以调用很多通用的方法，减少大量的重复代码。抽象方法也可以实现子类独有的方法。钩子还可以控制通用方法。使方法调用更加的灵活。模版方法就是为类的方法创建特别灵活的模版。 一、对于迭代器的理解通过看书之后，我觉得迭代器就是一个可以遍历所有不同集合类型对象的的一种方式。如用ArrayList, new [], HashMap等集合存储对象数据。如果要遍历就需要写三个for循环才可以完成遍历。但是有迭代器之后，就可以用一个迭代器完成三种不同类型的集合的遍历。总结出来就是：迭代器可以遍历所有实现了迭代器接口的不同类型的集合 二、代码实现实现思路：创建一个宠物类，有动物的名字、年龄、简介等。动物生病了就会找医生。每个医生都有自己的笼子，张医生的笼子使用ArrayList制作的。李医生的笼子使用Animal[]制作的。两个医生都在同一个宠物店里面上班。医生太忙了，领导来医院视察的时候，需要服务员小花去给领导报告两位医生的宠物都叫什么名字，年龄多少、宠物具体的情况等。如果没有迭代器，小花就需要拿张医生的ArrayList笼子的钥匙去看，李医生的钥匙和张医生的钥匙又不一样，每次都要拿不同的钥匙看不同的笼子，特别麻烦。而且还要去每个医生的工作区域才可以。但是有了迭代器，小花就不用拿这个多钥匙了，只要一种钥匙，而且不用去两个工作区域查看，就感觉像迭代器将宠物汇总了。小花只要拿一种钥匙，不用知道医生使用什么笼子关宠物的，只需要在一个地方查看在记录好报告领导就可以了。下面看代码。 1、 自己创建一个迭代器实现创建一个动物类 1234567891011121314151617181920// 动物类public class Animal &#123; String name; int age; String description; public Animal(String name, int age, String des) &#123; this.name = name; this.age = age; this.description = des; &#125; public String getName() &#123; return name; &#125; public int getAge() &#123; return age; &#125; public String getDescription() &#123; return description; &#125;&#125; 创建张医生和李医生，用不同的笼子关动物 123456789101112131415161718192021222324252627282930313233343536373839404142// 张医生用ArrayList笼子关动物public class DoctorZhang &#123; ArrayList ans; public DoctorZhang() &#123; ans = new ArrayList(); addAnimal("小狗",8, "黄色的小狗"); addAnimal("小猫",4, "黑色的小猫"); addAnimal("小猪",4, "白色的小猪"); &#125; // 增加动物方法 public void addAnimal(String name, int age, String des)&#123; Animal an = new Animal(name, age, des); this.ans.add(an); &#125; public Iterator createIterator() &#123; return new DoctorZhangIterator(this.ans); &#125;&#125;// 李医生用［］笼子关动物class DoctorLi&#123; static final int MAX=5; int number = 0; Animal[] animal; public DoctorLi() &#123; animal =new Animal[MAX]; addAnimal("小乌龟",8, "黄色的小乌龟"); addAnimal("小猴",4, "黑色的小猴"); addAnimal("大猪",4, "黄色的大猪"); &#125; // 增加动物方法 public void addAnimal(String name, int age, String des)&#123; if (number&gt;=MAX)&#123; return; &#125; Animal an = new Animal(name, age, des); this.animal[number] = an; this.number++; &#125; public Iterator createIterator() &#123; return new DoctorLiIterator(this.animal); &#125;&#125; 创建一个迭代器，并用张医生李医生去实现迭代器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// 迭代器接口public interface Iterator &#123; boolean hasNext(); Object next();&#125;// 李医生迭代器实现迭代器接口class DoctorZhangIterator implements Iterator&#123; ArrayList ans; int index = 0; public DoctorZhangIterator(ArrayList ans) &#123; this.ans = ans; &#125; @Override public boolean hasNext() &#123; if (index &gt;= ans.size() || ans.get(index) == null) &#123; return false; &#125; else &#123; return true; &#125; &#125; @Override public Object next() &#123; Animal animal = (Animal) ans.get(index); index ++; return animal; &#125; &#125;//张医生迭代器实现迭代器接口class DoctorLiIterator implements Iterator&#123; Animal[] animal; int index = 0; public DoctorLiIterator(Animal[] animal) &#123; this.animal = animal; &#125; @Override public boolean hasNext() &#123; if (index &gt;= animal.length || animal[index] == null) &#123; return false; &#125; else &#123; return true; &#125; &#125; @Override public Object next() &#123; Animal an = animal[index]; index ++; return an; &#125; &#125; 创建一个宠物店类 12345678910111213141516171819202122232425// 宠物店public class PetShop &#123; DoctorZhang zhang; DoctorLi li; public PetShop(DoctorZhang zhang,DoctorLi li) &#123; this.zhang = zhang; this.li = li; &#125; // 小花就用这个方法统计宠物 public void printAnimal() &#123; Iterator it = zhang.createIterator(); Iterator its = li.createIterator(); System.out.println("张医生的宠物"); printAnimal(it); System.out.println("李医生的宠物"); printAnimal(its); &#125; private void printAnimal(Iterator it) &#123; while(it.hasNext()) &#123; Animal an = (Animal)it.next(); System.out.println("名字为："+an.getName()+" 年龄为："+an.getAge() + " 介绍："+an.getDescription()); &#125; &#125;&#125; main方法实现－－ 领导来视察了，小花就去统计 123456public static void main(String args[]) &#123; DoctorZhang zhang =new DoctorZhang(); DoctorLi li = new DoctorLi(); PetShop ps =new PetShop(zhang, li); ps.printAnimal();&#125; 运行结果 12345678张医生的宠物名字为：小狗 年龄为：8 介绍：黄色的小狗名字为：小猫 年龄为：4 介绍：黑色的小猫名字为：小猪 年龄为：4 介绍：白色的小猪李医生的宠物名字为：小乌龟 年龄为：8 介绍：黄色的小乌龟名字为：小猴 年龄为：4 介绍：黑色的小猴名字为：大猪 年龄为：4 介绍：黄色的大猪 2、用上面的代码重构为java util 类里面的迭代器实现动物类不变动，改动两个医生的代码迭代器为。注意迭代器换为了import java.util.Iterator; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 张医生实现java util里面的迭代器public class DoctorZhangIteratorJavaUtil implements Iterator&#123; Animal[] ans; int index = 0; public DoctorZhangIteratorJavaUtil(Animal[] ans) &#123; this.ans = ans; &#125; @Override public boolean hasNext() &#123; if (index &gt;= ans.length || ans[index] == null) &#123; return false; &#125; else &#123; return true; &#125; &#125; @Override public Object next() &#123; Animal animal = (Animal) ans[index]; index ++; return animal; &#125; public void remove() &#123; if (index &lt;=0) &#123; throw new IllegalStateException("没有可以删除的了"); &#125; if(ans[index-1] !=null) &#123; for(int i = index-1; i&lt;(ans.length -1); i++) &#123; ans[i] = ans[i+1]; &#125; ans[ans.length - 1] = null; &#125; &#125;&#125;class DoctorLiIteratorJavaUtil implements Iterator&#123; ArrayList ans; int index = 0; public DoctorLiIteratorJavaUtil(ArrayList ans) &#123; this.ans = ans; &#125; @Override public boolean hasNext() &#123; if (index &gt;= ans.size() || ans.get(index) == null) &#123; return false; &#125; else &#123; return true; &#125; &#125; @Override public Object next() &#123; Animal animal = (Animal) ans.get(index); index ++; return animal; &#125;&#125; 改动两个医生的代码为。注意迭代器换为了import java.util.Iterator; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// 张医生用ArrayList区分动物public class DoctorLiJavaUtil implements Doctor&#123; ArrayList ans; public DoctorLiJavaUtil() &#123; ans = new ArrayList(); addAnimal("小狗",8, "黄色的小狗"); addAnimal("小猫",4, "黑色的小猫"); addAnimal("小猪",4, "白色的小猪"); &#125; // 增加动物方法 public void addAnimal(String name, int age, String des)&#123; Animal an = new Animal(name, age, des); this.ans.add(an); &#125; public Iterator createIterator() &#123; // 直接使用ArrayList的迭代器 return this.ans.iterator(); &#125;&#125;// 李医生用［］区分动物class DoctorZhangJavaUtil implements Doctor&#123; static final int MAX=5; int number = 0; Animal[] animal; public DoctorZhangJavaUtil() &#123; animal =new Animal[MAX]; addAnimal("小乌龟",8, "黄色的小乌龟"); addAnimal("小猴",4, "黑色的小猴"); addAnimal("大猪",4, "黄色的大猪"); &#125; // 增加动物方法 public void addAnimal(String name, int age, String des)&#123; if (number&gt;=MAX)&#123; return; &#125; Animal an = new Animal(name, age, des); this.animal[number] = an; this.number++; &#125; public Iterator createIterator() &#123; return new DoctorZhangIteratorJavaUtil(this.animal); &#125;&#125;// 新增的医生接口interface Doctor &#123; public Iterator createIterator();&#125; 更改宠物店的代码 123456789101112131415161718192021222324252627 // 宠物店 import java.util.Iterator; public class PetShopJavaUtil &#123; Doctor zhang; Doctor li; public PetShopJavaUtil(Doctor zhang,Doctor li) &#123; this.zhang = zhang; this.li = li; &#125; public void printAnimal() &#123; Iterator it = zhang.createIterator(); Iterator its = li.createIterator(); System.out.println("张医生的宠物"); printAnimal(it); System.out.println("李医生的宠物"); printAnimal(its); &#125; private void printAnimal(Iterator it) &#123; if (it == null) &#123; return; &#125; while(it.hasNext()) &#123; Animal an = (Animal)it.next(); System.out.println("名字为："+an.getName()+" 年龄为："+an.getAge() + " 介绍："+an.getDescription()); &#125; &#125;&#125; main方法运行 123456789public static void main(String args[]) &#123; // java.util 迭代器使用 System.out.println("++++++++++++++++java.util 迭代器 "); DoctorZhangJavaUtil zhangJavaUtil =new DoctorZhangJavaUtil(); DoctorLiJavaUtil liJavaUtil = new DoctorLiJavaUtil(); PetShopJavaUtil psJavaUtil =new PetShopJavaUtil(zhangJavaUtil, liJavaUtil); psJavaUtil.printAnimal(); &#125; 运行结果 123456789++++++++++++++++java.util 迭代器 张医生的宠物名字为：小乌龟 年龄为：8 介绍：黄色的小乌龟名字为：小猴 年龄为：4 介绍：黑色的小猴名字为：大猪 年龄为：4 介绍：黄色的大猪李医生的宠物名字为：小狗 年龄为：8 介绍：黄色的小狗名字为：小猫 年龄为：4 介绍：黑色的小猫名字为：小猪 年龄为：4 介绍：白色的小猪 三、UML类图 四、笔记 封装变化 多用组合,少用继承 面向接口编程，不面向实现编程 为交互对象之间的松耦合设计而努力 对扩展开放，对修改关闭 只跟朋友交谈 依赖抽象不要依赖具体类 别找我，我会找你 类应该只有一个被改变的理由 迭代器模式定义： 提供一种方法顺序访问一个聚合对象中的各个元素，而又不暴其露内部的表示 github源码：https://github.com/gaoqisen/java-pattern]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－工厂模式]]></title>
    <url>%2Fpatterm%2Ffactory.html</url>
    <content type="text"><![CDATA[之前学的是装饰者模式 装饰者模式的优点动态地为对象增加新的功能或者撤销功能（继承就不能做到这一点） 装饰者模式的缺点会产生过多的相似的对象！ 一、对工厂模式的理解简单工厂：通过工厂类生成不同的类。工厂类返回一个父类型的类，通过if或者switch判断用户给的数据，通过不同的数据返回不同的类。工厂方法：比较重要的就是抽象类里面的一个抽象方法，所有继承了抽象类的类都必须实现该方法，之后在调用的时候利用多态动态的调用实现类的方法。抽象的方法里面就可以用简单工厂模式实现不同的类 二、代码实现(简单工厂、工厂方法、抽象工厂)1、简单工厂 创建月饼类123456789101112131415161718192021public class MoonCake &#123; public String name; public void kenad() &#123; System.out.println("揉面粉"); &#125; public String getName() &#123; return name; &#125;&#125;// 糖陷月饼class sugar extends MoonCake&#123; public sugar()&#123; System.out.println("糖陷"); &#125;&#125;// 肉陷月饼class meat extends MoonCake &#123; public meat() &#123; System.out.println("肉馅"); &#125;&#125; 创建简单月饼工厂1234567891011public class SimpleFactory &#123; public MoonCake createProduct(String type) &#123; MoonCake product = null; if (type.equals(&quot;meat&quot;))&#123; product = new meat(); &#125; else if (type.equals(&quot;sugar&quot;)) &#123; product = new sugar(); &#125; return product; &#125;&#125; 创建月饼工厂12345678910public class MoonCakeFactory &#123; SimpleFactory factory; public MoonCakeFactory(SimpleFactory factory) &#123; this.factory = factory; &#125; public MoonCake orderMoonCake(String type) &#123; MoonCake product = factory.createProduct(type); return product; &#125;&#125; main方法实现1234567public class run &#123; public static void main(String args[]) &#123; // 简单工厂模式 生产月饼 SimpleFactory simpleFactory = new SimpleFactory(); new MoonCakeFactory(simpleFactory).orderMoonCake(&quot;meat&quot;); &#125;&#125; 运行结果1肉馅 2、工厂方法月饼店抽象类1234567891011// 月饼店public abstract class MoonCakeStore &#123; public MoonCake orderMoonCake(String type) &#123; MoonCake mc; mc = createMoonCake(type); mc.kenad(); return mc; &#125; // 抽象的工厂方法 public abstract MoonCake createMoonCake(String type);&#125; 北方月饼店和南方月饼店123456789101112131415161718192021222324252627// 北方月饼店public class NorthMoonCakeStore extends MoonCakeStore&#123; @Override public MoonCake createMoonCake(String type) &#123; if (type.equals(&quot;meat&quot;)) &#123; return new NorthSytleMeatMoonCake(); &#125; else if (type.equals(&quot;sugar&quot;)) &#123; return new NorthSytleSugarMoonCake(); &#125; return null; &#125;&#125;// 南方月饼店public class SouthMoonCakeStroe extends MoonCakeStore&#123; @Override public MoonCake createMoonCake(String type) &#123; if (type.equals(&quot;meat&quot;)) &#123; return new SouthSytleMeatMoonCake(); &#125; else if (type.equals(&quot;sugar&quot;)) &#123; return new SouthSytleSugarMoonCake(); &#125; return null; &#125;&#125; 月饼父类123456789public class MoonCake &#123; public String name; public void kenad() &#123; System.out.println(&quot;揉面粉&quot;); &#125; public String getName() &#123; return name; &#125;&#125; 北方月饼和南方月饼12345678910class SouthSytleMeatMoonCake extends MoonCake&#123; public SouthSytleMeatMoonCake() &#123; name =&quot;南方风格的肉馅月饼&quot;; &#125;&#125;class SouthSytleSugarMoonCake extends MoonCake&#123; public SouthSytleSugarMoonCake() &#123; name = &quot;南方风格的糖陷月饼&quot;; &#125;&#125; main方法实现12345678910111213public class run &#123; public static void main(String args[]) &#123; // 工厂方法模式 生产月饼 MoonCakeStore mcs = new SouthMoonCakeStroe(); MoonCakeStore smcs = new NorthMoonCakeStore(); MoonCake mc = mcs.orderMoonCake(&quot;meat&quot;); System.out.println(mc.getName()); MoonCake mc1 = smcs.orderMoonCake(&quot;meat&quot;); System.out.println(mc1.getName()); &#125;&#125; 运行结果1234揉面粉南方风格的肉馅月饼揉面粉北方风格的肉馅月饼 3.抽象工厂 创建一个抽象月饼类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// 面粉基类class flour &#123; &#125;// 芝麻基类class sesame&#123; &#125;// 重构之前的抽象月饼类public abstract class MoonCake1 &#123; String name; flour flour; sesame sesame; public void kenad() &#123; System.out.println(&quot;揉面粉&quot;); &#125; public String getName() &#123; return name; &#125; // 准备 abstract void prepare();&#125;//糖陷月饼class sugar1 extends MoonCake1&#123; MaterailFactory materailFactory; public sugar1()&#123; System.out.println(&quot;糖陷&quot;); &#125; public sugar1(MaterailFactory materailFactory) &#123; name = &quot;糖陷月饼&quot;; this.materailFactory = materailFactory; &#125; @Override void prepare() &#123; System.out.println(&quot;准备制作月饼了&quot;); flour = this.materailFactory.createFlour(); sesame = this.materailFactory.createSesame(); &#125;&#125;//肉陷月饼class meat1 extends MoonCake1 &#123; MaterailFactory materailFactory; public meat1() &#123; System.out.println(&quot;肉馅&quot;); &#125; public meat1(MaterailFactory materail) &#123; this.materailFactory = materail; &#125; @Override void prepare() &#123; flour = this.materailFactory.createFlour(); sesame = this.materailFactory.createSesame(); &#125;&#125; 抽象月饼店123456789101112// 月饼店抽象类 public abstract class MoonCakeStore1 &#123; public MoonCake1 orderMoonCake(String type) &#123; MoonCake1 mc; mc = createMoonCake(type); mc.kenad(); mc.prepare(); return mc; &#125; // 抽象的工厂方法 public abstract MoonCake1 createMoonCake(String type);&#125; 材料接口12345// 材料工厂接口public interface MaterailFactory &#123; public flour createFlour(); public sesame createSesame();&#125; 南方材料工厂实现材料接口12345678910111213141516171819202122232425// 南方材料工厂public class SouthMaterailFactory implements MaterailFactory&#123; @Override public flour createFlour() &#123; return new SouthFlour(); &#125; @Override public sesame createSesame() &#123; return new SouthSesame(); &#125;&#125;// 南方面粉class SouthFlour extends flour&#123; public SouthFlour() &#123; System.out.println(&quot;南方的独特制作的面粉&quot;); &#125;&#125;// 南方芝麻class SouthSesame extends sesame&#123; public SouthSesame() &#123; System.out.println(&quot;南方的独特制作的芝麻&quot;); &#125;&#125; 南方月饼店继承抽象月饼店1234567891011121314// 南方月饼店public class SouthMoonCakeStroe1 extends MoonCakeStore1&#123; @Override public MoonCake1 createMoonCake(String type) &#123; MaterailFactory mf = new SouthMaterailFactory(); if (type.equals(&quot;meat&quot;)) &#123; return new sugar1(mf); &#125; else if (type.equals(&quot;sugar&quot;)) &#123; return new meat1(mf); &#125; return null; &#125;&#125; 运行代码12345678910public class run &#123; public static void main(String args[])&#123; MoonCakeStore1 mcs1 = new SouthMoonCakeStroe1(); MoonCake1 mc12 = mcs1.orderMoonCake(&quot;meat&quot;); System.out.println(mc12.getName()); MoonCake1 mc11 = mcs1.orderMoonCake(&quot;meat&quot;); System.out.println(mc11.getName()); &#125;&#125; 运行结果12345揉面粉准备制作月饼了南方的独特制作的面粉南方的独特制作的芝麻糖陷月饼 三、UML类图 四、笔记面向对象原则 多用组合，少用继承 针对接口编程、不针对实现编程 为交互之间的松耦合设计而努力 类应该对扩展开发、修改关闭《开闭原则》 依赖抽象、不要依赖具体类《依赖倒置原则》 工厂方法模式定义 定义了一个创建对象的接口，但由于之类子类要决定要实例化哪一个。工厂方法让类的实例推迟到子类 抽象工厂模式定义 提供了一个接口，用于创建相关或依赖对象的家族，而不需要明确指定具体类 注：抽象工厂模式的代码比较复杂，只是做材料的UML类图 github源码：https://github.com/gaoqisen/java-pattern]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－装饰者模式]]></title>
    <url>%2Fpatterm%2Fdecorate.html</url>
    <content type="text"><![CDATA[之前学习的是观察模式，复习观察者模式 观察者模式一般在那些地方使用：比如我们有两个对象，一个对象依赖于另一个对象的变化而变化，此时我们可以将这两个对象抽象出来，做成接口，利用观察者模式来进行解耦，又或者，当一个对象发生变化的时候，需要通知别的对象来做出改变，但又不知道这样的对象有多少个，此时利用观察者模式非常合适。 使用观察者模式的好处：第一、观察者模式在被观察者和观察者之间建立一个抽象的耦合。被观察者角色所知道的只是一个具体观察者列表，每一个具体观察者都符合一个抽象观察者的接口。被观察者并不认识任何一个具体观察者，它只知道它们都有一个共同的接口。由于被观察者和观察者没有紧密地耦合在一起，因此它们可以属于不同的抽象化层次。如果被观察者和观察者都被扔到一起，那么这个对象必然跨越抽象化和具体化层次。 第二、观察者模式支持广播通讯。被观察者会向所有的登记过的观察者发出通知， 观察者模式有下面的缺点：第一、如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间。第二、如果在被观察者之间有循环依赖的话，被观察者会触发它们之间进行循环调用，导致系统崩溃。在使用观察者模式是要特别注意这一点。第三、如果对观察者的通知是通过另外的线程进行异步投递的话，系统必须保证投递是以自恰的方式进行的。第四、虽然观察者模式可以随时使观察者知道所观察的对象发生了变化，但是观察者模式没有相应的机制使观察者知道所观察的对象是怎么发生变化的。 一、对装饰者模式的理解可以想象为给房子装修，有英式风格的房子、中式风格的房子，英式风格有英式风格的桌子、椅子，中式风格有中式风格的桌子椅子、等等。但是我们在装修房子的时候会自己去找材料，椅子有不同的风格、不同的厂家等。最后我们用这些不同的材料来装饰自己的房子。我们可以建立一个房子的抽象类，用材料去实现房子的抽象类。中式风格的房子、英式风格的房子都去实现房子的抽象类。之后用桌子、椅子具体的实现去继承材料抽象类。这样就可以用多态（父类的引用指向自类的对象），具体的看下面的代码 二、代码实现创建房子抽象类12345678// 房子抽象类public abstract class House &#123; String description = &quot;毛坯房&quot;; // 房子的描述 public String getDescription() &#123; return this.description; &#125; public abstract double cost(); // 房子的成本成本&#125; 创建材料抽象类、继承房子类1234// 装修材料public abstract class Material extends House&#123; public abstract String getDescription(); // 重写获取房子描述的方法&#125; 中式风格的房子类、中式风格椅子类、中式风格桌子类12345678910111213141516171819202122232425262728293031323334353637// 中式风格的房子public class ChineseStyle extends House&#123; public ChineseStyle() &#123; description = &quot;中式风格的房子&quot;; &#125; @Override public double cost() &#123; return 888; &#125;&#125;// 中式风格的椅子class ChineseChair extends Material&#123; House house; public ChineseChair(House house)&#123; this.house = house; &#125; public String getDescription() &#123; return house.getDescription() + &quot;＊＊＊中式风格的椅子&quot;; &#125; public double cost () &#123; return 20 + house.cost(); &#125;&#125;// 中式风格的桌子class ChineseDesk extends Material&#123; House house; public ChineseDesk(House house)&#123; this.house = house; &#125; public String getDescription() &#123; return house.getDescription() + &quot;***中式风格的桌子&quot;; &#125; public double cost () &#123; return 50 + house.cost(); &#125;&#125; 英式风格的房子、英式风格的桌子、英式风格的椅子1234567891011121314151617181920212223242526272829303132333435// 英式风格public class EnglandStyle extends House&#123; public EnglandStyle() &#123; description = &quot;英式风格的房子&quot;; &#125; @Override public double cost() &#123; return 666; &#125;&#125;class EnglandChair extends Material&#123; House house; public EnglandChair(House house)&#123; this.house = house; &#125; public String getDescription() &#123; return house.getDescription() + &quot;＊＊＊英式风格的椅子&quot;; &#125; public double cost () &#123; return 20 + house.cost(); &#125;&#125;class EnglandDesk extends Material&#123; House house; public EnglandDesk(House house)&#123; this.house = house; &#125; public String getDescription() &#123; return house.getDescription() + &quot;***英式风格的桌子&quot;; &#125; public double cost () &#123; return 50 + house.cost(); &#125;&#125; 代码运行 123456789101112131415161718public static void main(String args[]) &#123; House house = new ChineseStyle(); System.out.println(house.getDescription() + &quot;***&quot; +house.cost()); // 英式风格的房子用 一张中式风格的桌子，和两把椅子，一把中式风格的，一把英式风格的椅子 House house1 = new EnglandStyle(); // 英式风格的房子 house1 = new ChineseDesk(house1); house1 = new ChineseChair(house1); house1 = new EnglandChair(house1); System.out.println(house1.getDescription() + &quot;***&quot; +house1.cost()); // 中式风格的房子用 一张中式风格的桌子，和两把椅子，一把中式风格的，一把英式风格的椅子 House house2 = new ChineseStyle(); // 中式风格的房子 house2 = new ChineseDesk(house2); house2 = new ChineseChair(house2); house2 = new EnglandChair(house2); System.out.println(house2.getDescription() + &quot;***&quot; +house2.cost()); // 后面就可以按照自己的喜欢装修自己的房子了 // 其它的家具也可以更加灵活的添加了 &#125; 运行结果 123中式风格的房子***888.0英式风格的房子***中式风格的桌子＊＊＊中式风格的椅子＊＊＊英式风格的椅子***756.0中式风格的房子***中式风格的桌子＊＊＊中式风格的椅子＊＊＊英式风格的椅子***978.0 三、UML类图 四、笔记面向对象原则 封装变化 多用组合、少用继承 针对接口编程、不针对实现编程 为交互对象之间的松耦合设计而努力 对扩展开发、对修改关闭 装饰者模式的定义 动态的将责任附加到对象上。想要扩展功能，装饰折提供有别于继承的另一种选择 java 的 io流就是用装饰者模式实现的 github源码：https://github.com/gaoqisen/java-pattern]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux+elasticsearch+logstash 自动同步mysql实现搜索引擎]]></title>
    <url>%2Ftool%2Felk.html</url>
    <content type="text"><![CDATA[docker安装一、Elasticsearch1.1 简介ElasticSearch是一个基于Lucene构建的开源，分布式，RESTful搜索引擎。 设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。官方维护的docker镜像https://www.docker.elastic.co/ 1.2 安装（lastic 需要 Java 8 环境）123456789101112131415161718mac: brew install elasticsearch // 安装 elasticsearch --version // 查看版本号 elasticsearch // 启动后默认端口9200linux: wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.3.1.zip unzip elasticsearch-7.3.1.zip cd elasticsearch-7.3.1/ ./bin/elasticsearch // 启动docker: docker pull docker.elastic.co/elasticsearch/elasticsearch:7.3.1 // 拉取镜像 docker tag docker.elastic.co/elasticsearch/elasticsearch:7.3.1 elasticsearch docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; elasticsearch // 运行容器 docker exec -it es /bin/bash // 进入容器 vi elasticsearch.yml // 添加如下配置解决跨域问题 http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; docker restart es // 重启 1.3 配置文件https://blog.csdn.net/yjclsx/article/details/81319454 二、Kibana2.1 简介Kibana 是一款开源的数据分析和可视化平台，它是Elastic Stack 成员之一，设计用于和Elasticsearch 协作。 … 它很简单，基于浏览器的界面便于您快速创建和分享动态数据仪表板来追踪Elasticsearch 的实时数据变化。 搭建Kibana 非常简单。 2.2 安装12345678910111213mac: brew install kibana // 安装 kibana // 启动后默认端口5601linux: wget https://artifacts.elastic.co/downloads/beats/kibana/kibana-7.3.1-linux-x86_64.tar.gz tar -zxvf kibana-7.3.1-linux-x86_64.tar.gz ./kibana // 进入kibana的bin目录进行启动 nohup ./kibana &amp; // 后台启动docker: docker pull docker.elastic.co/kibana/kibana:7.3.1 docker tag docker.elastic.co/kibana/kibana:7.3.1 kibana docker run --name kibana -p 5601:5601 -d kibana docker run -d -p 5601:5601 --link elasticsearch -e ELASTICSEARCH_URL=http://elasticsearch:9200 kibana // 使用link参数，会在kibana容器hosts文件中加入elasticsearch ip地址，这样我们就直接通过定义的name来访问es服务了 2.3 配置文件https://www.elastic.co/guide/cn/kibana/current/settings.html 三、Logstash3.1 简介它一个有jruby语言编写的运行在java虚拟机上的具有收集分析转发数据流功能的工具 3.2 安装123456789101112mac: brew install logstash logstash --versionlinux: wget https://artifacts.elastic.co/downloads/logstash/logstash-7.3.1.tar.gz tar -zxvf logstash-7.3.1.tar.gz bin/logstash -e &apos;input&#123;stdin&#123;&#125;&#125;output&#123;stdout&#123;codec=&gt;rubydebug&#125;&#125;&apos;docker: docker pull docker.elastic.co/logstash/logstash:7.3.1 docker tag docker.elastic.co/logstash/logstash:7.3.1 logstash docker run -d --name logstash 10.45.53.221:5000/logstash docker run --rm -it --name logstash --link elasticsearch -d -v ~/elk/yaml/logstash.conf:/usr/share/logstash/pipeline/logstash.conf logstash // 启动logstash并关联elasticsearch 3.3 配置文件12345678910111213141516171819202122232425262728logstash.confinput &#123; beats &#123; host =&gt; &quot;localhost&quot; port =&gt; &quot;5043&quot; &#125;&#125;filter &#123; if [fields][doc_type] == &apos;order&apos; &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;TIMESTAMP_ISO8601:timestamp&#125; %&#123;LOGLEVEL:level&#125; %&#123;JAVALOGMESSAGE:msg&#125;&quot; &#125; &#125; &#125; if [fields][doc_type] == &apos;customer&apos; &#123; # 这里写两个一样的grok，实际上可能出现多种不同的日志格式，这里做个提示而已,当然如果是相同的格式，这里可以不写的 grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;TIMESTAMP_ISO8601:timestamp&#125; %&#123;LOGLEVEL:level&#125; %&#123;JAVALOGMESSAGE:msg&#125;&quot; &#125; &#125; &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125; elasticsearch &#123; hosts =&gt; [ &quot;localhost:9200&quot; ] index =&gt; &quot;%&#123;[fields][doc_type]&#125;-%&#123;+YYYY.MM.dd&#125;&quot; &#125;&#125; 单独安装一、安装elasticsearch作用：将数据放到elasticsearch进行搜索 1.1 配置elasticsearch的yum源1234567891011vim /etc/yum.repos.d/elasticsearch.repo // 配置yum源// 在elasticsearch.repo（如果没有就新建） 中加入一下内容6.x版本以上，将6改为2即可变更为2.x版本[elasticsearch-6.x]name=Elasticsearch repository for 6.x packagesbaseurl=https://artifacts.elastic.co/packages/6.x/yumgpgcheck=1gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearchenabled=1autorefresh=1type=rpm-md 1.2 yum安装1yum -y install elasticsearch 1.3 启动1service elasticsearch start // 启动命令 Starting elasticsearch (via systemctl): [ 确定 ] // 出现这个表示启动成功 二、安装logstash2.1 用于将mysql里面的数据同步到elasticsearch123wget https://artifacts.elastic.co/downloads/logstash/logstash-6.4.1.zip // 下载到目录解压文件cd logstash-6.4.1 // 进入logstash文件夹vim mysql.conf // 新建mysql.conf文件 2.2 在mysql.conf文件中配置如下信息：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647input &#123; stdin &#123; &#125; jdbc &#123; # mysql数据库连接 jdbc_connection_string =&gt; &quot;jdbc:mysql://localhost/basesdataName?characterEncoding=utf-8&amp;useSSL=false&amp;serverTimezone=UTC&quot; # mysqly用户名和密码 jdbc_user =&gt; &quot;root&quot; jdbc_password =&gt; &quot;password&quot; # 驱动配置(可以自己下载mysql-connector-java-6.0.5.jar，填写路径即可) jdbc_driver_library =&gt; &quot;./lib/mysql-connector-java-6.0.5.jar&quot; # 驱动类名 jdbc_driver_class =&gt; &quot;com.mysql.cj.jdbc.Driver&quot; jdbc_paging_enabled =&gt; &quot;true&quot; jdbc_page_size =&gt; &quot;50000&quot; # 执行指定的sql文件 statement_filepath =&gt; &quot;./data.sql&quot; # 设置监听 各字段含义 分 时 天 月 年 ，默认全部为*代表含义：每分钟都更新 schedule =&gt; &quot;* * * * *&quot; # 索引类型 type =&gt; &quot;product&quot; &#125; &#125; filter &#123; json &#123; source =&gt; &quot;message&quot; remove_field =&gt; [&quot;message&quot;] &#125; &#125; output &#123; elasticsearch &#123; #es服务器 hosts =&gt; [&quot;localhost:9200&quot;] #ES索引名称 index =&gt; &quot;sl_product&quot; #自增ID document_id =&gt; &quot;%&#123;id&#125;&quot; &#125; stdout &#123; codec =&gt; json_lines &#125; ｝ 2.3 新建data.sql1234vim data.sql // 新建写入如下内容SELECT * FROM tableName // 查询语句 2.4 启动logstash1bin/logstash -f mysql.conf // 在logstash-6.4.1目录启动，如果其它目录，需要更改路径 三、测试是否安装成功1curl &apos;http://127.0.0.1:9200/_search?pretty&apos; // 返回json串表示成功]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux+nginx+tomcat的java项目打包war部署]]></title>
    <url>%2Fjava%2Fwar.html</url>
    <content type="text"><![CDATA[环境：linux centos 7 系统、jdk8+tomcat8+nginx-1.12.1+mysql-5.7.16(jdk,tomcat,mysql是通过阿里云的java环境一键部署的，非阿里云的服务器可以自己搭建环境) 1.将java代码进行war打包 eclipse打包 选择路径，点击finish即可 2.将war包移动到tomcat的webapps目录下面通过ftp或者scp可以直接将本地的代码放到linux服务器上面 scp命令：scp 文件名 root@地址:/root （scp test.war root@107.1.0.1:/root） 3.启动tomcat会出现地址被占用 可以用命令：netstat -ltunp 。查看所有的端口号使用情况 如果有（tomcat默认使用8080、8009、8005）端口运行；直接用命令：kill -9 端口号 重启4.安装nginx-1.12.1 安装的sh脚本如下 12345678910111213!/bin/shyum install pcre-devel -yyum install openssl-devel -yyum install zlib-devel -ywget http://nginx.org/download/nginx-1.12.1.tar.gztar -zvxf nginx-1.12.1.tar.gzcd nginx-1.12.1./configuremakemake installcd /usr/local/nginx/sbin/./nginx -t/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf 详情：https://www.jianshu.com/p/73efd33b9da4 配置nginx.conf文件 server_name 自己的域名 location ^~ /自己的项目 { proxy_pass http://localhost:8080; } 5.重启nginx服务器如果使用的上面的脚本安装的可以使用一下方式停止nginx，和启动nginx 停止nginx: /usr/local/nginx/sbin/nginx -s stop 启动nginx: /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf6.开放nginx默认的80端口阿里云服务器可以直接在配置安全组里面配置 之后就可以通过域名访问啦]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－观察者模式]]></title>
    <url>%2Fpatterm%2Fobserve.html</url>
    <content type="text"><![CDATA[之前学习的是策略模式，复习一下之前的策略模式 策略模式一般在哪方面使用“策略”百科中指[计策]。一般是指： 可以实现目标的方案集合； 根据形势发展而制定的行动方针和斗争方法； 有斗争艺术，能注意方式方法。 用不同的策略解决不同的问题如出门的方式有自驾、火车、飞机等。选择不同的出行方式就是不同的策略,程序就是对各个算法的封装。让客服端非常方便的可以调用。就是在一个类中属性有相同的地方,但是行为方法不同，为了以后添加类特别方便，就可以考虑使用策略模式。 使用策略模式有什么好处 策略模式提供了对“开闭原则”的完美支持，用户可以在不修改原有系统的基础上选择算法或行为，也可以灵活地增加新的算法或行为。 策略模式提供了管理相关的算法族的办法。 策略模式提供了可以替换继承关系的办法。 使用策略模式可以避免使用多重条件转移语句。 一、对观察者模式的理解： 观察者模式可以理解为很多人去观察一个事物。比如微信的公众号，公众号可以经常给用户推送信息（一周可以给每个用户推送4篇文章）。用户可以取消关注，取消之后，公众号就无法给该用户发送消息了。当用户关注该公众号之后，就可以每月接收文章了。观察者模式可以很好的实现这种功能。 二、代码实现观察者模式在java中有两种实现，一种是自己实现，还有一种就是java自带的jdk中已经写好的 1、自己用代码实现观察者模式创建公众号接口，用于其他公众号实现12345public interface OfficialAccounts &#123; public void follow(User user); // 关注公众号 public void unfollow(User user); // 取消关注 public void sendMessageAll(); // 给所有的用户发送消息&#125; 创建一个新闻的公众号用于实现公众号接口，新增其它公众号，直接实现OfficialAccounts就好了 1234567891011121314151617181920212223242526272829303132// 新闻公众号public class NewsOfficialAccounts implements OfficialAccounts&#123; private ArrayList users; private String content;public NewsOfficialAccounts () &#123; users = new ArrayList();&#125;@Overridepublic void follow(User user) &#123; // 关注该公众号 users.add(user);&#125;@Overridepublic void unfollow(User user) &#123; // 取消关注 int i = users.indexOf(user); if(i&gt;=0) &#123; users.remove(i); &#125;&#125;@Overridepublic void sendMessageAll() &#123; // 给所有用户发送文章 for(int i = 0; i&lt;users.size();i++) &#123; User user = (User) users.get(i); user.acceptMessage(content); &#125;&#125;public void setContent(String content)&#123;// 设置消息自动给所有用户发送文章 this.content = content; sendMessageAll();&#125;&#125; 创建用户类接口，用于接受公众号文章 123public interface User &#123; public void acceptMessage(String content); // 接收消息&#125; 创建用户实现用户接口。创建其它用户也只需要实现User接口 123456789101112131415161718192021222324252627282930313233// 用户jasonpublic class UserJason implements User&#123; private String name = "jason"; private String message; private OfficialAccounts os;@Overridepublic void acceptMessage(String content) &#123; System.out.println(name+"接收到了"+content); this.message = content;&#125;public UserJason(OfficialAccounts os) &#123; // 构造器作为关注公众号用 this.os = os; os.follow(this);&#125;public void unfollow()&#123; // 取消关注 os.unfollow(this);&#125;&#125;// 用户tompublic class UserTom implements User&#123; private String name = "tom"; private String message; private OfficialAccounts os;@Overridepublic void acceptMessage(String content) &#123; System.out.println(name+"接收到了"+content); this.message = content;&#125;public UserTom(OfficialAccounts os) &#123; // 构造器作为关注公众号用 this.os = os; os.follow(this);&#125;&#125; main方法运行 123456789101112public static void main(String args[]) &#123; // 创建一个新闻的公众号 NewsOfficialAccounts noa = new NewsOfficialAccounts(); // 创建用户 UserTom tom = new UserTom(noa); UserJason jason = new UserJason(noa); // 公众号发送消息 noa.setContent("新闻消息1"); noa.setContent("新闻消息2"); jason.unfollow(); // 取消关注，jason无法接收消息3 noa.setContent("新闻消息3"); &#125; 运行结果：实现类发现消息之后只要所有关注了新闻公众号的用户可以接受消息，没有关注的就没有接收到 1234jason接收到了新闻消息1tom接收到了新闻消息2jason接收到了新闻消息2tom接收到了新闻消息3 2、用java jdk 自带的Observable、Observer实现创建公众号 123456789101112131415161718public class BankOffcialAccounts extends Observable&#123; // 实现java自带的可观察者接口 private String content; // 接受的消息 public BankOffcialAccounts()&#123;&#125;; // 构造器 public void changed() &#123; // 消息变化方法 setChanged(); notifyObservers(); // 通知所有观察者 &#125; public void sendMessage(String content) &#123; // 发送消息 this.content = content; changed(); &#125; public String getContent() &#123; return content; &#125; public void setContent(String content) &#123; // 写入公众号内容 this.content = content; &#125; &#125; 创建一个用java自带的观察者用户（同上面的UserJason、UserTom） 123456789101112131415161718public class UserJDK implements Observer&#123; // 实现java自带的观察者 Observable observable; private String name = "jdk"; private String content;@Overridepublic void update(Observable o, Object arg) &#123; if (o instanceof BankOffcialAccounts) &#123; BankOffcialAccounts boa = (BankOffcialAccounts)o; this.content = boa.getContent(); System.out.println(name+"接收到了"+content); &#125;&#125;public UserJDK(Observable o) &#123; this.observable = o; observable.addObserver(this);&#125; &#125; 和之前自己写的观察者模式一起运行 123456789101112131415public static void main(String args[]) &#123; // 创建一个新闻的公众号 NewsOfficialAccounts noa = new NewsOfficialAccounts(); // 创建用户 UserTom tom = new UserTom(noa); UserJason jason = new UserJason(noa); BankOffcialAccounts bank = new BankOffcialAccounts(); UserJDK jdk = new UserJDK(bank); // 发送消息 noa.setContent("新闻消息1"); noa.setContent("新闻消息2"); jason.unfollow(); // 取消关注，jason无法接收消息3 noa.setContent("新闻消息3"); bank.sendMessage("发送消息4");&#125; 运行结果 tom接收到了新闻消息1 jason接收到了新闻消息1 tom接收到了新闻消息2 jason接收到了新闻消息2 tom接收到了新闻消息3 jdk接收到了发送消息4 需要注意的是Observable是一个类，必须要写一个类基础他。限制类Observable的复用潜力 三、UML类图 Observable、Observer 是java jdk自带的 四、笔记1、面向对象原则 封装变化 多用组合、少用继承 针对接口编程、不针对实现编程 为交互对象之间的松耦合而努力 2、观察模式定义在对象之间定义一对多的依赖、这样一来，当一个对象改变状态，依赖它的对象都会收到通知，并自动更新 github源码：https://github.com/gaoqisen/java-pattern]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式－策略模式]]></title>
    <url>%2Fpatterm%2Fstrategy.html</url>
    <content type="text"><![CDATA[最近在读head frist 的设计模式。之前就了解过这本书的，感觉还不错，于是就在淘宝上购买了一本。书有500多页挺厚的一本，内容都是很容易上手的，当成漫画看就可以了。本着学习的态度，我想认认真真的把设计模式好好学习一下。设计模式很多，一个一个的学，学完一个，我就在这里纪录一下自己的学习成果、自己对设计模式的理解、以及一些笔记、代码就是自己想一个显示生活中的例子模拟实现。 一、对策略模式的理解&emsp;&emsp;关于策略模式，我看完书之后回忆的起来的大概就是建立一个抽象类，抽象除类的不改变的属性，如动物的名字、年龄等这些都是每个动物都有的，不会改变的。 二、代码实现创建一个动物类1234 public abstract class animal &#123; private String name; private int age;｝ 然后多个类继承该抽象类，如小猫、小狗等。 public class Dog extends animal{} 之后就是动物有的会飞、会叫等。这些都是动物的行为。之后把动物的飞行、叫喊接口化。 public interface CallBehavior { // 叫喊行为 public void call(); } public interface FlyBehavior { // 飞行行为 public void fly(); } 会飞、会叫都可以是动物的行为。就可以将会飞、会叫的接口组合在动物类里面，当成动物的属性 public abstract class animal { private String name; private int age; FlyBehavior flyBehavior; // 让所有的动物都继承这个行为 CallBehavior callBehavior; // 添加方法，用于被继承的动物共用方法 public void performFly() { // 执行飞行 flyBehavior.fly(); } public void performCall() { // 执行叫喊 callBehavior.call(); } public void setFlyBehavior(FlyBehavior fly){ // 动态的设置飞行的实现类，可以在运行时改变动物的飞行方式 this.flyBehavior = fly; } public void setCallBehavior(CallBehavior call){ this.callBehavior = call; } ｝ 之后就用不同的实现类实现会飞、会叫的接口 // 叫喊接口实现 public class CallBig implements CallBehavior{ @Override public void call() { System.out.println(&quot;特别大声的叫&quot;); } } public class CallNoWay implements CallBehavior{ @Override public void call() { System.out.println(&quot;不会叫&quot;); } } // 飞行接口实现 public class FlyNoWay implements FlyBehavior{ @Override public void fly() { System.out.println(&quot;不会飞行&quot;); } } public class FlyWithWings implements FlyBehavior{ @Override public void fly() { System.out.println(&quot;我要飞的更高&quot;); } } 然后就可以给小狗类添加默认的构造器。 public class Dog extends animal{ public Dog() { // 小狗的构造器 callBehavior = new CallBig(); // 大声叫callBehavior 使用的是父类的变量 flyBehavior = new FlyNoWay(); } } 调用 public static void main(String args[]) { animal dw = new DogModle(); dw.performFly(); // 默认飞行 dw.performCall(); // 默认叫喊 dw.setFlyBehavior(new FlyWithWings()); //动态绑定飞行行为 dw.performFly(); // 更改之后的飞行方式 } 执行结果 不会飞行 特别大声的叫 我要飞的更高 这样就动态实现了数据的绑定，根据不同的策略，绑定不同的接口。动态的完成功能，后期添加其他动物，也不需要更改之前的代码。完全做到了，对新增开放、对修改闭合的开闭原则。 三、UML类图画的不正规的uml图 四、笔记1、学到的三个原则 将会变动的代码进行封装 针对接口编程，不针对实现编程 多用组合、少用继承 ####2、策略模式定义 定义算法族，分别封装起来，让他们之间可以互相替换，此模式让算法的变化独立于使用算法的客户 github源码：https://github.com/gaoqisen/java-pattern]]></content>
      <categories>
        <category>patterm</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习]]></title>
    <url>%2Ftool%2Fredis.html</url>
    <content type="text"><![CDATA[一、简介1.1 优势 单点吞吐量特别高单点TPS(服务器每秒处理的事务数)达到8万/秒，QPS(对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准)达到10万/秒(数据都在内存中)。 存储类型多: string、map、list、set、stored-set 二、redis常见问题2.1 数据的过期时间到了如何处理 定期删除: 默认100ms就随机抽取一些过期的key(如果没隔100秒就是遍历所有过期key进行删除的话，cpu的负载就很大)； 惰性删除: 定期删除可能有一些数据过期了但是没有被删除掉。惰性删除就是等系统查询过数据之后在进行数据删除。 2.2 内存淘汰机制 volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的） allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！ volatile-lfu（4.0版本后）：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰 allkeys-lfu（4.0版本后）：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key 2.3 持久化机制 RDB(快照): 快照持久化是redis默认的方式，如配置：save 900 1 表示在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 AOF: AOF的持久化的实时性更好，已经成为了主流的持久化方案，默认没有开启(appendonly yes开启),有三种持久化方式： appendfsync always每次修改数据都会写入aof文件,这种方式严重降低redis的速度。 appendfsync everysec每秒同步一次。 appendfsync no让操作系统决定 2.4 如何实现事务 redis通过MULTI、EXEC、WATCH实现事务功能，是一组命令的集合。如果这组命令中有语法错误，或者命令不存在。那么整组的命令都不会执行。redis保证一个事务中的所有命令要么都执行、要么都不执行。 2.5 缓存雪崩、缓存穿透如何解决 缓存雪崩: 缓存在同一时间大面积失效，导致数据库负载的压力过大而跌机 保证整个redis的高可用集群，发现宕机尽快补上。 本地ehcache缓存+限量&amp;降级，避免数据库挂掉 利用redis持久化机制保存的数据尽快恢复缓存 缓存穿透: 大量的请求是没有缓存过的，导致大量的数据直接从数据库查询(一般3000个并发就会打垮大部分数据库) 做好参数校验，不合法的参数直接抛出异常。 利用缓存无效key的方法解决变化不频繁的key 布隆过滤器：判断给定的key是否是存在于海量数据中，如果不存在，直接返回异常。 2.6 解决并发竞争key的问题如果多个系统同时操作一个key，并发处理数据导致结果和我们想的不一样，就会出现这个问题。这种情况可以利用分布式锁解决这个问题,但是这样性能不好(慎用)。 2.7 如何保证缓存和数据库双写时的数据一致性在使用redis作为缓存的时候，就会出现缓存和数据库的双写和双存储问题。先存储数据库之后，在存储缓存。 修改数据也是同样的情况，都要同时操作。如果数据库保存成功了，但是在存入redis的时候报错了，就会导致数据不一致。如果要求必须一致的话，可以进行读请求和写请求的串行化，串到一个内存队列中去，但是这样会导致系统的吞吐量大幅度降低，用比正常多几倍的机器去支撑请求。 2.8 节省空间 精简键名和键值: 将长键名改为短键名如vip:20等。 内部编码优化: redis为每种数据类型都提供了两种内部编码方式，当存储的元素变多时，redis会自动将该健的内部编码方式转换为散列表。 三、常用命令3.1 字符串 将数据以字符串方式存储。 12345678 // 自增数字 incr num // 获取字符串长度 strlen key // 向尾部增加字符串a append key &apos;a&apos; // 获取多个key mget a b c 3.2 散列123456789101112 // 散列类型赋值 hset car name bwm // 获取散列类型的值 hget car name // 设置多个字段 hmset car name bwm color red price 100 // 获取所有的字段 hgetall car // 判断字段是否存在 hexists car name // 删除散列值 hdel car price 3.3 列表12345678910111213141516 // 向列表的两端添加元素 lpush key value rpush key value // 向两边弹出元素 lpop key rpop key // 查看列表的长度 llen key // 获取列表片段中的值(lrange test 0 2) lrange key start stop // 通过索引获取数据 lindex key index // 删除指定片段之外的数据 ltrim key start end // 讲元素从一个列表转移到另一个列表 rpoplpush source destination 3.4 集合12345678910111213141516 // 增加元素 sadd key member // 删除元素 trem key member // 获取所有元素 smembers key // 判断元素是否在集合中 smembers key member // 属于A不属于B的数据 sdiff set1 set2 // 交集 sinter set1 set2 // 并集 sunion set1 set2 // 获取元素的个数 scard key 3.5 有序集合1234567891011121314 // 增加元素 sadd key 78 tom 89 cat sadd key score number // 获取存的值 zscore key tom // 按照分数从大到小的顺序返回 zrange key start stop // 增加分数 zincrby sss 6 tom // 获取元素的个数 zcard sss // 删除元素 zrem sss tom // 获取元素的排名 zrank sss cat 3.6 其他1234567891011121314// redis事务 multi exec // 监控值,防止事务中的值被改掉 watch key // 设置key15分钟之后过期 expire key 900 // 查看key的过期时间(s) ttl key // 设置不过期 persist key // redis最复杂的命令排序 sort key sort key by field 四、java stringRedisTemplate常用123456789101112131415161718192021222324252627//向redis里存入数据和设置缓存时间 stringRedisTemplate.opsForValue().set(&quot;baike&quot;, &quot;100&quot;, 60 * 10, TimeUnit.SECONDS);//val做-1操作 stringRedisTemplate.boundValueOps(&quot;baike&quot;).increment(-1);//根据key获取缓存中的val stringRedisTemplate.opsForValue().get(&quot;baike&quot;)//val +1 stringRedisTemplate.boundValueOps(&quot;baike&quot;).increment(1);//根据key获取过期时间 stringRedisTemplate.getExpire(&quot;baike&quot;);//根据key获取过期时间并换算成指定单位 stringRedisTemplate.getExpire(&quot;baike&quot;,TimeUnit.SECONDS);//根据key删除缓存 stringRedisTemplate.delete(&quot;baike&quot;);//检查key是否存在，返回boolean值 stringRedisTemplate.hasKey(&quot;baike&quot;);//向指定key中存放set集合 stringRedisTemplate.opsForSet().add(&quot;baike&quot;, &quot;1&quot;,&quot;2&quot;,&quot;3&quot;);//设置过期时间 stringRedisTemplate.expire(&quot;baike&quot;,1000 , TimeUnit.MILLISECONDS);//根据key查看集合中是否存在指定数据 stringRedisTemplate.opsForSet().isMember(&quot;baike&quot;, &quot;1&quot;);//根据key获取set集合 stringRedisTemplate.opsForSet().members(&quot;baike&quot;);//验证有效时间Long expire = redisTemplate.boundHashOps(&quot;baike&quot;).getExpire();System.out.println(&quot;redis有效时间：&quot;+expire+&quot;S&quot;); https://developer.aliyun.com/article/705832 ## 3.1 数据的过期时间到了，redis是如何处理数据的 定期删除: 默认100ms就随机抽取一些过期的key(如果没隔100秒就是遍历所有过期key进行删除的话，cpu的负载就很大)； 惰性删除: 定期删除可能有一些数据过期了但是没有被删除掉。惰性删除就是等系统查询过数据之后在进行数据删除。 3.2 内存淘汰机制 volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的） allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！ volatile-lfu（4.0版本后）：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰 allkeys-lfu（4.0版本后）：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key 3.3 持久化机制 RDB(快照): 快照持久化是redis默认的方式，如配置：save 900 1 表示在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 AOF: AOF的持久化的实时性更好，已经成为了主流的持久化方案，默认没有开启(appendonly yes开启),有三种持久化方式： appendfsync always每次修改数据都会写入aof文件,这种方式严重降低redis的速度。 appendfsync everysec每秒同步一次。 appendfsync no让操作系统决定 3.4 如何实现事务 redis通过MULTI、EXEC、WATCH实现事务功能，是一组命令的集合。如果这组命令中有语法错误，或者命令不存在。那么整组的命令都不会执行。redis保证一个事务中的所有命令要么都执行、要么都不执行。 3.5 缓存雪崩、缓存穿透如何解决 缓存雪崩: 缓存在同一时间大面积失效，导致数据库负载的压力过大而跌机 保证整个redis的高可用集群，发现宕机尽快补上。 本地ehcache缓存+限量&amp;降级，避免数据库挂掉 利用redis持久化机制保存的数据尽快恢复缓存 缓存穿透: 大量的请求是没有缓存过的，导致大量的数据直接从数据库查询(一般3000个并发就会打垮大部分数据库) 做好参数校验，不合法的参数直接抛出异常。 利用缓存无效key的方法解决变化不频繁的key 布隆过滤器：判断给定的key是否是存在于海量数据中，如果不存在，直接返回异常。 3.6 解决并发竞争key的问题如果多个系统同时操作一个key，并发处理数据导致结果和我们想的不一样，就会出现这个问题。这种情况可以利用分布式锁解决这个问题,但是这样性能不好(慎用)。 3.7 如何保证缓存和数据库双写时的数据一致性在使用redis作为缓存的时候，就会出现缓存和数据库的双写和双存储问题。先存储数据库之后，在存储缓存。 修改数据也是同样的情况，都要同时操作。如果数据库保存成功了，但是在存入redis的时候报错了，就会导致数据不一致。如果要求必须一致的话，可以进行读请求和写请求的串行化，串到一个内存队列中去，但是这样会导致系统的吞吐量大幅度降低，用比正常多几倍的机器去支撑请求。 3.8 节省空间 精简键名和键值: 将长键名改为短键名如vip:20等。 内部编码优化: redis为每种数据类型都提供了两种内部编码方式，当存储的元素变多时，redis会自动将该健的内部编码方式转换为散列表。 五、安装redis5.1 mac brew安装1brew install redis 5.2 linux下载安装1234wget http://download.redis.io/releases/redis-2.8.17.tar.gz tar xzf redis-2.8.17.tar.gz cd redis-2.8.17 make 六、spring boot集成redis6.1 Maven引入1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 6.2 配置文件123456789spring.redis.database=0spring.redis.host=localhost spring.redis.port=6379 // 端口号spring.redis.password=redispass // 密码spring.redis.pool.max-active=8spring.redis.pool.max-wait=-1spring.redis.pool.max-idle=8spring.redis.pool.min-idle=0spring.redis.timeout=5000 // 链接超时时间，可以设置大一些 6.3 Service接口12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970 @Service public class RedisService &#123;@Autowired private StringRedisTemplate redisTemplate; /** * 一周有多少秒 */ private static final long WEEK_SECONDS = 7 * 24 * 60 * 60; /** * 将 key，value 存放到redis数据库中，默认设置过期时间为一周 * @param key * @param value */ public void set(String key, Object value) &#123; redisTemplate.opsForValue().set(key, JsonUtil.convertObj2String(value), WEEK_SECONDS, TimeUnit.SECONDS); &#125; /** * 将 key，value 存放到redis数据库中，设置过期时间单位是秒 * * @param key * @param value * @param expireTime */ public void set(String key, Object value, long expireTime) &#123; redisTemplate.opsForValue().set(key, JsonUtil.convertObj2String(value), expireTime, TimeUnit.SECONDS); &#125; /** * 判断 key 是否在 redis 数据库中 * * @param key * @return */ public boolean exists(final String key) &#123; return redisTemplate.hasKey(key); &#125; /** * 获取与 key 对应的对象 * @param key * @param clazz 目标对象类型 * @param &lt;T&gt; * @return */ public &lt;T&gt; T get(String key, Class&lt;T&gt; clazz) &#123; String s = get(key); if (s == null) &#123; return null; &#125; return JsonUtil.convertString2Obj(s, clazz); &#125; /** * 获取 key 对应的字符串 * @param key * @return */ public String get(String key) &#123; return redisTemplate.opsForValue().get(key); &#125; /** * 删除 key 对应的 value * @param key */ public void delete(String key) &#123; redisTemplate.delete(key); &#125; &#125; 6.4 测试12345678910 @Testpublic void redisService()&#123; String str = &quot;test&quot;; String retStr = this.redisService.get(&quot;test&quot;); if(retStr == null) &#123; this.redisService.set(&quot;test&quot;, str); retStr = str; &#125; System.out.println(&quot;:::&quot;+retStr);&#125; 七、延迟队列在需要异步处理数据的时候，进行延迟一定的时间进行处理。可以用Redisson实现。Redission的延迟队列可以解决RabbitMQ死信队列处理不同TTL消息产生的缺陷。 八、分布式锁比如在注册逻辑中需要先去判断用户名是否已经存在，如果不存在则进行注册。这种情况如果不使用锁来进行控制的话，就会出现注册时出现插入的数据没有入库而其它线程确查询到用户名不存在进行重复注册的问题。需要把查询和插入实现在分布式锁中就可以解决这个问题。]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
</search>
